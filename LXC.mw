==Introduction==

'''LXC''' (Linux Containers) was initially created by IBM, available in the mainline Linux kernel.
It uses cgroups and in concept is similar to Solaris Zones and FreeBSD Jails.
As the previously named technologies it aims to provide an higher level of segregation than a simple chroot.

==Concepts==

===Virtualization concepts===
This section is a basic overview of how lxc fits in to the virtualization world, the type of approach it uses, and the benefits and limitations thereof.
If you are trying to figure out if lxc is for you, or it's your first time setting up virtualization under Linux, then you should at least skim this section.

Roughly speaking there are two types of virtualization in use today, container-based virtualization and full virtualization.

====Container-based Virtualization (lxc)====

Container based virtualization is very fast and efficient. It's based on the premise that an OS kernel provides different views of the system to different running processes. This sort of segregation or compartmentalisation (sometimes called "thick sandboxing") can be useful for ensuring guaranteed access to hardware resources such as CPU and IO bandwidth, whilst maintaining security and efficiency.

On the unix family of operating systems, it is said that container based virtualization has its roots in the 1982 release of the [http://en.wikipedia.org/wiki/Chroot ''chroot''] tool, a filesystem subsystem specific container-based virtualization tool that was written by Sun Microsystems founder Bill Joy and published as part of 4.2BSD.

Since this early tool, which has become a mainstay of the unix world, a large number of unix developers have worked to mature more powerful container based virtualization solutions.  Some examples:
* Solaris Zones
* FreeBSD Jails
* Linux VServer
* OpenVZ

On Linux, historically the major two techniques have been Linux-VServer (open source / community driven) and OpenVZ (a free spinoff of a commercial product).

However, neither of these will be accepted in to the Linux kernel.  Instead Linus has opted for a more flexible, longer-term approach to achieving similar goals, using various new kernel features.  lxc is the next-generation container-based virtualization solution that uses these new features.

Conceptually, lxc can be seen as a further development of the existing 'chroot' technique with extra dimensions added. Where 'chroot'-ing only offers isolation at the file system level, lxc offers complete logical isolation from a container to the host and all other containers. In fact, installing a new Gentoo container from scratch is pretty much the same as for any normal Gentoo installation. 

Some of the most notably differences are: 
* each container will share the kernel with the host (and other containers). No kernel need to be present and/or mounted on the containers /boot directory;
* devices and filesystem will be (more or less) 'inherited' from the host, and need not be configured as would apply for a normal installation;
* if the host is using the openrc system for bootstrapping, such configuration items will "automagically" be omitted (i.e. filesystem mounts from fstab).

The last point is important to keep lxc based installation as much as simple and the same as for normal installations (no exceptions).

====Full Virtualization (not lxc)====
Full virtualization and paravirtualization solutions aim to simulate the underlying hardware. This type of solution, unlike lxc and other container-based solutions, usually allow you to run any operating system. Whilst this may be useful for the purposes of security and server consolidation, it is hugely inefficient compared to container based solutions. The most popular solutions in this area right now are probably VMWare, [[KVM]]/[[qemu]] and [[Xen]].

===Limitations of lxc===
With lxc, you can efficiently manage resource allocation in real time. In addition, you should be able to run different Linux distributions on the same host kernel in different containers (though there may be teething issues with startup and shutdown 'run control' (rc) scripts, and these may need to be modified slightly to make some guests work.  That said, maintainers of tools such as [[OpenRC|openrc]] are increasingly implementing lxc detection to ensure correct behaviour when their code runs within containers.)

Unlike full virtualization solutions, lxc will not let you run other operating systems (such as proprietary operating systems, or other types of unix). 

However, in theory there is no reason why you can't install a full or paravirtualization solution on the same kernel as your lxc host system and run both full/paravirtualised guests in addition to lxc guests at the same time.

Should you elect to do this, there are powerful abstracted virtualization management API under development, such as [libvirt] and [ganeti], that you may wish to check out.

In short:
* One kernel
* One operating system
* Many instances
... but can co-exist with other virtualization solutions if required.

====MAJOR Temporary Problems with LXC - READ THIS====
As documented [https://wiki.ubuntu.com/UserNamespace over here], basically containers are not functional as security containers at present, in that if you have root on a container you have root on the whole box.
*''root'' in a container has all capabilities
**Workaround:
***Do not treat root privileges in the container any more lightly than on the host itself.
*legacy ''UID/GID'' comparisons in many parts of the kernel code are dumb and will not respect containers
**Workaround:
***Do not mount parts of external filesystems within a container, except ''ro'' (read only).
***Do not re-use UIDs/GIDs between the container and the host
*shutdown and halt will run over the host system.
**Workaround:
***Restrict/Replace them in the container

Containers are still useful for isolating applications, including their networking interfaces, and applying resource limits and accounting to those applications.  As the above issues are resolved, they will also become functional security containers.

If you are designing a virtualisation solution for the long term and want a timeframe, then with appropriate disclaimers, judging from various comments and experience, an extremely rough timeframe might be 'circa end of 2012'.  But no guarantees.

See also [http://lwn.net/Articles/486306/ CAP_SYS_ADMIN: the new root].

===lxc Components===

lxc uses two new / lesser known kernel features known as 'control groups' and 'POSIX file capabilities'.  It also includes 'template scripts' to setup different guest environments.

====Control Groups====
Control Groups are a multi-hierarchy, multi-subsystem resource management / control framework for the Linux kernel.

In simpler language, what this means is that unlike the old ''chroot'' tool which was limited to the file subsystem, control groups let you define a 'group' encompassing one or more processes (eg: sshd, Apache) and then specify a variety of resource control and accounting options for that control group against multiple subsystems, such as:
* filesystem access
* general device access
* memory resources
* network device resources
* CPU bandwidth
* block device IO bandwidth
* various other aspects of a control group's view of the system

The user-space access to these new kernel features is a kernel-provided filesystem, known as 'cgroup'.  It is typically mounted at /cgroup and provides files similar to /proc and /sys representing the running environment and various kernel configuration options.

====POSIX File Capabilities====
POSIX file capabilities are a way to allocate privileges to a process that allow for more specific security controls than the traditional 'root' vs. 'user' privilege separation on unix family operating systems.


==Host Setup==
To get an lxc-capable host system working you will need the following components:
* Kernel with the appropriate LXC related options enabled

===Kernel with the appropriate LXC options enabled===
If you are unfamiliar with recompiling kernels, see the copious documentation available on that subject in addition to the notes below.

====Kernel options required====

The complete list of relevant kernel options (tested on 3.2.1-gentoo-r2) is as follows.  You can check your running kernel with the ''lxc-checkconfig'' script.
{{note| if lxc-checkconfig complaints about missing File capabilities: The feature is classified as deprecated and already missing in 3.2.1-gentoo-r2}}
=====General Options=====
{{kernel|3.2.1-gentoo-r2|<pre>
General setup  --->
 [*] Control Group support  --->
  [*]   Freezer cgroup subsystem 
  [*]   Device controller for cgroups
  [*]   Cpuset support
  [*]     Include legacy /proc/<pid>/cpuset file
  [*]   Simple CPU accounting cgroup subsystem 
  [*]   Resource counters 
  [*]     Memory Resource Controller for Control Groups
  [*]       Memory Resource Controller Swap Extension
  [*]         Memory Resource Controller Swap Extension enabled by default
  [*]   Enable perf_event per-cpu per-container group (cgroup) monitoring
  [*]   Group CPU scheduler  --->
   [*]   Group scheduling for SCHED_OTHER 
   [*]   Group scheduling for SCHED_RR/FIFO   
  <*>   Block IO controller
 -*- Namespaces support
  [*]   UTS namespace
  [*]   IPC namespace
  [*]   User namespace (EXPERIMENTAL)
  [*]   PID Namespaces
  [*]   Network namespace 
[*] Networking support  --->
      Networking options  --->
      <M> 802.1d Ethernet Bridging
      <M> 802.1Q VLAN Support 
Device Drivers  --->
      [*] Network device support  --->
       <M>   MAC-VLAN support (EXPERIMENTAL)
       <M>   Virtual ethernet pair device
      Character devices  --->
       -*- Unix98 PTY support
       [*]   Support multiple instances of devpts
</pre>}}

{{kernel|namespaces|<pre>
 General Setup 
-> Namespaces support 
CONFIG_NAMESPACES / "Namespaces" ('General Setup -> Namespaces support')
CONFIG_UTS_NS / "Utsname namespace" ('General Setup -> Namespaces Support / UTS namespace')
CONFIG_IPC_NS / "Ipc namespace" ('General Setup -> Namespaces Support / IPC namesapce')
CONFIG_USER_NS / "User namespace" ('General Setup -> Namespaces Support / User namespace (EXPERIMENTAL)')
CONFIG_PID_NS / "Pid namespace" ('General Setup -> Namespaces Support / PID Namespaces')
CONFIG_NET_NS / "Network namespace" ('General Setup -> Namespaces Support -> Network namespace')
  Device Drivers 
-> Character devices 
-> Unix98 PTY support -> ...
CONFIG_DEVPTS_MULTIPLE_INSTANCES / "Multiple /dev/pts instances" ('Device Drivers -> Character devices -> Unix98 PTY support -> Support multiple instances of devpts')
</pre>}}

{{kernel|control groups|<pre>
#  -> General Setup -> Control Group support -> ...
CONFIG_CGROUPS / "Cgroup" ('General Setup -> Control Group support')
CONFIG_CGROUP_DEVICE / "Cgroup device" ('General Setup -> Control Group support -> Device controller for cgroups') 
CONFIG_CPUSETS / "Cgroup cpuset"
</pre>}}

=====Freezer Support=====
Freezer support allows you to 'freeze' and 'thaw' a running guest, something like 'suspend' under VMWare products.  It appears to be under heavy development as of October 2010 (LXC list) but is apparently mostly functional.  Please add additional notes on this page if you explore further.
<pre>
CONFIG_CGROUP_FREEZER / "Freeze/thaw support" ('General Setup -> Control Group support -> Freezer cgroup subsystem')
</pre>

=====Scheduling Options=====
Scheduling allows you to specify how much hardware access (CPU bandwidth, block device bandwidth, etc.) control groups have.
<pre>
CONFIG_CGROUP_SCHED / "Cgroup sched" ('General Setup -> Control Group support -> Group CPU scheduler')
FAIR_GROUP_SCHED / "Group scheduling for SCHED_OTHER" ('General Setup -> Control Group support -> Group CPU scheduler -> Group scheduling for SCHED_OTHER')
CONFIG_BLK_CGROUP / "Block IO controller" ('General Setup -> Control Group support -> Block IO controller')
CONFIG_CFQ_GROUP_IOSCHED / "CFQ Group Scheduling support" ('Enable the block layer -> IO Schedulers -> CFQ I/O scheduler -> CFQ Group Scheduling support')
</pre>

=====Resource Counters (Memory/Swap Accounting)=====
Resource counters are an 'accounting' feature - they allow you to measure resource utilisation in your guest.  They are also an apparent prerequisite for limiting memory and swap utilisation.
<pre>
CONFIG_RESOURCE_COUNTERS / "Resource counters" ('General Setup -> Control Group support -> Resource counters')
</pre>

For memory resources...
<pre>
CONFIG_CGROUP_MEM_RES_CTLR / "Cgroup memory controller" ('General Setup -> Control Group support -> Resource counters -> Memory Resource Controller for Control Groups')
</pre>

If you want to also count swap utilisation, also select...
<pre>
CONFIG_CGROUP_MEM_RES_CTLR_SWAP / "Memory Resource Controller Swap Extension(EXPERIMENTAL)" ('General Setup -> Control Group support -> Resource counters -> Memory Resource Controller for Control Groups -> Memory Resource Controller Swap Extension')
</pre>

=====CPU Accounting=====
This allows you to measure the CPU utilisation of your control groups.
<pre>
CONFIG_CGROUP_CPUACCT / "Cgroup cpu account" ('General Setup -> Control Group support -> Simple CPU accounting cgroup subsystem')
</pre>

=====Networking Options=====
Ethernet bridging, veth, macvlan and vlan (802.1q) support are optional, but you probably want these.
<pre>
CONFIG_BRIDGE / "802.1d Ethernet Bridging" ('Networking support -> Networking options -> 802.1d Ethernet Bridging')
CONFIG_VETH / "Veth pair device"
CONFIG_MACVLAN / "Macvlan"
CONFIG_VLAN_8021Q / "Vlan"
</pre>

====Reconfig Gentoo kernel====
You can use the '''lxc-checkconfig''' tool to list kernel options that you need to enable in order to make your existing kernel configuration lxc compatible(tested on 3.2.1-gentoo-r2).
Process would be something like...

{{RootCmd|cd /usr/src/linux}}
{{RootCmd| lxc-checkconfig}}
{{note|note missing kernel options in output, or leave it open and switch to a new terminal}}
{{RootCmd|make menuconfig}}
{{ note | search for each CONFIG_SOMETHING using '/SOMETHING', enable them one by one, quit & save.  (most are in general, except for multiple unix98 pty's, in device drivers, and POSIX file capabilities, in security options (but apparently invisible in 3.2.1-gentoo-r2))}}
{{RootCmd|make && make modules_install}}

Then copy your kernel to your boot partition, reconfigure your boot loader, and reboot.

===lxc userspace utilities===
Because lxc is currently very new, it is probably worth making sure that you have the absolute latest version.  Therefore, before we begin, you should ensure that your portage tree is up to date with the following command.
{{RootCmd|emerge --sync}}

Next, figure out which version of lxc is available with:

{{RootCmd|emerge -vp app-emulation/lxc|output=<pre>
These are the packages that would be merged, in order:

Calculating dependencies... done!
[ebuild  N   ~] app-emulation/lxc-0.8.0-rc1-r1  USE="-examples -vanilla" 0 kB

Total: 1 package (1 new), Size of downloads: 0 kB

</pre>}}

Now go ahead and install with...
{{Emerge|app-emulation/lxc}}


=== Mounted cgroup filesystem ===
The 'cgroup' filesystem provides user-space access to the required kernel control group features, and is required by the lxc userspace utilities.

Recent kernels introduced /sys/fs/cgroup as default location.

The [[OpenRC|openrc]] has already mounts 'cgroup' filesystem during bootstrap, therefore, there is no need for users to mount it manually.

==Networking: Ethernet bridge==
You probably want to set up an ethernet bridge.  Note that this requires the CONFIG_BRIDGE symbol to be enabled in your kernel.

===Installation===
To check if the tools are already installed for configuring and modifying a bridge, use the portage preview command...
{{RootCmd|emerge -pv net-misc/bridge-utils}}
<pre>
# emerge -pv net-misc/bridge-utils

These are the packages that would be merged, in order:

Calculating dependencies... done!
[ebuild  N    ] net-misc/bridge-utils-1.4  32 kB

Total: 1 package (1 new), Size of downloads: 32 kB</pre>

If you see this, the tools are not installed yet. Go ahead and install with...
{{RootCmd|emerge --ask net-misc/bridge-utils}}

===Host Configuration===

First, we need to add the bridge device to the /etc/conf.d/net file. As an example, bridge configuration with DHCP:

{{note|Note that it is important to include 'setfd 0' and 'sethello 0' in order to bring the interface up quickly.  Other values will cause a delay after the guest starts, before the guest's networking will function.}}

{{File|/etc/conf.d/net||<pre>
#host
config_eth0=("192.168.0.3 netmask 255.255.255.0")
route_eth0=("default via 192.168.0.1")
# bridge (some guest)
config_br0=("dhcp")
brctl_br0="setfd 0
sethello 10
stp off"
bridge_br0="eth0"
</pre>}}

More documentation can be found in /usr/share/doc/openrc-0.9.9.3/net.example.

Next, create the init script and start the interface as follows:
{{RootCmd|ln -s /etc/init.d/net.lo /etc/init.d/net.br0}}
{{RootCmd|/etc/init.d/net.br0 start}}

Finally, to make sure the bridge is automatically set up on subsequent boots, run:
{{RootCmd|rc-update add net.br0 default}}

To grant the guest access to the internet, you will need to use iptables.  If it's not installed, first emerge it.
{{RootCmd|emerge --ask iptables}}

Allow ip forwarding in your {{Path|/etc/sysctl.conf}} or with the following command:
{{RootCmd|echo 1 > /proc/sys/net/ipv4/ip_forward}}

Add the iptables rules to grand masqueraded access to the internet. For
example (substitute 'eth0' with your external facing physical interface):
{{RootCmd|iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source ''your eth0 ip address''}}

This is equivalent to:
<pre>
EXTIF=eth0 # external facing physical interface
IP=`ifconfig $EXTIF|grep 'inet addr'|cut -d ':' -f2|cut -d ' ' -f1`
iptables -t nat -A POSTROUTING -o $EXTIF -j SNAT --to-source $IP
</pre>

Save the configuration and ensure it is restored at boot:
{{RootCmd|/etc/init.d/iptables save}}
{{RootCmd|rc-update add iptables default}}

===Guest Configuration===
Your guest network configuration resides in the guest's lxc.conf file.  Documentation for this file is accessible with:
<pre>man lxc.conf</pre>

If you have used a template script to create your guest, this will typically reside in the parent directory of the guest's root filesystem.  However, using /etc/lxc/ to store guest configurations is also common.

Your guest configuration should include the following network-related lines:
{{File|/etc/lxc/guest.conf||<pre>
lxc.network.type = veth
lxc.network.flags = up
lxc.network.link = br0
#lxc.network.ipv4 = 192.168.0.88
#lxc.network.hwaddr = b6:65:81:93:cb:a0
</pre>}}

{{Note|If you are not using dhcp inside the container to get an IP address, then just delete the 'lxc.network.hwaddr' line, and manually specify the IP you want to use next to lxc.network.ipv4.}}

If, like me, you are using dhcp inside the container to get an IP address, then run it once as shown.  LXC will generate a random MAC address for the interface.  To keep your DHCP server from getting confused, you will want to use that MAC address all the time.  So find out what it is, and then uncomment the 'lxc.network.hwaddr' line and specify it there.

==Guest Setup==

====Template scripts====
A number of 'template scripts' are distributed with the lxc package.  These scripts assist with generating various guest environments.

Template scripts live in ''/usr/lib(lib64)/lxc/templates/'' but should be executed via the '''lxc-create''' tool as follows:
{{RootCmd|lxc-create -n ''guestname'' -t ''template-name'' -f ''configuration-file-path''}}

The rootfs of linux container is stored in ''/etc/lxc/guestname/''

Configuration files (the '''-f ''configuration-file''''' option) are usually used to specify the network configuration for the guest.  For example:
<pre>
lxc.network.type=macvlan
lxc.network.link=eth0
lxc.network.flags=up
</pre>
... or ...
<pre>
lxc.network.type=veth
lxc.network.link=br0
lxc.network.flags=up
</pre>

More documentation about linux container network can be found in this [http://blog.flameeyes.eu/2010/09/linux-containers-and-networking ''article''].

The template scripts included in ''app-emulation/lxc-0.8.0-rc1-r1'' are:

*'''lxc-altlinux''' assists with setting up ALT Linux guests. However, this template script cannot be executed in gentoo linux directly, because it contains "apt-get" command when downloading Alt linux guest.
*'''lxc-archlinux''' assists with setting up Archlinux guests (see [http://wiki.archlinux.org/ wiki.archlinux.org]).  Note that in order to use lxc-archlinux, you must:
{{RootCmd|emerge sys-apps/pacman}}
'''Fixme''': It seems the pacman-4.0.1 cannot work correctly in gentoo linux
{{RootCmd|pacman|output=<pre>
error: failed to initialize alpm library (Could not find or read directory)
</pre>}}
*'''lxc-busybox''' assists with setting up minimal guests using Busybox (see [http://www.busybox.net/ busybox.net])
*'''lxc-debian''' assists with setting up Debian guests (see [http://www.debian.org/ debian.org]).  Note that in order to use lxc-debian, you must:
:{{RootCmd|emerge dev-util/debootstrap}}
*'''lxc-fedora''' assists with setting up Fedora guests (see [http://www.fedoraproject.org/ fedoraproject.org]).  Note that in order to use lxc-fedora, you must:
:{{RootCmd|emerge sys-apps/yum}}
:You will also need to install febootstrap tool from [http://people.redhat.com/~rjones/febootstrap/ http://people.redhat.com/~rjones/febootstrap/].  An ebuild has been created but is not yet in portage: {{Bug|309805}}
*'''lxc-lenny'''
*'''lxc-opensuse'''
*'''lxc-sshd''' assistss with setting up minimal sshd guests (see [http://www.openssh.com/ openssh.com]).
*'''lxc-ubuntu''' assist with setting up Ubuntu guests (see [http://www.ubuntu.com/ ubuntu.com]).  Note that in order to use lxc-ubuntu, you must:
:{{RootCmd|emerge dev-util/debootstrap}}
:Usage is as follows...
:{{RootCmd|mkdir ubuntu-guest}}
:{{RootCmd|lxc-create -t ubuntu -p ubuntu-guest -f ''network-configuration-file''}}
*'''lxc-ubuntu-cloud'''


[[category:virtualization]]
