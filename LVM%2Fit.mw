<languages />

{{Metadata|abstract=LVM consente agli amministratori di creare meta dispositivi che forniscono un livello di astrazione tra un file system e la memoria fisica che viene utilizzato al di sotto.}}

{{InfoBox stack
|{{InfoBox wikipedia|Logical Volume Manager (Linux)|header=true}}
}}

'''LVM''' ('''L'''ogical '''V'''olume '''M'''anager) consente agli amministratori di creare meta dispositivi che forniscono un livello di astrazione tra un file di sistema e la memoria fisica che viene utilizzato al di sotto. I meta dispositivi (su cui sono posti i file system) sono "volumi logici", che utilizzano memoria dai lotti di memoria chiamati "volume groups". Un "volume groups" (gruppo di volumi) viene fornito con uno o più "physical volumes" (volumi fisici), che sono i veri dispositivi su cui sono memorizzati i dati.

I volumi fisici possono essere partizioni, interi hard disk SATA raggruppati come JBOD ('''J'''ust a '''B'''unch '''O'''f '''D'''isks), sistemi RAID, iSCSI, Fibre Channel, eSATA ecc...

== Installazione ==

LVM è gestita da entrambi, drivers kernel-level e applicazioni su spazio utente (user-space), per gestire la configurazione di LVM.

=== Kernel ===

Attivare le seguenti opzioni del kernel:

{{KernelBox|<pre>
Device Drivers  --->
   Multiple devices driver support (RAID and LVM)  --->
       <*> Device mapper support
           <*> Crypt target support
           <*> Snapshot target
           <*> Mirror target
       <*> Multipath target
           <*> I/O Path Selector based on the number of in-flight I/Os
           <*> I/O Path Selector based on the service time
</pre>}}

{{Note|Non tutto deve essere abilitato; alcune opzioni sono richieste solo per [[LVM#LVM2_snapshots_and_thin_snapshots|LVM2 Snapshots and LVM2 Thin Snapshots]], [[LVM#Mirrored_volumes|LVM2 Mirrors]], [[LVM#Striping_.28RAID0.29|LVM2 RAID 0/Stripeset]] e encryption.}}

=== Software ===

Installare il pacchetto {{Package|sys-fs/lvm2}}:

{{USEflag|package=sys-fs/lvm2}}

{{Emerge|lvm2}}

== Configurazione ==

La configurazione di LVM è eseguita su più livelli:
# Gestione di LV, PV e VG attraverso le utilità di gestione;
# Messa a punto del sottosistema LVM attraverso il file di configurazione;
# La gestione dei servizi a livello di distribuzione;
# Configurazione tramite una ram iniziale del file system (initramfs).

La gestione dei volumi logici e fisici nonché i gruppi di volumi viene gestita tramite il capitolo [[#Usage|Utilizzo]].

=== File di configurazione di LVM ===

LVM ha un vasto file di configurazione in {{Path|/etc/lvm/lvm.conf}}. La maggior parte degli utenti non avranno bisogno di modificare le impostazioni in questo file per iniziare ad utilizzare LVM.

=== Gestione del servizio ===

Gentoo fornisce il servizio di LVM per rilevare e attivare i gruppi di volumi e i volumi logici automaticamente.

Il servizio può essere gestito attraverso il sistema di init.

==== openrc ====

Per avviare LVM manualmente:

{{RootCmd|/etc/init.d/lvm start}}

Per avviare LVM in fase di avvio:

{{RootCmd|rc-update add lvm boot}}

==== systemd ====

Per avviare LVM manualmente:

{{RootCmd|systemctl start lvm2-monitor.service}}

Per avviare LVM in fase di avvio:

{{RootCmd|systemctl enable lvm2-monitor.service}}

=== Utilizzare LVM in un initramfs ===

La maggior parte dei bootloader non può essere avviata direttamente da LVM - né GRUB legacy né LILO possono farlo. Grub 2 PUO' avviare da un volume logico LVM lineare, volume logico con mirroring e forse alcuni tipi di volumi logici RAID. Attualmente nessun bootloader supporta volumi logici sottili. 

Per questa ragione è raccomandabile utilizzare una partizione di avvio non-LVM e montare la root LVM da initramfs. Tale initramfs può essere generato automaticamente tramite [[Genkernel|genkernel]], {{Package|sys-kernel/genkernel-next}} e [[dracut]]:

* {{c|genkernel}} può avviare da tutti i tipi tranne dai volumi sottili (in quanto non costruisce la copia del pacchetto binario {{Package|thin-provisioning-tools}} dall'host di compilazione) e forse anche RAID10 (il supporto RAID10 richiede LVM2 2.02.98, ma genkernel 2.02.89, tuttavia, se i binari statici sono disponibili, può copiare quelli);
* {{c|genkernel-next}} può avviare da tutti i tipi di volumi, ma ha bisogno di un nuovo pacchetto {{Package|app-misc/pax-utils}} o i binari sottili risultanti saranno rotti (See {{Bug|482504}});
* {{c|dracut}} dovrebbe avviare tutti i tipi, ma include solo il supporto sottile initramfs se l'host viene eseguito su una root sottile.

==== Genkernel/Genkernel-next ====

Emergere o il pacchetto {{Package|sys-kernel/genkernel}} o ilpacchetto {{Package|sys-kernel/genkernel-next}}. La USE flag statica può anche essere abilitata per il pacchetto {{Package|sys-fs/lvm2}} così che genkernel utilizzerà il sistema binario (altrimenti compilerà la propria copia privata). Il seguente esempio compilerà solo un initramfs (non un interno kernel) e abiliterà il supporto per LVM.

{{RootCmd|genkernel --lvm initramfs}}

La pagina di manuale di genkernel delinea le altre opzioni a seconda delle esigenze del sistema.

L'initrd richiederà i parametri per stabilire come avviare LVM, ed essi sono forniti allo stesso modo di altri parametri del kernel. Per esempio:

{{FileBox|filename=/etc/default/grub|title=Aggiungere dolvm come parametro di avvio del kernel|lang=bash|1=
GRUB_CMDLINE_LINUX="dolvm"
}}

==== Dracut ====

Il pacchetto {{Package|sys-kernel/dracut}} è stato importato dal progetto Red Hat e offre uno strumento simile per generare un initramfs. Dal momento che è attualmente in ~arch per essere testato, gli utenti dovranno [[Knowledge_Base:Accepting_a_keyword_for_a_single_package|accept it]] (mediante {{Path|/etc/portage/package.accept_keywords}}) per emergerlo. Prima di fare ciò, la variabile <code>DRACUT_MODULES="lvm"</code> dovrebbe essere aggiunta sul file {{Path|/etc/portage/make.conf}}. Altri moduli possono essere desiderati, fare riferimento al [[Dracut]]. In generale, il seguente comando genererà un predefinito initramfs funzionale.

{{RootCmd|dracut -a lvm}}

L'initrd richiederà parametri per stabilire come avviare LVM, e questi sono in dotazione come gli altri parametri del kernel. Per esempio:

{{FileBox|filename=/etc/default/grub|title=Aggiungere il supporto LVM ai parametri di avvio del kernel|lang=bash|1=
GRUB_CMDLINE_LINUX="rd.lvm.vg=vol00"
}}

Per una lista globale delle opzioni di LVM all'interno di {{c|dracut}} vedere la sezione nel [https://www.kernel.org/pub/linux/utils/boot/dracut/dracut.html#_lvm Manuale di Dracut].

== Utilizzo ==

LVM organizza la memoria in tre diversi livelli come segue:
* dichi fissi, partizioni, sistemi RAID o altri mezzi di memorizzazione vengono inizializzati come Volumi Fisici (PVs)
* Volumi fisici (PV) sono raggruppati in Gruppi di Volumi (VG)
* Volumi logici (LV) sono gestiti in Gruppi di Volumi (VG)

=== PV (Volume Fisico) ===
I Volumi Fisici sono gli attuali hardware o sistemi di memoria di LVM.

==== Partizionamento ====

{{Note|Utilizzare partizioni separate per approvvigionare memoria a gruppi di volumi è necessario solo se non si desidera utilizzare l'intero disco per un singolo gruppo di volumi LVM. Se può essere utilizzato l'intero disco, saltare questo passaggio e inizializzare l'intero disco rigido come un volume fisico.}}

Il tipo di partizione per "LVM" è "8e" (LVM Linux).

Ad esempio, per impostare il tipo tramite {{c|fdisk}} per una partizione su {{Path|/dev/sda}}:

{{RootCmd|fdisk /dev/sda}}

In {{c|fdisk}}, creare partizioni utilizzando il tasto {{Key|n}} e variare il tipo di partizione con il tasto {{Key|t}} a "8e".

==== Creare PV ====

I volumi fisici possono essere creati/inizializzati con il comando   {{c|pvcreate}}.

Ad esempio, il seguente comando crea un volume fisico nella prima partizione primaria di {{Path|/dev/sda}} e {{Path|/dev/sdb}}:

{{RootCmd|pvcreate /dev/sd[ab]1}}

==== Lista PV ====

Con il comando {{c|pvdisplay}}, si può avere una panoramica di tutti i volumi fisici attivi sul sistema.

{{RootCmd|pvdisplay|output=<pre>
 --- Physical volume ---
  PV Name               /dev/sda1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               4098
  Allocated PE          36864
  PV UUID               3WHAz3-dh4r-RJ0E-5o6T-9Dbs-4xLe-inVwcV
  
 --- Physical volume ---
  PV Name               /dev/sdb1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               40962
  Allocated PE          0
  PV UUID               b031x0-6rej-BcBu-bE2C-eCXG-jObu-0Boo0x
</pre>}}

Se devono essere visualizzati più volumi fisici, {{c|pvscan}} può rilevare i volumi fisici inattivi, quindi attivarli.

{{RootCmd|pvscan|output=<pre>
  PV /dev/sda1  VG volgrp        lvm2 [160.01 GiB / 16.01 GiB free]
  PV /dev/sdb1  VG volgrp        lvm2 [160.01 GiB / 160.01 GiB free]
  Total: 2 [320.02 GB] / in use: 2 [320.02 GiB] / in no VG: 0 [0]
</pre>}}

==== Rimuovere PV ====

LVM distribuisce automaticamente i dati su tutti i volumi fisici disponibili (a meno che non impostato diversamente), ma in un approccio lineare. Se un richiesto volume logico (all'interno di un gruppo di volumi) è più piccolo rispetto alla quantità di spazio libero di un solo volume fisico, tutto lo spazio per il volume logico viene rivendicato su quel (singolo) volume fisico in modo contiguo. Questo viene fatto per motivi di prestazioni.

Se un volume fisico deve essere rimosso da un gruppo di volumi, i dati devono prima essere rimossi dal volume fisico. Con il comando  {{c|pvmove}} tutti i dati su un volume fisico vengono spostati su un altro volume fisico all'interno dello stesso gruppo di volumi.

{{RootCmd|pvmove -v /dev/sda1}}

Tale operazione può richiedere tempo a seconda della quantità di dati che devono essere spostati. Una volta terminata, non ci dovrebbero essere dati rimasti sul dispositivo. Verificare con pvdisplay che il volume fisico non è più utilizzato da nessun volume logico.

Il prossimo passo è rimuovere il volume fisico dal gruppo di volumi utilizzando {{c|vgreduce}}, dopodichè il dispositivo può essere "deselezionato" come volume fisico utilizzando pvremove:

{{RootCmd|vgreduce vg0 /dev/sda1 && pvremove /dev/sda1}}

=== VG (Gruppo di Volumi) ===

Un gruppo di volumi (VG) raggruppa un numero di volumi fisici e si presenta come {{Path|/dev/VG_NAME}} nel file system del dispositivo. Il nome di un gruppo di volumi è scelto dall'amministratore.

==== Creare VG ====

Il seguente comando crea un gruppo di volumi chiamato "vg0" con due volumi fisici assegnati: {{Path|/dev/sda1}} e {{Path|/dev/sdb1}}.

{{RootCmd|vgcreate vg0 /dev/sd[ab]1}}

==== Elenco VG ====

Per elencare tutti i gruppi di volumi attivi, utilizzare il comando {{c|vgdisplay}}:

{{RootCmd|vgdisplay|output=<pre>
  --- Volume group ---
  VG Name               vg0
  System ID             
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  8
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                6
  Open LV               6
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               320.02 GiB
  PE Size               4.00 MiB
  Total PE              81924
  Alloc PE / Size       36864 / 144.00 GiB
  Free  PE / Size       45056 /176.01 GiB
  VG UUID               mFPXj3-DdPi-7YJ5-9WKy-KA5Y-Vd4S-Lycxq3
</pre>}}

Se i gruppi di volume sono mancanti, utilizzare il comando {{c|vgscan}} per localizzarli:

{{RootCmd|vgscan|output=<pre>
  Reading all physical volumes.  This may take a while...
  Found volume group "vg0" using metadata type lvm2
</pre>}}

==== Estendere VG ====

I gruppi di volume raggruppano i volumi fisici, permettendo agli amministratori di utilizzare un pool di risorse di memoria da destinare ai file systems. Quando un gruppo di volumi non ha sufficienti risorse di memoria, è necessario estendere il gruppo di volumi con volumi fisici aggiuntivi.

Il seguente esempio amplia il gruppo di volumi "vg0" di un volume fisico su {{Path|/dev/sdc1}}:

{{RootCmd|vgextend vg0 /dev/sdc1}}

Si ricorda che il volume fisico deve prima essere inizializzato come tale!

==== Ridurre VG ====

Se i volumi fisici devono essere rimossi dal gruppo di volumi, tutti i dati ancora in uso nel volume fisico devono essere spostati ad altri volumi fisici nel gruppo di volumi. Come visto prima, questo viene gestito tramite il comando {{c|pvmove}}, dopodichè il volume fisico può essere rimosso dal gruppo di volumi utilizzando vgreduce:

{{RootCmd|pvmove -v /dev/sdc1
|vgreduce vg0 /dev/sdc1}}

==== Rimuovere VG ====

Se un gruppo di volumi non è più necessario (o, in altre parole, il lotto di memoria che rappresenta non viene più utilizzato e i volumi fisici in esso contenuti necessitano di essere liberati per altri scopi), tale gruppo di volumi può essere rimosso con vgremove. Questo funziona solo se nessun volume logico è definito per il gruppo di volumi, e tutti, tranne un volume fisico, sono già stati rimossi dal lotto di memoria.

{{RootCmd|vgremove vg0}}

=== LV (Volume Logico) ===

I volumi logici sono i dispositivi meta finali che sono messi a disposizione dal sistema di solito per crearci sopra i file system. Essi vengono creati e gestiti in gruppi di volumi e si presentano come {{Path|/dev/VG_NAME/LV_NAME}}. Come per i gruppi di volumi, il nome usato per un volume logico è deciso dall'amministratore.

==== Creare LV ====

Per creare un volume logico si utilizza il comando {{c|lvcreate}}. I parametri per il comando sono la dimensione richiesta per il volume logico (che non può essere più grande della quantità di spazio libero nel gruppo di volumi), il gruppo di volumi da cui lo spazio è rivendicato ed il nome del volume logico da creare.

Nell'esempio seguente, un volume logico di nome "lvol1" è stato creato dal gruppo di volumi chiamato "vg0" e con una dimensione di 150 MB:

{{RootCmd|lvcreate -L 150M -n lvol1 vg0}}

E' possibile utilizzare {{c|lvcreate}} per usare tutto lo spazio libero all'interno del gruppo di volumi. Ciò viene fatto con l'opzione <code>-l</code> la quale seleziona la quantità di "estensioni" piuttosto che la dimensione (leggibile dall'uomo). I volumi logici sono divisi in "estensioni logiche" che sono blocchi di dati all'interno di un gruppo di volumi. Tutte le estensioni in un gruppo di volumi hanno la stessa dimensione. Con l'opzione <code>-l</code> {{c|lvcreate}} può essere utilizzato per allocare tutte le estensioni libere:

{{RootCmd|lvcreate -l 100%FREE -n lvol1 vg0}}

Dopo il "FREE", può essere utilizzata la chiave "VG" per indicare l'intera dimensione del gruppo di volume.

==== Elencare LV ====

Per elencare tutti i volumi logici, utilizzare il comando {{c|lvdisplay}}:

{{RootCmd|lvdisplay}}

If logical volumes are missing, then the {{c|lvscan}} command can be used to scan for logical volumes on all available volume groups.

{{RootCmd|lvscan}}

==== Estendere LV ====

Quando un volume logico ha bisogno di essere esteso, si può utilizzare il comando {{c|lvextend}} per aumentare lo spazio allocato per il volume logico.

Per esempio, per estendere il volume logico "lvol1" a un totale di 500 MB:

{{RootCmd|lvextend -L500M /dev/vg0/lvol1}}

E' anche possibile utilizzare la dimensione da aggiungere piuttosto che la dimensione totale:

{{RootCmd|lvextend -L+350MB /dev/vg0/lvol1}}

Un gruppo di volumi esteso non fornisce immediatamente la memoria addizionale agli utenti finali. Per questo, il file system in cima al gruppo di volumi deve essere incrementato in termini di dimensioni pure. Non tutti i file systems consentono il ridimensionamento, quindi, per ulteriori informazioni, controllare la documentazione per il file system in questione.

Per esempio, per ridimensionare un file system ext4 e farlo diventare con dimensione da 500 MB:

{{RootCmd|resize2fs /dev/vg0/lvol1 500M}}

==== Diminuire LV ====

Se un volume logico ha bisogno di essere ridotto di dimensione, per prima cosa ridurre il file system stesso. Non tutti i file system supportano la riduzione.

Per esempio, ext4 non supporta la riduzione così il file system prima deve essere smontato. E' anche raccomandato fare un controllo al file system per assicurarsi che non vi siano incongruenze:

{{RootCmd|umount /mnt/data
|e2fsck -f /dev/vg0/lvol1
|resize2fs /dev/vg0/lvol1 150M}}

Con la riduzione del file system, è ora possibile diminuire pure la dimensione del volume logico:

{{RootCmd|lvreduce -L150M /dev/vg0/lvol1}}

==== Autorizzazioni LV ====

LVM supporta i permessi sui volui logici.

Per esempio, un volume logico può essere impostato a "leggi solo" utilizzando il comando {{c|lvchange}}:

{{RootCmd|lvchange -p r /dev/vg0/lvol1
|mount -o remount /dev/vg0/lvol1}}

Rimontarlo è necessario in quanto la modifica non viene applicata immediatamente.

Per contrassegnare il volume logico come scrivibile di nuovo, utilizzare il permesso "rw":

{{RootCmd|lvchange -p rw /dev/vg0/lvol1 && mount -o remount /dev/vg0/lvol1}}

==== Rimuovere LV ====

Prima di rimuovere un volume logico, assicurarsi che non sia montato:

{{RootCmd|umount /dev/vg0/lvol1}}

Disattivare il volume logico in modo che nessuna ulteriore attività di scrittura possa avvenire:

{{RootCmd|lvchange -a n /dev/vg0/lvol1}}

Con il volume smontato e disattivato, ora può essere rimosso, liberando le estensioni ad esso attribuite per l'uso da parte di altri volumi logici nel gruppo di volumi:

{{RootCmd|lvremove /dev/vg0/lvol1}}

== Caratteristiche ==

LVM fornisce un bel pò di caratteristiche interessanti per gli amministratori di memoria, tra cui (ma non solo)
* sottile approvvigionamento (memoria over-committing)
* supporto istantaneo
* tipi di volume con metodi di allocazione di memoria diversi

=== Approvvigionamento sottile ===

La versione più recente di LVM2 (2.02.89) supporta i volumi sottili. I volumi sottili sono per dispositivi a blocchi come [[Wikipedia:Sparse_file|sparse files]] sono dei file systems. Quindi, un volume logico sottile all'interno di una vasca può essere "extra-impegnato": la sua dimensione può essere maggiore della dimensione allocata - può anche essere più grande della vasca stessa. Proprio come un sparse file, le estensioni vengono allocate come il dispositivo a blocchi viene popolato. Se il file system ha "scartato" le estensioni di supporto sono liberati ancora come i files sono rimossi, riducendo l'utilizzo degli spazi della vasca.

Dentro LVM, tale vasca sottile è un tipo speciale di volume logico, che a sua volta può ospitare volumi logici.

==== Creazione di una vasca sottile ====

{{Warning|Se si verifica un overflow all'interno della vasca di metadati sottile, la vasca sarà danneggiata. '''LVM non può recuperare da questo'''.}} 

{{Note|Se la vasca sottile si esaurisce, qualsiasi processo che avrebbe causato la vasca sottile di allocare più estensioni (non disponibili) sarà bloccato in stato di "sonno uccidibile" fino a quando la vasca sottile non viene estesa o il processo riceve SIGKILL.}}

Ogni vasca sottile ha metadati associati ad essa, i quali vengono aggiunti alla dimensione della vasca sottile. LVM  calcolerà la dimensione dei metadati in base alla dimensione della vasca sottile come il minimo di "pool_chunks * 64 bytes" o 2MiB, se superiore. L'amministratore può selezionare un formato di metadati diverso.

Per creare una vasca sottile, aggiungere le opzioni <code>--type thin-pool --thinpool thin_pool</code> su {{c|lvcreate}}:

{{RootCmd|lvcreate -L 150M --type thin-pool --thinpool thin_pool vg0}}

L'esempio sopra crea una vasca sottile chiamata "thin_pool" con una dimensione totale di 150 MB. Questa è la dimensione reale allocata per la vasca sottile (e quindi la quantità totale di memoria effettiva che può essere utilizzata).

Per richiedere esplicitamente una certa dimensione dei metadati, utilizzare l'opzione <code>--metadatasize</code>:

{{RootCmd|lvcreate -L 150M --poolmetadatasize 2M --type thin-pool --thinpool thin_pool vg0}}

Per via che il metadata viene aggiunto alla vasca sottile, la via migliore di utilizzare tutta la dimensione disponibile in un gruppo di volumi per un volume logico, non funziona (vedere LVM bug [https://bugzilla.redhat.com/show_bug.cgi?id=812726|812726]):

{{RootCmd|lvcreate -l 100%FREE --type thin-pool --thinpool thin_pool vg0|output=<pre>
Insufficient suitable allocatable extents for logical volume thin_pool: 549 more required
</pre>}}

Si noti che la vasca sottile non ha un nodo del dispositivo associato come altri LV.

==== Creazione di un volume logico sottile ====

Un "volume logico sottile" è un volume logico all'interno della vasca sottile (che è essa stessa un volume logico). Come i volumi logici sottili sono "scarsi", una dimensione virtuale invece di una dimensione fisica è specificata utilizzando l'opzione <code>-V</code> :

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -n lvol1}}

In questo esempio, il volume logico (sottile) "lvol1" è esposto come dispositivo da 300MB di dimensione, anche se la vasca sottostante contiene solo 150MB di memoria reale allocata.

E' anche possibile creare sia la vasca sottile che il volume logico all'interno della vasca sottile con un unico comando:

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -L150M -n lvol1}}

==== Elencare vasche sottili e volumi logici sottili ====

Le vasche sottili e i volumi logici sottili sono tipologie speciali di volumi logici, e come tali sono visualizzati tramite il comando {{c|lvdisplay}}. Il comando {{c|lvscan}} individuerà anche questi volumi logici.

==== Estendere una vasca sottile ====

{{Warning|Come per LVM2 2.02.89, la dimensione del metadata relativo alla vasca sottile non può essere ampliata, essa è fissata al momento della creazione}}

La vasca sottile è ampliata come un volume logico non sottile utilizzando {{c|lvextend}}. Per esempio:

{{RootCmd|lvextend -L500M vg0/thin_pool}}

==== Estendere un volume logico sottile ====

Un volume logico sottile è ampliato regolarmente proprio come un volume logico sottile:

{{RootCmd|lvextend -L1G vg0/lvol1}}

Notare che il comando {{c|lvextend}} utilizza l'opzione <code>-L</code> (o <code>-l</code> se si utilizzano i conteggi estesi) e non un'opzione di "dimensione virtuale" come utilizzata durante la creazione. 

==== Ridurre una vasca sottile ====

Attualmente, LVM non può ridurre la dimensione della vasca sottile. Vedere il bug LVM [https://bugzilla.redhat.com/show_bug.cgi?id=812731|812731].

==== Ridurre un volume logico sottile ====

I volumi logici sottili sono ridotti regolarmente proprio come i volumi logici.

Per esempio:
{{RootCmd|lvreduce -L300M vg0/lvol1l}}

Notare che il comando {{c|lvreduce}} utilizza l'opzione <code>-L</code> (o <code>-l</code> se si utilizzano i conteggi estesi) e non un opzione di "dimensione virtuale" come utilizzata durante la creazione.

==== Rimuovere vasche sottili ====

Le vasche sottili non possono essere rimosse fino a che tutti i volumi logici in esse contenuti non vengono rimossi.

Quando una vasca sottile non serve più a nessun volume logico, essa può essere rimossa attraverso il comando {{c|lvremove}}:

{{RootCmd|lvremove vg0/thin_pool}}

=== LVM2 istantanee e istantanee sottili ===

Un'istantanea è un volume logico che agiscecome copia di un altro volume logico. Essa visualizza lo stato del volume logico originale al tempo della creazione dell'istantanea.

{{Warning|Poichè il volume dell'istantanea logica ottiene la stessa "LABEL" e "UUID" del filesystem, assicurarsi che il file {{Path|/etc/fstab}} o l'initramfs '''non''' contengano annotazioni per questi filesystems utilizzando la sintassi <code>LABEL{{=}}</code> o <code>UUID{{=}}</code>. Altrimenti si potrebbe finire col montare l'istantanea invece del volume logico originale.}}

==== Creazione di un'istantanea di un volume logico ====

Un'istantanea di un volume logico viene creata utilizzando l'opzione <code>-s</code> di {{c|lvcreate}}. L'istantanea di un volume logico è sempre memoria allocata come "registro" LVM, tutte le variazioni sono fatte dal volume logico originale e questi cambiamenti vengono memorizzati nella memoria allocata per l'istantanea. LVM inizierà dal volume logico originale dopodichè controllerà tutte le variazioni registrate, "annullando" le modifiche prima di mostrare il risultato per l'utente.

L'istantanea del volume logico, d'ora in poi, "cresce" al tasso che le modifiche vengono fatte sul volume logico originale. Quando la memoria allocata per l'istantanea è utilizzata completamente, l'istantanea sarà rimossa automaticamente dal sistema.

{{RootCmd|lvcreate -l 10%VG -s -n 20140412_lvol1 /dev/vg0/lvol1}}

L'esempio di sopra crea un'istantanea di volume logico chiamata "20140412_lvol1", basata sul volume logico "lvol1" nel gruppo di volume "vg0". Essa utilizza il 10% dello spazio (estensioni reali) allocato dal gruppo di volume.

==== Accedere ad un'istantanea di volume logico ====

Le istantanee dei volumi logici possono essere montate come volumi logici normali. Esse non sono nemmeno limitate a operazioni di sola lettura - è possibile modificare le istantanee e quindi utilizzarle per testare cose, tipo provare variazioni prima di effettuarle realmente su un file system di "produzione".

Finché esistono istantanee di volumi logici, il volume logico normale/originale non può essere ridotto di dimensioni e non può essere rimosso.

==== Istantanee sottili LVM ====

{{Note|Una istantanea sottile può essere presa solo su una vasca sottile per un volume logico sottile. Il bersaglio dispositivo mappatore sottile supporta istantanee sottili di sola lettura dei volumi logici non-sottili, ma l'LVM2 non le supporta. Tuttavia, è possibile creare una regolare istantanea di volume logico (non-sottile) di un volume logico sottile.}}

Per creare una istantanea sottile, il comando {{c|lvcreate}} viene utilizzato con l'opzione <code>-s</code>. Nessuna indicazione di dimensione deve essere trasmessa:

{{RootCmd|lvcreate -s -n 20140413_lvol1 /dev/vg0/lvol1}}

Le istantanee sottili del volume logico hanno la stessa dimensione del loro volume logico sottile originale, ed utilizzano un'allocazione fisica di 0 proprio come tutti gli altri volumi logici. 

{{Important|Se viene specificata l'opzione ''-l'' o ''-L'', l'istantanea verrà ancora creata, ma l'istantanea risultante sarà un'istantanea regolare, non un'istantanea sottile.}}

E' possibile anche ottenere istantanee di istantanee:

{{RootCmd|lvcreate -s -n 1_20140413_lvol1 /dev/vg0/20140413_lvol1}}

Le istantanee sottili hanno vari vantaggi rispetto alle istantanee regolari. Primo, le istantanee sottili sono indipendenti dal loro volume logico originale una volta create. Il volume logico originale può essere ridotto o cancellato senza influenzare l'istantanea. Secondo, l'istantanea sottile può essere efficacemente creata ricorsivamente (istantanea di un'istantanea) senza il "concatenamento" globale di regolari istantanee LVM ricorsive.

==== Riportare indietro allo stato di istantanea ====

Per riportare indietro il volume logico alla versione dell'istantanea, utilizzare il seguente comando:

{{RootCmd|lvconvert --merge /dev/vg0/20140413_lvol1}}

Dovrebbe impiegarci una coppia di minuti, dipende dalla dimensione del volume. Prego notare che il riportare indietro si verificherà solo se il volume logico genitore sarà offline. Quindi un riavvio potrebbe essere necessario.

{{Important|L'istantanea scomparirà e questa variazione non è reversibile}}

==== Riportare indietro le istantanee sottili ====

Per i volumi sottili, {{c|lvconvert --merge}} non funziona. Invece, bisogna cancellare il volume logico originale e rinominare l'istantanea:

{{RootCmd|umount /dev/vg0/lvol1
|lvremove /dev/vg0/lvol1
|lvrename vg0/20140413_lvol1 lvol1}}

=== Diversi metodi di allocazione della memoria ===

LVM supporta diversi metodi di allocazione di memoria:
* Volumi lineari (che è di default);
* Volumi mirroring (in una configurazione pressappoco attivo/standby);
* Striping (RAID0);
* Volumi mirroring (RAID1 - che è più una configurazione attivo/attivo);
* Striping con parità (RAID4  e RAID5);
* Striping con doppia parità (RAID6);
* Striping e mirroring (RAID10).

==== Volumi lineari ====

I volumi lineari sono il tipo più comune di volumi LVM. LVM

The commands introduced earlier on to create volume groups and logical volumes create linear volumes.

Because linear volumes have no special requirements, they are the easiest to manipulate and can be resized and relocated at will. If a logical volume is allocated across multiple physical volumes, and any of the physical volumes become unavailable, then that logical volume cannot be started anymore and will be unusable.

==== Mirrored volumes ====

LVM supports ''mirrored'' volumes, which provide fault tolerance in the event of drive failure. Unlike RAID1, there is no performance benefit - all reads and writes are delivered to a single side of the mirror.

To keep track of the mirror state, LVM requires a ''log'' to be kept. It is recommended (and often even mandatory) to position this log on a physical volume that does not contain any of the mirrored logical volumes. There are three kind of logs that can be used for mirrors:

# '''Disk''' is the default log type. All changes made are logged into extra metadata extents, which LVM manages. If a device fails, then the changes are kept in the log until the mirror can be restored again.
# '''Mirror''' logs are '''disk''' logs that are themselves mirrored. 
# '''Core''' mirror logs record the state of the mirror in memory only. LVM will have to rebuild the mirror every time it is activated. This type is useful for temporary mirrors.

To create a logical volume with a single mirror, pass the ''-m 1'' argument (to select standard mirroring) with optionally <code>--mirrorlog</code> to select a particular log type:

{{RootCmd|lvcreate -m 1 --mirrorlog mirror -l 40%VG --nosync -n lvol1 vg0}}

The ''-m 1'' tells LVM to create one (additional) mirror, so requiring 2 physical volumes. The <code>--nosync</code> option is an optimization - without it LVM will try synchronize the mirror by copying empty sectors from one logical volume to another.

It is possible to create a mirror of an existing logical volume:

{{RootCmd|lvconvert -m 1 -b vg0/lvol1}}

The <code>-b</code> option does the conversion in the background as this can take quite a while.

To remove a mirror, set the number of mirrors (back) to 0:

{{RootCmd|lvconvert -m0 vg0/lvol1}}

If part of the mirror is unavailable (usually because the disk containing the physical volume has failed), the volume group will need to be brought up in degraded mode:

{{RootCmd|vgchange -ay --partial vg0}}

On the first write, LVM will notice the mirror is broken. The default policy ("remove") is to automatically reduce/break the mirror according to the number of pieces available. A 3-way mirror with a missing physical volume will be reduced to 2-way mirror; a 2-way mirror will be reduced to a regular linear volume. If the failure is only transient, and the missing physical volume returns after LVM has broken the mirror, the mirrored logical volume will need to be recreated on it. 

To recover the mirror, the failed physical volume needs to be removed from the volume group, and a replacement physical volume needs to be added (or if the volume group has a free physical volume, it can be created on that one). Then the mirror can be recreated with {{c|lvconvert}} at which point the old physical volume can be removed from the volume group:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert -b -m 1 --mirrorlog disk vg0/lvol1
|vgreduce --removemissing vg0}}

It is possible to have LVM recreate the mirror with free extents on a different physical volume if one side fails. To accomplish that, set <code>mirror_image_fault_policy</code> to ''allocate'' in {{Path|lvm.conf}}.

==== Thin mirrors ====

It is not (yet) possible to create a mirrored thin pool or thin volume. It is possible to create a mirrored thin pool by creating a normal mirrored logical volume and then converting the logical volume to a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the volume group. Also, conversion of a mirror into a thin pool '''destroys''' all existing data in the mirror!}}

{{RootCmd|lvcreate -m 1 --mirrorlog mirrored -l40%VG -n thin_pool vg0
|lvcreate -m 1 --mirrorlog mirrored -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== Striping (RAID0) ====

Instead of a linear volume, where multiple contiguous physical volumes are appended, it possible to create a ''striped'' or ''RAID0'' volume for better performance. This will alternate storage allocations across the available physical volumes.

To create a striped volume over three physical volumes:

{{RootCmd|lvcreate -i 3 -l 20%VG -n lvol1_stripe vg0|output=<pre>
Using default stripesize 64.00 KiB
</pre>}}

The <code>-i</code> option indicates over how many physical volumes the striping should be done.

It is possible to mirror a stripe set. The <code>-i</code> and <code>-m</code> options can be combined to create a striped mirror:

{{RootCmd|lvcreate -i 2 -m 1 -l 10%VG vg0}}

This creates a 2 physical volume stripe set and mirrors it on 2 different physical volumes, for a total of 4 physical volumes. An existing stripe set can be mirrored with {{c|lvconvert}}.

A thin pool can be striped like any other logical volume. All the thin volumes created from the pool inherit that settings - do not specify it manually when creating a thin volume.

It is not possible to stripe an existing volume, nor reshape the stripes across more/less physical volumes, nor to convert to a different RAID level/linear volume. A stripe set can be mirrored. It is possible to extend a stripe set across additional physical volumes, but they must be added in multiples of the original stripe set (which will effectively linearly append a new stripe set).

==== Mirroring (RAID1) ====

Unlike RAID0, which is striping, RAID1 is mirroring, but implemented differently than the original LVM mirror. Under RAID1, reads are spread out across physical volumes, improving performance. RAID1 mirror failures do not cause I/O to block because LVM does not need to break it on write.

Any place where an LVM mirror could be used, a RAID1 mirror can be used in its place. It is possible to have LVM create RAID1 mirrors instead of regular mirrors implicitly by setting ''mirror_segtype_default'' to ''raid1'' in {{Path|lvm.conf}}.

{{Warning|LVM RAID1 mirroring is not yet supported by GRUB. If you apply this to the LVM volume that holds your kernel/initramfs (your 'boot' volume), you will render your system unbootable. (A fix will appear in the next version of GRUB. See GRUB bug [http://savannah.gnu.org/bugs/?44534 #44534] for details.)}}

To create a logical volume with a single mirror:

{{RootCmd|lvcreate -m 1 --type raid1 -l 40%VG --nosync -n lvm_raid1 vg0}}

Note the difference for creating a mirror: There is no ''mirrorlog'' specified, because RAID1 logical volumes do not have an explicit mirror log - it built-in to the logical volume.

It is possible to convert an existing logical volume to RAID1:

{{RootCmd|lvconvert -m 1 --type raid1 -b vg0/lvol1}}

To remove a RAID1 mirror, set the number of mirrors to 0:

{{RootCmd|lvconvert -m0 vg0/lvm_raid1}}

If part of the RAID1 is unavailable (usually because the disk containing the physical volume has failed), the volume group will need to be brought up in degraded mode:

{{RootCmd|vgchange -ay --partial vg0}}

Unlike an LVM mirror, writing does NOT break the mirroring. If the failure is only transient, and the missing physical volume returns, LVM will resync the mirror by copying cover the out-of-date segments instead of the entire logical volume. If the failure is permanent, then the failed physical volume needs to be removed from the volume group, and a replacement physical volume needs to be added (or if the volume group has a free physical volume, it can be created on a different PV). The mirror can then be repaired with {{c|lvconvert}}, and the old physical volume can be removed from the volume group:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert --repair -b vg0/lvm_raid1
|vgreduce --removemissing vg0}}

==== Thin RAID1 ====

It is not (yet) possible to create a RAID1 thin pool or thin volume. It is possible to create a RAID1 thin pool by creating a normal mirrored logical volume and then converting the logical volume to a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will then merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, conversion of a RAID1 into a thin pool '''destroys''' all existing data in the mirror!}}

{{RootCmd|lvcreate -m 1 --type raid1 -l40%VG -n thin_pool vg0
|lvcreate -m 1 --type raid1 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== Striping with parity (RAID4 and RAID5) ====

{{Note|Striping with parity requires at least 3 physical volumes.}}

RAID0 is not fault-tolerant - if any of the physical volumes fail then the logical volume is unusable. By adding a parity stripe to RAID0 the logical volume can still function if a physical volume is missing. A new physical volume can then be added to restore fault tolerance.

Stripsets with parity come in 2 flavors: RAID4 and RAID5. Under RAID4, all the parity stripes are stored on the same physical volume. This can become a bottleneck because all writes hit that physical volume, and it gets worse the more physical volumes are in the array. With RAID5, the parity data is distributed evenly across the physical volumes so none of them become a bottleneck. For that reason, RAID4 is rare and is considered obsolete/historical. In practice, all stripesets with parity are RAID5.

{{RootCmd|lvcreate --type raid5 -l 20%VG -i 2 -n lvm_raid5 vg0}}

Only the data physical volumes are specified with -i, LVM adds one to it automatically for the parity. So for a 3 physical volume RAID5, ''-i 2'' is passed on and not ''-i 3''.

When a physical volume fails, then the volume group will need to be brought up in degraded mode:

{{RootCmd|vgchange -ay --partial vg0}}

The volume will work normally at this point, however this degrades the array to RAID0 until a replacement physical volume is added. Performance is unlikely to be affected while the array is degraded - although it does need to recompute its missing data via parity, it only requires simple XOR for the parity block with the remaining data. The overhead is negligible compared to the disk I/O.

To repair the RAID5:

{{RootCmd|lvconvert --repair vg0/lvm_raid5
|vgreduce --removemissing vg0}}

It is possible to replace a still working physical volume in RAID5 as well:

{{RootCmd|lvconvert --replace /dev/sdb1 vg0/lvm_raid5
|vgreduce vg0 /dev/sdb1}}

The same restrictions of stripe sets apply to stripe sets with parity as well: it is not possible to enable striping with parity on an existing volume, nor reshape the stripes with parity across more/less physical volumes, nor to convert to a different RAID level/linear volume. A stripe set with parity can be mirrored. It is possible to extend a stripe set with parity across additional physical volumes, but they must be added in multiples of the original stripe set with parity (which will effectively linearly append a new stripe set with parity).

==== Thin RAID5 logical volumes ====

It is not (yet) possible to create stripe set with parity (RAID5) thin pools or thin logical volumes. It is possible to create a RAID5 thin pool by creating a normal RAID5 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, coversion of a RAID5 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid5 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid5 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== Striping with double parity (RAID6) ====

{{Note|RAID6 requires at least 5 physical volumes.}}

RAID6 is similar to RAID5, however RAID6 can survive up to '''two''' physical volume failures, thus offering more fault tolerance than RAID5 at the expense of extra physical volumes. 

{{RootCmd|lvcreate --type raid6 -l 20%VG -i 3 -n lvm_raid6 vg00}}

Like RAID5, the <code>-i</code> option is used to specify the number of physical volumes to stripe, excluding the 2 physical volumes for parity. So for a 5 physical volume RAID6, pass on <code>-i 3</code> and not <code>-i 5</code>.

Recovery for RAID6 is the same as RAID5.

{{Note|Unlike RAID5 where parity block is cheap to recompute vs disk I/O, this is only half true in RAID6. RAID6 uses 2 parity stripes: One stripe is computed the same way as RAID5 (simple XOR). The second parity stripe is much harder to compute - see [https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf|raid6 (pdf)] for more information.}}

==== Thin RAID6 logical volumes ====

It is not (yet) possible to create a RAID6 thin pool or thin volumes. It is possible to create a RAID6 thin pool by creating a normal RAID6 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, conversion of a RAID6 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid6 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid6 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== LVM RAID10 ====

{{Note|RAID10 requires at least 4 physical volumes. Also LVM syntax requires the number of physical volumes be multiple of the numbers stripes and mirror, even though RAID10 format does not}}

RAID10 is a combination of RAID0 and RAID1. It is more powerful than RAID0+RAID1 as the mirroring is done at the stripe level instead of the logical volume level, and therefore the layout doesn't need to be symmetric. A RAID10 volume can tolerate at least a single missing physical volume, and possibly more.

{{Note|LVM currently limits RAID10 to a single mirror.}}

{{RootCmd|lvcreate --type raid10 -l 1020 -i 2 -m 1 --nosync -n lvm_raid10 vg0}}

Both the <code>-i</code> and <code>-m</code> options are specified: <code>-i</code> is the number of stripes and <code>-m</code> is the number of mirrors. Two stripes and 1 mirror requires 4 physical volumes.

==== Thin RAID10 ====

It is not (yet) possible to create a RAID10 thin pool or thin volumes. It is possible to create a RAID10 thin pool by creating a normal RAID10 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.
 
{{Warning|Conversion of a RAID10 logical volume into a thin pool '''destroys''' all existing data in the logical volume!}}

{{RootCmd|lvcreate -i 2 -m 1 --type raid10 -l 1012 -n thin_pool vg0
|lvcreate -i 2 -m 1 --type raid10 -l 6 -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

== Experimenting with LVM ==

It is possible to experiment with LVM without using real storage devices. To accomplish this, loopback devices are created.

First make sure to have the loopback module loaded. 

{{RootCmd|modprobe -r loop && modprobe loop max_part{{=}}63}}

{{Note|If loopback support is built into the kernel, then use <code>loop.max_part{{=}}63</code> as boot option.}}

Next configure LVM to not use [[udev]] to scan for devices:

{{FileBox|filename=/etc/lvm/lvm.conf|title=Disabling udev in LVM config|lang=ini|1=
obtain_device_list_from_udev = 0
}}

{{Important|This is for testing only, make sure to change the setting back when dealing with real devices since it is much faster to use udev!}}

Create some image files which will become the storage devices. The next example uses five files for a total of about ~10GB of real hard drive space:

{{RootCmd|mkdir /var/lib/lvm_img
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm0.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm1.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm2.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm3.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm4.img bs{{=}}1024 seek{{=}}2097152}}

Check which loopback devices are available:

{{RootCmd|losetup -a}}

Assuming all loopback devices are available, next create the devices:

{{RootCmd|losetup /dev/loop0 /var/lib/lvm_img/lvm0.img
|losetup /dev/loop1 /var/lib/lvm_img/lvm1.img
|losetup /dev/loop2 /var/lib/lvm_img/lvm2.img
|losetup /dev/loop3 /var/lib/lvm_img/lvm3.img
|losetup /dev/loop4 /var/lib/lvm_img/lvm4.img}}

The {{Path|/dev/loop[0-4]}} devices are now available to use as any other hard drive in the system (and thus be perfect for physical volumes).

{{Note|On the next reboot, all the loopback devices will be released and the folder {{Path|/var/lib/lvm_img}} can be deleted.}}

== Troubleshooting ==

LVM has a few features that already provide some level of redundancy. However, there are situations where it is possible to restore lost physical volumes or logical volumes.

=== vgcfgrestore utility ===

By default, on any change to a LVM physical volume, volume group, or logical volume, LVM2 create a backup file of the metadata in {{Path|/etc/lvm/archive}}. These files can be used to recover from an accidental change (like deleting the wrong logical volume). LVM also keeps a backup copy of the most recent metadata in {{Path|/etc/lvm/backup}}. These can be used to restore metadata to a replacement disk, or repair corrupted metadata.

To see what states of the volume group are available to be restored (partial output to improve readability):

{{RootCmd|vgcfgrestore --list vg00|output=<pre>
  File:		/etc/lvm/archive/vg0_00042-302371184.vg
  VG name:    	vg0
  Description:	Created *before* executing 'lvremove vg0/lvm_raid1'
  Backup Time:	Sat Jul 13 01:41:32 201
</pre>}}

==== Recovering an accidentally deleted logical volume ====

Assuming the logical volume ''lvm_raid1'' was accidentally removed from volume group ''vg0'', it is possible to recover it as follows:

{{RootCmd|vgcfgrestore -f /etc/lvm/archive/vg0_00042-302371184.vg vg0}}

{{Important|vgcfgrestore only restores LVM metadata, ''not'' the data inside the logical volume. However pvremove, vgremove, and lvremove only wipe metadata, leaving any data intact. If <code>issue_discards</code> is set in {{Path|/etc/lvm/lvm.conf}} though, then these command ''are'' destructive to data.}}

==== Replacing a failed physical volume ====

It possible to do a true "replace" and recreate the metadata on the new physical volume to be the same as the old physical volume:

{{RootCmd|vgdisplay --partial --verbose|output=<pre>
  --- Physical volumes ---
  PV Name               /dev/loop0     
  PV UUID               iLdp2U-GX3X-W2PY-aSlX-AVE9-7zVC-Cjr5VU
  PV Status             allocatable
  Total PE / Free PE    511 / 102
  
  PV Name               unknown device     
  PV UUID               T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY
  PV Status             allocatable
  Total PE / Free PE    511 / 102
</pre>}}

The important line here is the UUID "unknown device". 

{{RootCmd|pvcreate --uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY --restorefile /etc/lvm/backup/vg0 /dev/loop1|output=<pre>
  Couldn't find device with uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY.
  Physical volume "/dev/loop1" successfully created</pre>}}

This recreates the physical volume metadata, but not the missing logical volume or volume group data on the physical volume.

{{RootCmd|vgcfgrestore -f /etc/lvm/backup/vg0 vg0|output=<pre>
  Restored volume group vg0
</pre>}}

This now reconstructs all the missing metadata on the physical volume, including the logical volume and volume group data. However it doesn't restore the data, so the mirror is out of sync.

{{RootCmd|vgchange -ay vg0|output=<pre>
  device-mapper: reload ioctl on  failed: Invalid argument
  1 logical volume(s) in volume group "vg0" now active
</pre>}}

{{RootCmd|lvchange --resync vg0/lvm_raid1|output=<pre>
Do you really want to deactivate logical volume lvm_raid1 to resync it? [y/n]: y
</pre>}}

This will resync the mirror. This works with RAID 4,5 and 6 as well.

=== Deactivating a logical volume ===

It is possible to deactivate a logical volume with the following command:

{{RootCmd|umount /dev/vg0/lvol1
|lvchange -a n /dev/vg0/lvol1}}

It is not possible to mount the logical volume anywhere before it gets reactivated:

{{RootCmd|lvchange -a y /dev/vg0/lvol1}}

== External resources ==

* [http://sourceware.org/lvm2/ LVM2 sourceware.org]
* [http://tldp.org/HOWTO/LVM-HOWTO/ LVM tldp.org]
* [http://sources.redhat.com/lvm2/wiki/ LVM2 Wiki redhat.com]


[[Category:Core system]]
