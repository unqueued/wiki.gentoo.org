<languages />

{{Metadata|abstract=LVM consente agli amministratori di creare meta dispositivi che forniscono un livello di astrazione tra un file system e la memoria fisica che viene utilizzato al di sotto.}}

{{InfoBox stack
|{{InfoBox wikipedia|Logical Volume Manager (Linux)|header=true}}
}}

'''LVM''' ('''L'''ogical '''V'''olume '''M'''anager) consente agli amministratori di creare meta dispositivi che forniscono un livello di astrazione tra un file system e la memoria fisica che viene utilizzata al di sotto. I meta dispositivi (su cui sono posti i file systems) sono "volumi logici", che utilizzano memoria dai lotti di memoria chiamati "volume groups". Un "volume groups" (gruppo di volumi) viene fornito con uno o più "physical volumes" (volumi fisici), che sono i veri dispositivi su cui sono memorizzati i dati.

I volumi fisici possono essere partizioni, interi hard disk SATA raggruppati come JBOD ('''J'''ust a '''B'''unch '''O'''f '''D'''isks), sistemi RAID, iSCSI, Fibre Channel, eSATA ecc...

== Installazione ==

LVM è gestita da entrambi, drivers kernel-level e applicazioni su spazio utente (user-space), per gestire la configurazione di LVM.

=== Kernel ===

Attivare le seguenti opzioni del kernel:

{{KernelBox|<pre>
Device Drivers  --->
   Multiple devices driver support (RAID and LVM)  --->
       <*> Device mapper support
           <*> Crypt target support
           <*> Snapshot target
           <*> Mirror target
       <*> Multipath target
           <*> I/O Path Selector based on the number of in-flight I/Os
           <*> I/O Path Selector based on the service time
</pre>}}

{{Note|Non tutto deve essere abilitato; alcune opzioni sono richieste solo per [[LVM#LVM2_snapshots_and_thin_snapshots|LVM2 Snapshots and LVM2 Thin Snapshots]], [[LVM#Mirrored_volumes|LVM2 Mirrors]], [[LVM#Striping_.28RAID0.29|LVM2 RAID 0/Stripeset]] e encryption.}}

=== Software ===

Installare il pacchetto {{Package|sys-fs/lvm2}}:

{{USEflag|package=sys-fs/lvm2}}

{{Emerge|lvm2}}

== Configurazione ==

La configurazione di LVM è eseguita su più livelli:
# Gestione di LV, PV e VG attraverso le utilità di gestione;
# Messa a punto del sottosistema LVM attraverso il file di configurazione;
# La gestione dei servizi a livello di distribuzione;
# Configurazione tramite una ram iniziale del file system (initramfs).

La gestione dei volumi logici e fisici nonché i gruppi di volumi viene gestita tramite il capitolo [[#Usage|Utilizzo]].

=== File di configurazione di LVM ===

LVM ha un vasto file di configurazione in {{Path|/etc/lvm/lvm.conf}}. La maggior parte degli utenti non avranno bisogno di modificare le impostazioni in questo file per iniziare ad utilizzare LVM.

=== Gestione del servizio ===

Gentoo fornisce il servizio di LVM per rilevare e attivare i gruppi di volumi e i volumi logici automaticamente.

Il servizio può essere gestito attraverso il sistema di init.

==== openrc ====

Per avviare LVM manualmente:

{{RootCmd|/etc/init.d/lvm start}}

Per avviare LVM in fase di avvio:

{{RootCmd|rc-update add lvm boot}}

==== systemd ====

Per avviare LVM manualmente:

{{RootCmd|systemctl start lvm2-monitor.service}}

Per avviare LVM in fase di avvio:

{{RootCmd|systemctl enable lvm2-monitor.service}}

=== Utilizzare LVM in un initramfs ===

La maggior parte dei bootloader non può essere avviata direttamente da LVM - né GRUB legacy né LILO possono farlo. Grub 2 PUO' avviare da un volume logico LVM lineare, volume logico con mirroring e forse alcuni tipi di volumi logici RAID. Attualmente nessun bootloader supporta volumi logici sottili. 

Per questa ragione è raccomandabile utilizzare una partizione di avvio non-LVM e montare la root LVM da initramfs. Tale initramfs può essere generato automaticamente tramite [[Genkernel|genkernel]], {{Package|sys-kernel/genkernel-next}} e [[dracut]]:

* {{c|genkernel}} può avviare da tutti i tipi tranne dai volumi sottili (in quanto non costruisce la copia del pacchetto binario {{Package|thin-provisioning-tools}} dall'host di compilazione) e forse anche RAID10 (il supporto RAID10 richiede LVM2 2.02.98, ma genkernel 2.02.89, tuttavia, se i binari statici sono disponibili, può copiare quelli);
* {{c|genkernel-next}} può avviare da tutti i tipi di volumi, ma ha bisogno di un nuovo pacchetto {{Package|app-misc/pax-utils}} o i binari sottili risultanti saranno rotti (See {{Bug|482504}});
* {{c|dracut}} dovrebbe avviare tutti i tipi, ma include solo il supporto sottile initramfs se l'host viene eseguito su una root sottile.

==== Genkernel/Genkernel-next ====

Emergere o il pacchetto {{Package|sys-kernel/genkernel}} o ilpacchetto {{Package|sys-kernel/genkernel-next}}. La USE flag statica può anche essere abilitata per il pacchetto {{Package|sys-fs/lvm2}} così che genkernel utilizzerà il sistema binario (altrimenti compilerà la propria copia privata). Il seguente esempio compilerà solo un initramfs (non un interno kernel) e abiliterà il supporto per LVM.

{{RootCmd|genkernel --lvm initramfs}}

La pagina di manuale di genkernel delinea le altre opzioni a seconda delle esigenze del sistema.

L'initrd richiederà i parametri per stabilire come avviare LVM, ed essi sono forniti allo stesso modo di altri parametri del kernel. Per esempio:

{{FileBox|filename=/etc/default/grub|title=Aggiungere dolvm come parametro di avvio del kernel|lang=bash|1=
GRUB_CMDLINE_LINUX="dolvm"
}}

==== Dracut ====

Il pacchetto {{Package|sys-kernel/dracut}} è stato importato dal progetto Red Hat e offre uno strumento simile per generare un initramfs. Dal momento che è attualmente in ~arch per essere testato, gli utenti dovranno [[Knowledge_Base:Accepting_a_keyword_for_a_single_package|accept it]] (mediante {{Path|/etc/portage/package.accept_keywords}}) per emergerlo. Prima di fare ciò, la variabile <code>DRACUT_MODULES="lvm"</code> dovrebbe essere aggiunta sul file {{Path|/etc/portage/make.conf}}. Altri moduli possono essere desiderati, fare riferimento al [[Dracut]]. In generale, il seguente comando genererà un predefinito initramfs funzionale.

{{RootCmd|dracut -a lvm}}

L'initrd richiederà parametri per stabilire come avviare LVM, e questi sono in dotazione come gli altri parametri del kernel. Per esempio:

{{FileBox|filename=/etc/default/grub|title=Aggiungere il supporto LVM ai parametri di avvio del kernel|lang=bash|1=
GRUB_CMDLINE_LINUX="rd.lvm.vg=vol00"
}}

Per una lista globale delle opzioni di LVM all'interno di {{c|dracut}} vedere la sezione nel [https://www.kernel.org/pub/linux/utils/boot/dracut/dracut.html#_lvm Manuale di Dracut].

== Utilizzo ==

LVM organizza la memoria in tre diversi livelli come segue:
* dichi fissi, partizioni, sistemi RAID o altri mezzi di memorizzazione vengono inizializzati come Volumi Fisici (PVs)
* Volumi fisici (PV) sono raggruppati in Gruppi di Volumi (VG)
* Volumi logici (LV) sono gestiti in Gruppi di Volumi (VG)

=== PV (Volume Fisico) ===
I Volumi Fisici sono gli attuali hardware o sistemi di memoria di LVM.

==== Partizionamento ====

{{Note|Utilizzare partizioni separate per approvvigionare memoria a gruppi di volumi è necessario solo se non si desidera utilizzare l'intero disco per un singolo gruppo di volumi LVM. Se può essere utilizzato l'intero disco, saltare questo passaggio e inizializzare l'intero disco rigido come un volume fisico.}}

Il tipo di partizione per "LVM" è "8e" (LVM Linux).

Ad esempio, per impostare il tipo tramite {{c|fdisk}} per una partizione su {{Path|/dev/sda}}:

{{RootCmd|fdisk /dev/sda}}

In {{c|fdisk}}, creare partizioni utilizzando il tasto {{Key|n}} e variare il tipo di partizione con il tasto {{Key|t}} a "8e".

==== Creare PV ====

I volumi fisici possono essere creati/inizializzati con il comando   {{c|pvcreate}}.

Ad esempio, il seguente comando crea un volume fisico nella prima partizione primaria di {{Path|/dev/sda}} e {{Path|/dev/sdb}}:

{{RootCmd|pvcreate /dev/sd[ab]1}}

==== Lista PV ====

Con il comando {{c|pvdisplay}}, si può avere una panoramica di tutti i volumi fisici attivi sul sistema.

{{RootCmd|pvdisplay|output=<pre>
 --- Physical volume ---
  PV Name               /dev/sda1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               4098
  Allocated PE          36864
  PV UUID               3WHAz3-dh4r-RJ0E-5o6T-9Dbs-4xLe-inVwcV
  
 --- Physical volume ---
  PV Name               /dev/sdb1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               40962
  Allocated PE          0
  PV UUID               b031x0-6rej-BcBu-bE2C-eCXG-jObu-0Boo0x
</pre>}}

Se devono essere visualizzati più volumi fisici, {{c|pvscan}} può rilevare i volumi fisici inattivi, quindi attivarli.

{{RootCmd|pvscan|output=<pre>
  PV /dev/sda1  VG volgrp        lvm2 [160.01 GiB / 16.01 GiB free]
  PV /dev/sdb1  VG volgrp        lvm2 [160.01 GiB / 160.01 GiB free]
  Total: 2 [320.02 GB] / in use: 2 [320.02 GiB] / in no VG: 0 [0]
</pre>}}

==== Rimuovere PV ====

LVM distribuisce automaticamente i dati su tutti i volumi fisici disponibili (a meno che non impostato diversamente), ma in un approccio lineare. Se un richiesto volume logico (all'interno di un gruppo di volumi) è più piccolo rispetto alla quantità di spazio libero di un solo volume fisico, tutto lo spazio per il volume logico viene rivendicato su quel (singolo) volume fisico in modo contiguo. Questo viene fatto per motivi di prestazioni.

Se un volume fisico deve essere rimosso da un gruppo di volumi, i dati devono prima essere rimossi dal volume fisico. Con il comando  {{c|pvmove}} tutti i dati su un volume fisico vengono spostati su un altro volume fisico all'interno dello stesso gruppo di volumi.

{{RootCmd|pvmove -v /dev/sda1}}

Tale operazione può richiedere tempo a seconda della quantità di dati che devono essere spostati. Una volta terminata, non ci dovrebbero essere dati rimasti sul dispositivo. Verificare con pvdisplay che il volume fisico non è più utilizzato da nessun volume logico.

Il prossimo passo è rimuovere il volume fisico dal gruppo di volumi utilizzando {{c|vgreduce}}, dopodichè il dispositivo può essere "deselezionato" come volume fisico utilizzando pvremove:

{{RootCmd|vgreduce vg0 /dev/sda1 && pvremove /dev/sda1}}

=== VG (Gruppo di Volumi) ===

Un gruppo di volumi (VG) raggruppa un numero di volumi fisici e si presenta come {{Path|/dev/VG_NAME}} nel file system del dispositivo. Il nome di un gruppo di volumi è scelto dall'amministratore.

==== Creare VG ====

Il seguente comando crea un gruppo di volumi chiamato "vg0" con due volumi fisici assegnati: {{Path|/dev/sda1}} e {{Path|/dev/sdb1}}.

{{RootCmd|vgcreate vg0 /dev/sd[ab]1}}

==== Elenco VG ====

Per elencare tutti i gruppi di volumi attivi, utilizzare il comando {{c|vgdisplay}}:

{{RootCmd|vgdisplay|output=<pre>
  --- Volume group ---
  VG Name               vg0
  System ID             
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  8
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                6
  Open LV               6
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               320.02 GiB
  PE Size               4.00 MiB
  Total PE              81924
  Alloc PE / Size       36864 / 144.00 GiB
  Free  PE / Size       45056 /176.01 GiB
  VG UUID               mFPXj3-DdPi-7YJ5-9WKy-KA5Y-Vd4S-Lycxq3
</pre>}}

Se i gruppi di volume sono mancanti, utilizzare il comando {{c|vgscan}} per localizzarli:

{{RootCmd|vgscan|output=<pre>
  Reading all physical volumes.  This may take a while...
  Found volume group "vg0" using metadata type lvm2
</pre>}}

==== Estendere VG ====

I gruppi di volume raggruppano i volumi fisici, permettendo agli amministratori di utilizzare un pool di risorse di memoria da destinare ai file systems. Quando un gruppo di volumi non ha sufficienti risorse di memoria, è necessario estendere il gruppo di volumi con volumi fisici aggiuntivi.

Il seguente esempio amplia il gruppo di volumi "vg0" di un volume fisico su {{Path|/dev/sdc1}}:

{{RootCmd|vgextend vg0 /dev/sdc1}}

Si ricorda che il volume fisico deve prima essere inizializzato come tale!

==== Ridurre VG ====

Se i volumi fisici devono essere rimossi dal gruppo di volumi, tutti i dati ancora in uso nel volume fisico devono essere spostati ad altri volumi fisici nel gruppo di volumi. Come visto prima, questo viene gestito tramite il comando {{c|pvmove}}, dopodichè il volume fisico può essere rimosso dal gruppo di volumi utilizzando vgreduce:

{{RootCmd|pvmove -v /dev/sdc1
|vgreduce vg0 /dev/sdc1}}

==== Rimuovere VG ====

Se un gruppo di volumi non è più necessario (o, in altre parole, il lotto di memoria che rappresenta non viene più utilizzato e i volumi fisici in esso contenuti necessitano di essere liberati per altri scopi), tale gruppo di volumi può essere rimosso con vgremove. Questo funziona solo se nessun volume logico è definito per il gruppo di volumi, e tutti, tranne un volume fisico, sono già stati rimossi dal lotto di memoria.

{{RootCmd|vgremove vg0}}

=== LV (Volume Logico) ===

I volumi logici sono i dispositivi meta finali che sono messi a disposizione dal sistema di solito per crearci sopra i file system. Essi vengono creati e gestiti in gruppi di volumi e si presentano come {{Path|/dev/VG_NAME/LV_NAME}}. Come per i gruppi di volumi, il nome usato per un volume logico è deciso dall'amministratore.

==== Creare LV ====

Per creare un volume logico si utilizza il comando {{c|lvcreate}}. I parametri per il comando sono la dimensione richiesta per il volume logico (che non può essere più grande della quantità di spazio libero nel gruppo di volumi), il gruppo di volumi da cui lo spazio è rivendicato ed il nome del volume logico da creare.

Nell'esempio seguente, un volume logico di nome "lvol1" è stato creato dal gruppo di volumi chiamato "vg0" e con una dimensione di 150 MB:

{{RootCmd|lvcreate -L 150M -n lvol1 vg0}}

E' possibile utilizzare {{c|lvcreate}} per usare tutto lo spazio libero all'interno del gruppo di volumi. Ciò viene fatto con l'opzione <code>-l</code> la quale seleziona la quantità di "estensioni" piuttosto che la dimensione (leggibile dall'uomo). I volumi logici sono divisi in "estensioni logiche" che sono blocchi di dati all'interno di un gruppo di volumi. Tutte le estensioni in un gruppo di volumi hanno la stessa dimensione. Con l'opzione <code>-l</code> {{c|lvcreate}} può essere utilizzato per allocare tutte le estensioni libere:

{{RootCmd|lvcreate -l 100%FREE -n lvol1 vg0}}

Dopo il "FREE", può essere utilizzata la chiave "VG" per indicare l'intera dimensione del gruppo di volume.

==== Elencare LV ====

Per elencare tutti i volumi logici, utilizzare il comando {{c|lvdisplay}}:

{{RootCmd|lvdisplay}}

If logical volumes are missing, then the {{c|lvscan}} command can be used to scan for logical volumes on all available volume groups.

{{RootCmd|lvscan}}

==== Estendere LV ====

Quando un volume logico ha bisogno di essere esteso, si può utilizzare il comando {{c|lvextend}} per aumentare lo spazio allocato per il volume logico.

Per esempio, per estendere il volume logico "lvol1" a un totale di 500 MB:

{{RootCmd|lvextend -L500M /dev/vg0/lvol1}}

E' anche possibile utilizzare la dimensione da aggiungere piuttosto che la dimensione totale:

{{RootCmd|lvextend -L+350MB /dev/vg0/lvol1}}

Un gruppo di volumi esteso non fornisce immediatamente la memoria addizionale agli utenti finali. Per questo, il file system in cima al gruppo di volumi deve essere incrementato in termini di dimensioni pure. Non tutti i file systems consentono il ridimensionamento, quindi, per ulteriori informazioni, controllare la documentazione per il file system in questione.

Per esempio, per ridimensionare un file system ext4 e farlo diventare con dimensione da 500 MB:

{{RootCmd|resize2fs /dev/vg0/lvol1 500M}}

==== Diminuire LV ====

Se un volume logico ha bisogno di essere ridotto di dimensione, per prima cosa ridurre il file system stesso. Non tutti i file system supportano la riduzione.

Per esempio, ext4 non supporta la riduzione così il file system prima deve essere smontato. E' anche raccomandato fare un controllo al file system per assicurarsi che non vi siano incongruenze:

{{RootCmd|umount /mnt/data
|e2fsck -f /dev/vg0/lvol1
|resize2fs /dev/vg0/lvol1 150M}}

Con la riduzione del file system, è ora possibile diminuire pure la dimensione del volume logico:

{{RootCmd|lvreduce -L150M /dev/vg0/lvol1}}

==== Autorizzazioni LV ====

LVM supporta i permessi sui volui logici.

Per esempio, un volume logico può essere impostato a "leggi solo" utilizzando il comando {{c|lvchange}}:

{{RootCmd|lvchange -p r /dev/vg0/lvol1
|mount -o remount /dev/vg0/lvol1}}

Rimontarlo è necessario in quanto la modifica non viene applicata immediatamente.

Per contrassegnare il volume logico come scrivibile di nuovo, utilizzare il permesso "rw":

{{RootCmd|lvchange -p rw /dev/vg0/lvol1 && mount -o remount /dev/vg0/lvol1}}

==== Rimuovere LV ====

Prima di rimuovere un volume logico, assicurarsi che non sia montato:

{{RootCmd|umount /dev/vg0/lvol1}}

Disattivare il volume logico in modo che nessuna ulteriore attività di scrittura possa avvenire:

{{RootCmd|lvchange -a n /dev/vg0/lvol1}}

Con il volume smontato e disattivato, ora può essere rimosso, liberando le estensioni ad esso attribuite per l'uso da parte di altri volumi logici nel gruppo di volumi:

{{RootCmd|lvremove /dev/vg0/lvol1}}

== Caratteristiche ==

LVM fornisce un bel pò di caratteristiche interessanti per gli amministratori di memoria, tra cui (ma non solo)
* sottile approvvigionamento (memoria over-committing)
* supporto istantaneo
* tipi di volume con metodi di allocazione di memoria diversi

=== Approvvigionamento sottile ===

La versione più recente di LVM2 (2.02.89) supporta i volumi sottili. I volumi sottili sono per dispositivi a blocchi come [[Wikipedia:Sparse_file|sparse files]] sono dei file systems. Quindi, un volume logico sottile all'interno di una vasca può essere "extra-impegnato": la sua dimensione può essere maggiore della dimensione allocata - può anche essere più grande della vasca stessa. Proprio come un sparse file, le estensioni vengono allocate come il dispositivo a blocchi viene popolato. Se il file system ha "scartato" le estensioni di supporto sono liberati ancora come i files sono rimossi, riducendo l'utilizzo degli spazi della vasca.

Dentro LVM, tale vasca sottile è un tipo speciale di volume logico, che a sua volta può ospitare volumi logici.

==== Creazione di una vasca sottile ====

{{Warning|Se si verifica un overflow all'interno della vasca di metadati sottile, la vasca sarà danneggiata. '''LVM non può recuperare da questo'''.}} 

{{Note|Se la vasca sottile si esaurisce, qualsiasi processo che avrebbe causato la vasca sottile di allocare più estensioni (non disponibili) sarà bloccato in stato di "sonno uccidibile" fino a quando la vasca sottile non viene estesa o il processo riceve SIGKILL.}}

Ogni vasca sottile ha metadati associati ad essa, i quali vengono aggiunti alla dimensione della vasca sottile. LVM  calcolerà la dimensione dei metadati in base alla dimensione della vasca sottile come il minimo di "pool_chunks * 64 bytes" o 2MiB, se superiore. L'amministratore può selezionare un formato di metadati diverso.

Per creare una vasca sottile, aggiungere le opzioni <code>--type thin-pool --thinpool thin_pool</code> su {{c|lvcreate}}:

{{RootCmd|lvcreate -L 150M --type thin-pool --thinpool thin_pool vg0}}

L'esempio sopra crea una vasca sottile chiamata "thin_pool" con una dimensione totale di 150 MB. Questa è la dimensione reale allocata per la vasca sottile (e quindi la quantità totale di memoria effettiva che può essere utilizzata).

Per richiedere esplicitamente una certa dimensione dei metadati, utilizzare l'opzione <code>--metadatasize</code>:

{{RootCmd|lvcreate -L 150M --poolmetadatasize 2M --type thin-pool --thinpool thin_pool vg0}}

Per via che il metadata viene aggiunto alla vasca sottile, la via migliore di utilizzare tutta la dimensione disponibile in un gruppo di volumi per un volume logico, non funziona (vedere LVM bug [https://bugzilla.redhat.com/show_bug.cgi?id=812726|812726]):

{{RootCmd|lvcreate -l 100%FREE --type thin-pool --thinpool thin_pool vg0|output=<pre>
Insufficient suitable allocatable extents for logical volume thin_pool: 549 more required
</pre>}}

Si noti che la vasca sottile non ha un nodo del dispositivo associato come altri LV.

==== Creazione di un volume logico sottile ====

Un "volume logico sottile" è un volume logico all'interno della vasca sottile (che è essa stessa un volume logico). Come i volumi logici sottili sono "scarsi", una dimensione virtuale invece di una dimensione fisica è specificata utilizzando l'opzione <code>-V</code> :

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -n lvol1}}

In questo esempio, il volume logico (sottile) "lvol1" è esposto come dispositivo da 300MB di dimensione, anche se la vasca sottostante contiene solo 150MB di memoria reale allocata.

E' anche possibile creare sia la vasca sottile che il volume logico all'interno della vasca sottile con un unico comando:

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -L150M -n lvol1}}

==== Elencare vasche sottili e volumi logici sottili ====

Le vasche sottili e i volumi logici sottili sono tipologie speciali di volumi logici, e come tali sono visualizzati tramite il comando {{c|lvdisplay}}. Il comando {{c|lvscan}} individuerà anche questi volumi logici.

==== Estendere una vasca sottile ====

{{Warning|Come per LVM2 2.02.89, la dimensione del metadata relativo alla vasca sottile non può essere ampliata, essa è fissata al momento della creazione}}

La vasca sottile è ampliata come un volume logico non sottile utilizzando {{c|lvextend}}. Per esempio:

{{RootCmd|lvextend -L500M vg0/thin_pool}}

==== Estendere un volume logico sottile ====

Un volume logico sottile è ampliato regolarmente proprio come un volume logico sottile:

{{RootCmd|lvextend -L1G vg0/lvol1}}

Notare che il comando {{c|lvextend}} utilizza l'opzione <code>-L</code> (o <code>-l</code> se si utilizzano i conteggi estesi) e non un'opzione di "dimensione virtuale" come utilizzata durante la creazione. 

==== Ridurre una vasca sottile ====

Attualmente, LVM non può ridurre la dimensione della vasca sottile. Vedere il bug LVM [https://bugzilla.redhat.com/show_bug.cgi?id=812731|812731].

==== Ridurre un volume logico sottile ====

I volumi logici sottili sono ridotti regolarmente proprio come i volumi logici.

Per esempio:
{{RootCmd|lvreduce -L300M vg0/lvol1l}}

Notare che il comando {{c|lvreduce}} utilizza l'opzione <code>-L</code> (o <code>-l</code> se si utilizzano i conteggi estesi) e non un opzione di "dimensione virtuale" come utilizzata durante la creazione.

==== Rimuovere vasche sottili ====

Le vasche sottili non possono essere rimosse fino a che tutti i volumi logici in esse contenuti non vengono rimossi.

Quando una vasca sottile non serve più a nessun volume logico, essa può essere rimossa attraverso il comando {{c|lvremove}}:

{{RootCmd|lvremove vg0/thin_pool}}

=== LVM2 istantanee e istantanee sottili ===

Un'istantanea è un volume logico che agiscecome copia di un altro volume logico. Essa visualizza lo stato del volume logico originale al tempo della creazione dell'istantanea.

{{Warning|Poichè il volume dell'istantanea logica ottiene la stessa "LABEL" e "UUID" del filesystem, assicurarsi che il file {{Path|/etc/fstab}} o l'initramfs '''non''' contengano annotazioni per questi filesystems utilizzando la sintassi <code>LABEL{{=}}</code> o <code>UUID{{=}}</code>. Altrimenti si potrebbe finire col montare l'istantanea invece del volume logico originale.}}

==== Creazione di un'istantanea di un volume logico ====

Un'istantanea di un volume logico viene creata utilizzando l'opzione <code>-s</code> di {{c|lvcreate}}. L'istantanea di un volume logico è sempre memoria allocata come "registro" LVM, tutte le variazioni sono fatte dal volume logico originale e questi cambiamenti vengono memorizzati nella memoria allocata per l'istantanea. LVM inizierà dal volume logico originale dopodichè controllerà tutte le variazioni registrate, "annullando" le modifiche prima di mostrare il risultato per l'utente.

L'istantanea del volume logico, d'ora in poi, "cresce" al tasso che le modifiche vengono fatte sul volume logico originale. Quando la memoria allocata per l'istantanea è utilizzata completamente, l'istantanea sarà rimossa automaticamente dal sistema.

{{RootCmd|lvcreate -l 10%VG -s -n 20140412_lvol1 /dev/vg0/lvol1}}

L'esempio di sopra crea un'istantanea di volume logico chiamata "20140412_lvol1", basata sul volume logico "lvol1" nel gruppo di volume "vg0". Essa utilizza il 10% dello spazio (estensioni reali) allocato dal gruppo di volume.

==== Accedere ad un'istantanea di volume logico ====

Le istantanee dei volumi logici possono essere montate come volumi logici normali. Esse non sono nemmeno limitate a operazioni di sola lettura - è possibile modificare le istantanee e quindi utilizzarle per testare cose, tipo provare variazioni prima di effettuarle realmente su un file system di "produzione".

Finché esistono istantanee di volumi logici, il volume logico normale/originale non può essere ridotto di dimensioni e non può essere rimosso.

==== Istantanee sottili LVM ====

{{Note|Una istantanea sottile può essere presa solo su una vasca sottile per un volume logico sottile. Il bersaglio dispositivo mappatore sottile supporta istantanee sottili di sola lettura dei volumi logici non-sottili, ma l'LVM2 non le supporta. Tuttavia, è possibile creare una regolare istantanea di volume logico (non-sottile) di un volume logico sottile.}}

Per creare una istantanea sottile, il comando {{c|lvcreate}} viene utilizzato con l'opzione <code>-s</code>. Nessuna indicazione di dimensione deve essere trasmessa:

{{RootCmd|lvcreate -s -n 20140413_lvol1 /dev/vg0/lvol1}}

Le istantanee sottili del volume logico hanno la stessa dimensione del loro volume logico sottile originale, ed utilizzano un'allocazione fisica di 0 proprio come tutti gli altri volumi logici. 

{{Important|Se viene specificata l'opzione ''-l'' o ''-L'', l'istantanea verrà ancora creata, ma l'istantanea risultante sarà un'istantanea regolare, non un'istantanea sottile.}}

E' possibile anche ottenere istantanee di istantanee:

{{RootCmd|lvcreate -s -n 1_20140413_lvol1 /dev/vg0/20140413_lvol1}}

Le istantanee sottili hanno vari vantaggi rispetto alle istantanee regolari. Primo, le istantanee sottili sono indipendenti dal loro volume logico originale una volta create. Il volume logico originale può essere ridotto o cancellato senza influenzare l'istantanea. Secondo, l'istantanea sottile può essere efficacemente creata ricorsivamente (istantanea di un'istantanea) senza il "concatenamento" globale di regolari istantanee LVM ricorsive.

==== Riportare indietro allo stato di istantanea ====

Per riportare indietro il volume logico alla versione dell'istantanea, utilizzare il seguente comando:

{{RootCmd|lvconvert --merge /dev/vg0/20140413_lvol1}}

Dovrebbe impiegarci una coppia di minuti, dipende dalla dimensione del volume. Prego notare che il riportare indietro si verificherà solo se il volume logico genitore sarà offline. Quindi un riavvio potrebbe essere necessario.

{{Important|L'istantanea scomparirà e questa variazione non è reversibile}}

==== Riportare indietro le istantanee sottili ====

Per i volumi sottili, {{c|lvconvert --merge}} non funziona. Invece, bisogna cancellare il volume logico originale e rinominare l'istantanea:

{{RootCmd|umount /dev/vg0/lvol1
|lvremove /dev/vg0/lvol1
|lvrename vg0/20140413_lvol1 lvol1}}

=== Diversi metodi di allocazione della memoria ===

LVM supporta diversi metodi di allocazione di memoria:
* Volumi lineari (che è di default);
* Volumi mirroring (in una configurazione pressappoco attivo/standby);
* Striping (RAID0);
* Volumi mirroring (RAID1 - che è più una configurazione attivo/attivo);
* Striping con parità (RAID4  e RAID5);
* Striping con doppia parità (RAID6);
* Striping e mirroring (RAID10).

==== Volumi lineari ====

I volumi lineari sono il tipo più comune di volumi LVM. LVM tenterà di allocare il volume logico per essere fisicamente il più contiguo possibile. Se questo è un volume fisico abbastanza grande da includere l'intero volume logico, LVM lo allocherà là, altrimenti lo frammenterà nel minor numero di pezzi possibile.

I comandi introdotti in precedenza per creare gruppi di volumi e volumi logici creano anche volumi lineari.

Visto che i volumi lineari non hanno richieste particolari, essi sono facili da manipolare e possono essere ridimensionati e riallocati a volontà. Se un volume logico è allocato attraverso multipli volumi fisici, e ogni volume fisico diventa non più disponibile, tale volume logico non può essere avviato più e sarà inutilizzabile.

==== Volumi Mirrored ====

LVM supporta i volumi "mirrored" (rispecchiati), i quali forniscono una tolleranza di errore in caso di guasto del disco. A differenza di RAID 1, non vi è alcun miglioramento delle prestazioni - tutte le letture e le scritture sono consegnate ad un solo lato del "mirror" (specchio).

Per tenere traccia dello stato del mirror, LVM richiede un "log". E' raccomandato (e spesso anche obbligatorio) posizionare questo log su un volume fisico che non contiene nessuno dei volumi logici  in mirroring. Questi sono tre tipi di logs che possono essere utilizzati per i mirrors:

# '''Disk''' è il tipo di log predefinito. Tutte le variazioni fatte sono registrate su estensioni extra metadata, che vengono gestite da LVM. Se il dispositivo fallisce, le variazioni sono mantenute nel log fino a che il mirror non viene ripristinato nuovamente.
# '''Mirror''' i logs sono '''disk''' logs i quali sono loro stessi in mirroring. 
# '''Core''' i logs mirror logs registra lo stato del mirror solo in memoria. LVM dovrà ricostruire il mirror ogni volta che è attivato. Questa tipologia è utile per i mirrors temporanei.

Per creare un volume logico con un singolo mirror, inserire l'opzione "-m 1" (per selezionare il mirroring standard) con il codice opzionale <code>--mirrorlog</code> per selezionare un particolare tipo di log:

{{RootCmd|lvcreate -m 1 --mirrorlog mirror -l 40%VG --nosync -n lvol1 vg0}}

L'opzione "-m 1" dice a LVM di creare un (addizionale) mirror, quindi richiede 2 volumi fisici. L'opzione <code>--nosync</code> è un'ottimizzazione - senza di essa LVM proverà a sincronizzare il mirror copiando i settori vuoti da un volume logico ad un altro.

E' possibile creare un mirror di un volume logico esistente:

{{RootCmd|lvconvert -m 1 -b vg0/lvol1}}

L'opzione <code>-b</code> fa la conversione in background visto che questo può richiedere molto tempo.

Per rimuovere un mirror, impostare il numero di mirror (quello precedente) da 0:

{{RootCmd|lvconvert -m0 vg0/lvol1}}

Se parte di un mirror non è disponibile (generalmente perchè il disco contenente il volume fisico è danneggiato), il gruppo di volumi dovrà essere portato in modalità degraded:

{{RootCmd|vgchange -ay --partial vg0}}

Nella prima scrittura, LVM noterà il guasto del mirror. Il procedimento di default ("remove") è quello di ridurre automaticamente il mirror in base al numero di parti disponibili. Un mirror a 3-parti con un volume fisico mancante verrà ridotto a mirror a 2-parti; un mirror a 2-parti sarà ridotto a volume lineare regolare. Se il guasto è solo transitorio, e il volume fisico mancante ritorna dopo che LVM ha guastato il mirror, i volumi logici mirrored dovranno essere ricreati su di esso. 

Per recuperare il mirror, il volume fisico guasto deve essere rimosso dal gruppo di volumi, e va aggiunto un volume fisico sostitutivo (o se il gruppo di volumi ha un volume fisico libero, il mirror può essere ricreato su questo). Ora il mirror può essere ricreato con il comando {{c|lvconvert}} e il vecchio volume fisico può essere rimosso dal gruppo di volumi:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert -b -m 1 --mirrorlog disk vg0/lvol1
|vgreduce --removemissing vg0}}

E' possibile che LVM crei il mirror con estensioni disponibili in volumi fisici differenti se da un lato non riesce. Per realizzare questo, impostare <code>mirror_image_fault_policy</code> di "allocate" su {{Path|lvm.conf}}.

==== Mirrors sottili ====

Non è ancora possibile creare una vasca sottile mirror o un volume sottile mirror. E' possibile creare una vasca sottile mirror con la creazione di un volume logico mirror normale e convertire il volume logico di una vasca sottile con il comando {{c|lvconvert}}. 2 volumi logici sono richiesti: uno per la vasca sottile e uno per il metadata sottile; il processo di conversione li unirà in un singolo volume logico.

{{Warning|E' richiesta la versione 2.02.98 o successive di LVM per far funzionare tutto correttamente. Le versioni precedenti non sono in grado di fare ciò oppure danneggeranno e corromperanno il gruppo di volumi. Inoltre, la conversione di un mirror in vasca sottile '''distrugge''' tutti i dati esistenti nel mirror!}}

{{RootCmd|lvcreate -m 1 --mirrorlog mirrored -l40%VG -n thin_pool vg0
|lvcreate -m 1 --mirrorlog mirrored -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== Striping (RAID0) ====

Invece di un volume lineare, dove più volumi fisici contigui vengono aggiunti, è possibile creare un volume ''striped'' o ''RAID 0'' per migliorare le prestazioni. Questo alternerà le allocazioni di memoria attraverso i volumi fisici disponibili.

Per creare un volume striped sopra tre volumi fisici:

{{RootCmd|lvcreate -i 3 -l 20%VG -n lvol1_stripe vg0|output=<pre>
Using default stripesize 64.00 KiB
</pre>}}

L'opzione <code>-i</code> indica su quanti volumi fisici lo striping dovrebbe essere fatto.

E' possibile fare il mirror di una serie di stripe. Le opzioni <code>-i</code> e <code>-m</code> possono essere combinate per creare un mirror striped:

{{RootCmd|lvcreate -i 2 -m 1 -l 10%VG vg0}}

Questo crea 2 serie di volumi fisici stripe e ci rispecchia 2 differenti volumi fisici, per un totale di 4 volumi fisici. Una serie di stripe esistente può essere rispecchiata con {{c|lvconvert}}.

Una vasca sottile può essere striped come qualsiasi altro volume logico. Tutti i volumi sottili creati dalla vasca ereditano queste impostazioni - tali impostazioni non vanno specificate manualmente quando si crea un volume sottile.

Non è possibile creare lo stripe di un volume esistente, nè rimodellare gli stripes attraverso più o meno volumi fisici, nè convertire a differente volume RADI livello/lineare. Una serie di stripe possono essere rispechiati (mirrored). E' possibile estendere una serie di stripe attraverso volumi fisici addizionali, ma questi devono essere aggiunti in multipli delle serie di stripe originali (i quali efficacemente e linearmente aggiungeranno una nuova serie di stripe).

==== Mirroring (RAID) ====

A differenza di RAID0, il quale è striping, RAID1 è mirroring, ma implementato defferentemente dall'originale mirror LVM. Sotto RAID1, le letture sono distribuite su volumi fisici, migliorando le prestazioni. I guasti del mirror RAID1 non causano blocchi I/O perchè LVM non lo corrompe in scrittura.

In ogni posizione in cui il mirror LVM può essere utilizzato, un mirror RAID1 può essere usato nella stessa posizione. E' possibile che LVM crea dei mirrors RAID1 invece di mirrors regolari impostando implicitamente ''mirror_segtype_default'' di ''raid1'' su {{Path|lvm.conf}}.

{{Warning|Il mirroring LVM RAID1 non è ancora supportato da GRUB. Se si applica al volume LVM che contiene il kernel/initramfs (il volume di 'avvio'), il sistema sarà inavviabile. (Una correzione ci sarà dalla prossima versione di GRUB. Vedere GRUB bug [http://savannah.gnu.org/bugs/?44534 #44534] for details.)}}

Per creare un volume logico con un mirror singolo:

{{RootCmd|lvcreate -m 1 --type raid1 -l 40%VG --nosync -n lvm_raid1 vg0}}

Notare la differenza per creare un mirror: Qui non è specificato un "mirrorlog", perchè il volume logico RAID1 non ha un mirror log esplicito - esso è integrato nel volume logico.

E' possibile convertire un volume logico esistente a RAID1:

{{RootCmd|lvconvert -m 1 --type raid1 -b vg0/lvol1}}

To remove a RAID1 mirror, set the number of mirrors to 0:

{{RootCmd|lvconvert -m0 vg0/lvm_raid1}}

If part of the RAID1 is unavailable (usually because the disk containing the physical volume has failed), the volume group will need to be brought up in degraded mode:

{{RootCmd|vgchange -ay --partial vg0}}

Unlike an LVM mirror, writing does NOT break the mirroring. If the failure is only transient, and the missing physical volume returns, LVM will resync the mirror by copying cover the out-of-date segments instead of the entire logical volume. If the failure is permanent, then the failed physical volume needs to be removed from the volume group, and a replacement physical volume needs to be added (or if the volume group has a free physical volume, it can be created on a different PV). The mirror can then be repaired with {{c|lvconvert}}, and the old physical volume can be removed from the volume group:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert --repair -b vg0/lvm_raid1
|vgreduce --removemissing vg0}}

==== Thin RAID1 ====

It is not (yet) possible to create a RAID1 thin pool or thin volume. It is possible to create a RAID1 thin pool by creating a normal mirrored logical volume and then converting the logical volume to a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will then merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, conversion of a RAID1 into a thin pool '''destroys''' all existing data in the mirror!}}

{{RootCmd|lvcreate -m 1 --type raid1 -l40%VG -n thin_pool vg0
|lvcreate -m 1 --type raid1 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== Striping with parity (RAID4 and RAID5) ====

{{Note|Striping with parity requires at least 3 physical volumes.}}

RAID0 is not fault-tolerant - if any of the physical volumes fail then the logical volume is unusable. By adding a parity stripe to RAID0 the logical volume can still function if a physical volume is missing. A new physical volume can then be added to restore fault tolerance.

Stripsets with parity come in 2 flavors: RAID4 and RAID5. Under RAID4, all the parity stripes are stored on the same physical volume. This can become a bottleneck because all writes hit that physical volume, and it gets worse the more physical volumes are in the array. With RAID5, the parity data is distributed evenly across the physical volumes so none of them become a bottleneck. For that reason, RAID4 is rare and is considered obsolete/historical. In practice, all stripesets with parity are RAID5.

{{RootCmd|lvcreate --type raid5 -l 20%VG -i 2 -n lvm_raid5 vg0}}

Only the data physical volumes are specified with -i, LVM adds one to it automatically for the parity. So for a 3 physical volume RAID5, ''-i 2'' is passed on and not ''-i 3''.

When a physical volume fails, then the volume group will need to be brought up in degraded mode:

{{RootCmd|vgchange -ay --partial vg0}}

The volume will work normally at this point, however this degrades the array to RAID0 until a replacement physical volume is added. Performance is unlikely to be affected while the array is degraded - although it does need to recompute its missing data via parity, it only requires simple XOR for the parity block with the remaining data. The overhead is negligible compared to the disk I/O.

To repair the RAID5:

{{RootCmd|lvconvert --repair vg0/lvm_raid5
|vgreduce --removemissing vg0}}

It is possible to replace a still working physical volume in RAID5 as well:

{{RootCmd|lvconvert --replace /dev/sdb1 vg0/lvm_raid5
|vgreduce vg0 /dev/sdb1}}

The same restrictions of stripe sets apply to stripe sets with parity as well: it is not possible to enable striping with parity on an existing volume, nor reshape the stripes with parity across more/less physical volumes, nor to convert to a different RAID level/linear volume. A stripe set with parity can be mirrored. It is possible to extend a stripe set with parity across additional physical volumes, but they must be added in multiples of the original stripe set with parity (which will effectively linearly append a new stripe set with parity).

==== Thin RAID5 logical volumes ====

It is not (yet) possible to create stripe set with parity (RAID5) thin pools or thin logical volumes. It is possible to create a RAID5 thin pool by creating a normal RAID5 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, coversion of a RAID5 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid5 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid5 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== Striping with double parity (RAID6) ====

{{Note|RAID6 requires at least 5 physical volumes.}}

RAID6 is similar to RAID5, however RAID6 can survive up to '''two''' physical volume failures, thus offering more fault tolerance than RAID5 at the expense of extra physical volumes. 

{{RootCmd|lvcreate --type raid6 -l 20%VG -i 3 -n lvm_raid6 vg00}}

Like RAID5, the <code>-i</code> option is used to specify the number of physical volumes to stripe, excluding the 2 physical volumes for parity. So for a 5 physical volume RAID6, pass on <code>-i 3</code> and not <code>-i 5</code>.

Recovery for RAID6 is the same as RAID5.

{{Note|Unlike RAID5 where parity block is cheap to recompute vs disk I/O, this is only half true in RAID6. RAID6 uses 2 parity stripes: One stripe is computed the same way as RAID5 (simple XOR). The second parity stripe is much harder to compute - see [https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf|raid6 (pdf)] for more information.}}

==== Thin RAID6 logical volumes ====

It is not (yet) possible to create a RAID6 thin pool or thin volumes. It is possible to create a RAID6 thin pool by creating a normal RAID6 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, conversion of a RAID6 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid6 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid6 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== LVM RAID10 ====

{{Note|RAID10 requires at least 4 physical volumes. Also LVM syntax requires the number of physical volumes be multiple of the numbers stripes and mirror, even though RAID10 format does not}}

RAID10 is a combination of RAID0 and RAID1. It is more powerful than RAID0+RAID1 as the mirroring is done at the stripe level instead of the logical volume level, and therefore the layout doesn't need to be symmetric. A RAID10 volume can tolerate at least a single missing physical volume, and possibly more.

{{Note|LVM currently limits RAID10 to a single mirror.}}

{{RootCmd|lvcreate --type raid10 -l 1020 -i 2 -m 1 --nosync -n lvm_raid10 vg0}}

Both the <code>-i</code> and <code>-m</code> options are specified: <code>-i</code> is the number of stripes and <code>-m</code> is the number of mirrors. Two stripes and 1 mirror requires 4 physical volumes.

==== Thin RAID10 ====

It is not (yet) possible to create a RAID10 thin pool or thin volumes. It is possible to create a RAID10 thin pool by creating a normal RAID10 logical volume and then converting the logical volume into a thin pool with {{c|lvconvert}}. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.
 
{{Warning|Conversion of a RAID10 logical volume into a thin pool '''destroys''' all existing data in the logical volume!}}

{{RootCmd|lvcreate -i 2 -m 1 --type raid10 -l 1012 -n thin_pool vg0
|lvcreate -i 2 -m 1 --type raid10 -l 6 -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

== Experimenting with LVM ==

It is possible to experiment with LVM without using real storage devices. To accomplish this, loopback devices are created.

First make sure to have the loopback module loaded. 

{{RootCmd|modprobe -r loop && modprobe loop max_part{{=}}63}}

{{Note|If loopback support is built into the kernel, then use <code>loop.max_part{{=}}63</code> as boot option.}}

Next configure LVM to not use [[udev]] to scan for devices:

{{FileBox|filename=/etc/lvm/lvm.conf|title=Disabling udev in LVM config|lang=ini|1=
obtain_device_list_from_udev = 0
}}

{{Important|This is for testing only, make sure to change the setting back when dealing with real devices since it is much faster to use udev!}}

Create some image files which will become the storage devices. The next example uses five files for a total of about ~10GB of real hard drive space:

{{RootCmd|mkdir /var/lib/lvm_img
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm0.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm1.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm2.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm3.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm4.img bs{{=}}1024 seek{{=}}2097152}}

Check which loopback devices are available:

{{RootCmd|losetup -a}}

Assuming all loopback devices are available, next create the devices:

{{RootCmd|losetup /dev/loop0 /var/lib/lvm_img/lvm0.img
|losetup /dev/loop1 /var/lib/lvm_img/lvm1.img
|losetup /dev/loop2 /var/lib/lvm_img/lvm2.img
|losetup /dev/loop3 /var/lib/lvm_img/lvm3.img
|losetup /dev/loop4 /var/lib/lvm_img/lvm4.img}}

The {{Path|/dev/loop[0-4]}} devices are now available to use as any other hard drive in the system (and thus be perfect for physical volumes).

{{Note|On the next reboot, all the loopback devices will be released and the folder {{Path|/var/lib/lvm_img}} can be deleted.}}

== Troubleshooting ==

LVM has a few features that already provide some level of redundancy. However, there are situations where it is possible to restore lost physical volumes or logical volumes.

=== vgcfgrestore utility ===

By default, on any change to a LVM physical volume, volume group, or logical volume, LVM2 create a backup file of the metadata in {{Path|/etc/lvm/archive}}. These files can be used to recover from an accidental change (like deleting the wrong logical volume). LVM also keeps a backup copy of the most recent metadata in {{Path|/etc/lvm/backup}}. These can be used to restore metadata to a replacement disk, or repair corrupted metadata.

To see what states of the volume group are available to be restored (partial output to improve readability):

{{RootCmd|vgcfgrestore --list vg00|output=<pre>
  File:		/etc/lvm/archive/vg0_00042-302371184.vg
  VG name:    	vg0
  Description:	Created *before* executing 'lvremove vg0/lvm_raid1'
  Backup Time:	Sat Jul 13 01:41:32 201
</pre>}}

==== Recovering an accidentally deleted logical volume ====

Assuming the logical volume ''lvm_raid1'' was accidentally removed from volume group ''vg0'', it is possible to recover it as follows:

{{RootCmd|vgcfgrestore -f /etc/lvm/archive/vg0_00042-302371184.vg vg0}}

{{Important|vgcfgrestore only restores LVM metadata, ''not'' the data inside the logical volume. However pvremove, vgremove, and lvremove only wipe metadata, leaving any data intact. If <code>issue_discards</code> is set in {{Path|/etc/lvm/lvm.conf}} though, then these command ''are'' destructive to data.}}

==== Replacing a failed physical volume ====

It possible to do a true "replace" and recreate the metadata on the new physical volume to be the same as the old physical volume:

{{RootCmd|vgdisplay --partial --verbose|output=<pre>
  --- Physical volumes ---
  PV Name               /dev/loop0     
  PV UUID               iLdp2U-GX3X-W2PY-aSlX-AVE9-7zVC-Cjr5VU
  PV Status             allocatable
  Total PE / Free PE    511 / 102
  
  PV Name               unknown device     
  PV UUID               T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY
  PV Status             allocatable
  Total PE / Free PE    511 / 102
</pre>}}

The important line here is the UUID "unknown device". 

{{RootCmd|pvcreate --uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY --restorefile /etc/lvm/backup/vg0 /dev/loop1|output=<pre>
  Couldn't find device with uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY.
  Physical volume "/dev/loop1" successfully created</pre>}}

This recreates the physical volume metadata, but not the missing logical volume or volume group data on the physical volume.

{{RootCmd|vgcfgrestore -f /etc/lvm/backup/vg0 vg0|output=<pre>
  Restored volume group vg0
</pre>}}

This now reconstructs all the missing metadata on the physical volume, including the logical volume and volume group data. However it doesn't restore the data, so the mirror is out of sync.

{{RootCmd|vgchange -ay vg0|output=<pre>
  device-mapper: reload ioctl on  failed: Invalid argument
  1 logical volume(s) in volume group "vg0" now active
</pre>}}

{{RootCmd|lvchange --resync vg0/lvm_raid1|output=<pre>
Do you really want to deactivate logical volume lvm_raid1 to resync it? [y/n]: y
</pre>}}

This will resync the mirror. This works with RAID 4,5 and 6 as well.

=== Deactivating a logical volume ===

It is possible to deactivate a logical volume with the following command:

{{RootCmd|umount /dev/vg0/lvol1
|lvchange -a n /dev/vg0/lvol1}}

It is not possible to mount the logical volume anywhere before it gets reactivated:

{{RootCmd|lvchange -a y /dev/vg0/lvol1}}

== External resources ==

* [http://sourceware.org/lvm2/ LVM2 sourceware.org]
* [http://tldp.org/HOWTO/LVM-HOWTO/ LVM tldp.org]
* [http://sources.redhat.com/lvm2/wiki/ LVM2 Wiki redhat.com]


[[Category:Core system]]
