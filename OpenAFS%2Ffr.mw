<languages />

Ce guide explique comment installer un serveur et un cilent OpenAFS sur Gentoo Linux.

== Vue d'ensemble ==

=== À propos de ce document ===

Ce document vous guide à travers toutes les étapes nécessaires pour installer un serveur OpenAFS sur Gentoo Linux. Certaines parties de ce document sont issues de la FAQ AFS et du ''AFS Quick Beginnings guide'' d'IBM. Il ne sert à rien de réinventer la roue. 

=== Qu'est-ce qu'AFS ? ===

AFS est un système de fichiers distribué qui permet à des  hôtes coopérants (clients et serveurs) de partager efficacement des ressources de systèmes de fichiers à travers à la fois, le réseau local et des réseaux étendus. Les clients détiennent un cache pour les objets d'usage fréquent (fichiers), pour accélérer leur accès à ces derniers. 

AFS est basé sur un système de fichiers distribué,  développé à l'origine par l'''Information Technology Center de l'université'' de Carnegie-Mellon, appelé ''Andrew File System''. ''Andrew'' était le nom d'un projet de recherche de l'université de Carnégie-Mellon, en l'honneur de ses  fondateurs. Une fois que ''Transarc'' fut créé et que AFS devint un produit, le ''Andrew'' fut abandonné pour indiquer que AFS avait dépassé les limites du projet et était devenu un système de fichiers de qualité et un produit exportable. Néanmoins, il y avait un nombre de cellules existantes qui utilisaient /afs comme racine de leur système de fichiers. À cette époque, changer la racine d'un système de fichiers était loin d'être une entreprise triviale. Aussi, pour éviter aux  premiers site AFS d'avoir à renommer leur systèmes de fichiers, AFS fut retenu, à la fois,  comme le nom du système de fichier  et comme le nom de  sa racine. 

=== Qu'est-ce qu'une cellule  AFS ? ===

Une cellule AFS est un collection de serveurs administrativement regroupés, qui présente un système de fichiers unique et cohésif. Typiquement, une cellule AFS est un ensemble d'hôtes qui utilisent le même nom de domaine (par exemple gentoo.org). Les utilisateurs se connectent par des stations de travail clientes AFS qui demandent des informations et des fichiers à une cellules de serveurs au nom des utilisateurs. Les utilisateurs ne savent pas sur quel serveur le fichier auquel ils accèdent se trouve. Il ne se rendent même pas compte si un serveur est situé dans la pièce d'à coté dans la mesure ou chacun des volumes peut être  répliqué et déplacé vers un autre serveur sans que les utilisateurs en soient avertis. Les fichiers sont toujours accessibles. 

=== Quels sont les bénéfices de l'utilisation  d'AFS ? ===

Les principales forces de AFS sont : ses possibilités de cache ( du coté client, typiquement de 100 Mo à 1 Go), ses fonctionnalités de sécurité (basées sur Kerberos 4, listes de contrôle d'accès), sa simplicité d'adressage (vous n'avez qu'un seul système de fichiers), sa modulabilité (vous pouvez rajoute des serveurs à votre cellule en fonction de vos besoins), ses protocoles de communication. 

=== Où puis-je trouver plus d'information ? ===

Lisez les [http://www.angelfire.com/hi/plutonic/afs-faq.html FAQ AFS] . 

La page d'accueil de OpenAFS est à  [http://www.openafs.org www.openafs.org] . 

AFS a été développé à l'origine par Transarc qui est maintenant détenu par IBM. Depuis avril 2005, il a été retiré du catalogue des produits d'IBM. 

=== Comment résoudre les problèmes ? ===

OpenAFS possède des fonctions de journalisation importantes. Cependant, par défaut, il tient ses propres journaux au lieu d'utiliser les fonctions de journalisation de votre système. Pour que le serveur utilise les fonctions de journalisation du  système,  utilisez l'option <code>-syslog</code> pour toutes les commandes <code>bos</code>. 

== Mise à jour depuis une versions antérieure ==

=== Introduction ===

Cette section vous guide dans le processus de mise à jour d'une installation OpenAFS existante vers une version d'OpenAFS 1.4.0 ou postérieure (ou 1.2.x partant de 1.2.13. Cette dernière ne sera pas prise en compte spécifiquement car la majorité des gens désireront 1.4 pour disposer d'une prise en charge de a.o.linux-2.6, de fichiers de grande taille et de la résolution des bogues). 

Si vous disposez d'une installation fraîche de la version 1.4 d'OpenAFS, vous pouvez sans risque sauter ce chapitre. Néanmoins, si vous mettez à jour depuis une version antérieure, nous vous recommandons fortement de suivre les conseils des sections suivantes. Le script de transition dans l'ebuild est conçu pour vous assister dans la mise à jour rapide et le redémarrage. Notez que :il n'effacera pas (pour des raisons de sécurité) les fichiers de configuration et les scripts de démarrage aux anciens emplacements; ne changera pas automatiquement  votre configuration de démarrage pour utiliser les nouveaux scripts, etc. Si vous n'êtes pas encore convaincu, l'utilisation d'un ancien module du noyau OpenAFS avec le système de binaires à jour, peut rendre votre noyau imprévisible. C'est pourquoi vous devez continuer à lire pour une transition claire et facile. 


{{Note|Ce chapitre a été écrit en tenant compte de différentes configurations du système. Néanmoins, il est toujours possible que, en fonction des ajustements spécifiques qu'un utilisateur a pu apporter à sa configuration, sa situtation particulière ne soit pas décrite ici. Un utilisateur suffisamment assuré pour modifier sa configuration devrait être assez expérimenté pour mettre en œuvre les observations émises quand c'est approprié. À l'inverse, un utilisateur qui a très peu modifié son système en dehors de l'installation de l'ebuild précédent, pourra ignorer la plupart des avertissements donnés par la suite.}}


=== Différences avec les versions précédentes ===

Traditionnellement, OpenAFS a utilisé les mêmes conventions de chemin qu'IBM TransArc labs, jusqu'à ce que le code choisisse un embranchement différent. C'est compréhensible que la configuration de l'ancien AFS continue à utiliser ces conventions héritées. Des configuration plus récentes se conforment à FHS en utilisant des emplacements standards (comme dans beaucoup de distributions Linux). La table suivante est une compilation du script ''configure'' et du fichier README qui accompagne l'archive de distribution d'OpenAFS : 

{| class="wikitable" style="text-align: left;" 
|- 
! Répertoire
! But
! Mode Transarc
! Mode par défaut
! traduction pour  Gentoo
|- 
| viceetcdir
| Configuration du client
| /usr/vice/etc
| $(sysconfdir)/openafs
| /etc/openafs
|- 
| unnamed
| Binaires client 
| unspecified
| $(bindir)
| /usr/bin
|- 
| afsconfdir
| Configuration du serveur
| /usr/afs/etc
| $(sysconfdir)/openafs/server
| /etc/openafs/server
|- 
| afssrvdir
| Binaires serveur internes
| /usr/afs/bin (servers)
| $(libexecdir)/openafs
| /usr/libexec/openafs
|- 
| afslocaldir
| État du serveur
| /usr/afs/local
| $(localstatedir)/openafs
| /var/lib/openafs
|- 
| afsdbdir
| Aut/liste des serveurs/... bases de données
| /usr/afs/db
| $(localstatedir)/openafs/db
| /var/lib/openafs/db
|- 
| afslogdir
| Fichiers de journalisation
| /usr/afs/logs
| $(localstatedir)/openafs/logs
| /var/lib/openafs/logs
|- 
| afsbosconfig
| Configuration supervisatrice
| $(afslocaldir)/BosConfig
| $(afsconfdir)/BosConfig
| /etc/openafs/BosConfig
|-
|}

Il y a quelques autres curiosités, comme les binaires placés dans {{Path|/usr/vice/etc}}  pour le mode Transarc, mais cette liste ne prétend pas être exhaustive. Elle est plutôt destinée à servir de référence pour la transition créatrice de dysfonctionnements de ces fichiers de configuration. 

En conséquence des changements de chemin, l'emplacement par défaut du cache de  disque a également été changé de {{Path|/usr/vice/cache}} en {{Path|/var/cache/openafs}} . 

Plus encore, le script d'initialisation a été éclaté en une partie ''client'' et une partie ''serveur''. Vous aviez pour habitude d'avoir {{Path|/etc/init.d/afs}}, mais maintenant vous avez finalement {{Path|/etc/init.d/openafs-client}} et {{Path|/etc/init.d/openafs-server}}. Par conséquent, le fichier de configuration {{Path|/etc/conf.d/afs}} a été éclaté en {{Path|/etc/conf.d/openafs-client}} et {{Path|/etc/conf.d/openafs-server}}. Les options dans {{Path|/etc/conf.d/openafs}} pour arrêter ou démarrer le client ou le serveur sont également devenues obsolètes. 

Un autre changement au script d'initialisation, c'est qu'il ne vérifie plus la configuration de votre cache de disque. L'ancien code requérait qu'une partition ext2 séparée soit montée sur {{Path|/usr/vice/cache}}. Cela occasionnait quelques problèmes : 

* Bien qu'il s'agisse d'une configuration très logique, votre cache n'a pas besoin d'être sur une partition séparée. Tant que vous assurez que la quantité de place spécifiée dans {{Path|/etc/openafs/cacheinfo}} est réellement disponible pour le cache de disque, tout va bien. Ainsi, il n'y a réellement pas de problème à ce que le cache se trouve sur votre partition ''root''. 
* Quelques personnes utilisent des liens symboliques pour pointer vers le cache de disque réel. Le script d'initialisation n'aime pas ça, parce qu'alors, l'emplacement de ce cache n'apparaît pas dans {{Path|/proc/mounts}} .
* De nos jours, beaucoup préfèrent ext3 à ext2. Les deux systèmes de fichiers sont valides pour une utilisation en cache de disque. Tout autre système de fichiers n'est pas pris en charge (par exemple, n'essayez pas reiserfs, vous obtiendriez un énorme avertissement , et pourriez vous attendre à des plantages par la suite).

=== Transition vers les nouveaux chemins  ===

Tout d'abord, l'installation d'une nouvelle version d'OpenAFS n'écraserait pas vous anciens fichiers de configuration. Le script est conçu pour ne  remplacer aucun fichier déjà présent sur le système. C'est pourquoi, même si vous avez une configuration complètement anarchique, avec un mélange d'anciens et de nouveaux emplacements, le script ne créera pas de problèmes supplémentaires. Par ailleurs, si un serveur OpenAFS en service est détecté, l'installation avortera, empêchant ainsi une possible corruption de base de données. 

Une mise en garde cependant -- il y a eu des ebuilds traînant sur Internet qui désactivent partiellement la protection que Gentoo place sur {{Path|/etc}}. Ces ebuils n'ont jamais été distribués par Gentoo. Vous devriez vérifier la variable <code>CONFIG_PROTECT_MASK</code>  dans la sortie de la commande suivante : 

{{RootCmd|emerge info {{!}} grep "CONFIG_PROTECT_MASK"|output=<pre>
CONFIG_PROTECT_MASK="/etc/gconf /etc/terminfo /etc/texmf/web2c /etc/env.d"
</pre>
}}

Bien que rien dans cet ebuild ne toucherait les fichiers dans  {{Path|/etc/afs}} , la mise à jour causerait la suppression de votre ancienne installation d'OpenAFS. Les fichiers dans <code>CONFIG_PROTECT_MASK</code> qui appartiennent à l'ancienne installation seraient supprimés également. 

Il devrait être clair à l'utilisateur expérimenté que, s'il a mis au point son système en ajoutant les liens symboliques à la main (par exemple  {{Path|/usr/afs/etc}} vers {{Path|/etc/openafs}} ), la nouvelle installation peut continuer à bien fonctionner en continuant à utiliser les anciens fichiers de configuration. Dans ce cas, il n'y aurait pas eu de réelle transition, et le nettoyage de l'ancienne installation résulterait dans une configuration cassée d'OpenAFS. 

Maintenant que vous savez ce qui ne se produira pas, vous voulez savoir quoi faire : 

* {{Path|/usr/afs/etc}} is copied to {{Path|/etc/openafs/server}} 
* {{Path|/usr/vice/etc}} is copied to {{Path|/etc/openafs}} 
* {{Path|/usr/afs/local}} is copied to {{Path|/var/lib/openafs}} 
* {{Path|/usr/afs/local/BosConfig}} is copied to {{Path|/etc/openafs/BosConfig}} , while replacing occurrences of {{Path|/usr/afs/bin/}} with {{Path|/usr/libexec/openafs}} , {{Path|/usr/afs/etc}} with {{Path|/etc/openafs/server}} and {{Path|/usr/afs/bin}} (without the / as previously) with {{Path|/usr/bin}} 
* {{Path|/usr/afs/db}} is copied to {{Path|/var/lib/openafs/db}} 
* The configuration file {{Path|/etc/conf.d/afs}} is copied to {{Path|/etc/conf.d/openafs-client}} , as all known old options were destined for client usage only.

=== La mise à jour elle-même ===

Ainsi vous n'avez pas réussi à configurer le  serveur OpenAFS ? Ou peut-être y êtes-vous parvenu, les sections précédentes vous ont informé sur ce qui va se passer, et vous êtes toujours décidé ? 

Allons-y alors ! 

Si vous avez un serveur qui tourne, arrêtez-le maintenant. 

{{RootCmd|/etc/init.d/afs stop}}

Et ensuite, faites la mise à jour elle-même. 

{{Emerge|openafs}}

=== Redémarrer OpenAFS ===

Si vous aviez un serveur OpenAFS en service, vous pourriez n'avoir pas été forcé à l'arrêter. C'est le moment de le faire maintenant. 

{{RootCmd|/etc/init.d/afs stop}}

Vous désirerez peut-être maintenir le temps d'arrêt à un minimum, c'est pourquoi vous pouvez redémarrer le serveur OpenAFS tout de suite. 

{{RootCmd|/etc/init.d/openafs-server start}}

Vous pouvez vérifier qu'il tourne correctement avec cette commande : 

{{RootCmd|/usr/bin/bos status localhost -localauth}}

Avant de redémarrer le client OpenAFS, prenez le temps de vérifier la configuration de votre cache. Elle est fixée dans {{Path|/etc/openafs/cacheinfo}} .  Pour redémarrer le client OpenAFS, entrez la commande suivante : 

{{RootCmd|/etc/init.d/openafs-client start}}

=== Nettoyage après coup  ===

Avant de procéder au nettoyage, assurez-vous que tout fonctionne correctement et que vous avez redémarré après la mise à jour (autrement, vous pourriez être toujours en train de fonctionner sur l'ancienne installation) 

{{Important|Assusez-vous que vous n'êtes pas en train d'utiliser  {{Path|/usr/vice/cache}} comme cache de disque si vous effacez {{Path|/usr/vice}} !!}}

Les répertoires suivants peuvent être retirés du système en toute sécurité. 

*  {{Path|/etc/afs}} 
*  {{Path|/usr/vice}} 
*  {{Path|/usr/afs}} 
*  {{Path|/usr/afsws}} 

Les fichiers suivants sont également inutiles : 

*  {{Path|/etc/init.d/afs}} 
*  {{Path|/etc/conf.d/afs}} 

{{RootCmd|tar czf /root/oldafs-backup.tgz /etc/afs /usr/vice /usr/afs /usr/afsws
|rm -R /etc/afs /usr/vice /usr/afs /usr/afsws
|rm /etc/init.d/afs /etc/conf.d/afs}}

Au cas où vous auriez au préalable utilisé ebuilds=openafs-1.2.13 ou =openafs-1.3.85, vous pourriez également avoir d'autres fichiers inutiles : 

* {{Path|/etc/init.d/afs-client}} 
* {{Path|/etc/init.d/afs-server}} 
* {{Path|/etc/conf.d/afs-client}} 
* {{Path|/etc/conf.d/afs-server}} 

=== Changements au script d'initialisation ===

Maintenant, la plupart des gens devraient avoir leur système configuré pour démarrer  le client et le serveur OpenAFS automatiquement au démarrage. Ceux qui ne pratiquent pas ainsi peuvent sauter cette section sans crainte. Si votre système est configuré pour les démarrer automatiquement, vous devriez revalider ceci car les noms des scripts d'initialisation ont changé. 

{{RootCmd|rc-update del afs default
|rc-update add openafs-client default
|rc-update add openafs-server default}}

Si vous aviez <code>=openafs-1.2.13</code> ou <code>=openafs-1.3.85</code> , vous devriez retirer {{Path|afs-client}} et {{Path|afs-server}} du niveau d'exécution par défaut, au lieu de {{Path|afs}} . 

=== Dépannage : que faire si la mise à jour automatique échoue  ===

Pas de panique ! Vous ne devriez pas avoir perdu de donnée ou de fichier de configuration. Aussi nous devons analyser la situation. Postez un rapport de bogue à [http://bugs.gentoo.org bugs.gentoo.org]  dans tous les cas, de préférence avec autant d'informations que possible. 

Si vous avez des problèmes avec le démarrage du client, ceci devrait vous aider à faire un diagnostic. 

* Exécutez <code>dmesg</code> . Normalement, le client y envoie des messages d'erreur.
* Vérifiez {{Path|/etc/openafs/cacheinfo}} . Il devrait être de la forme : /afs:{chemin vers le cache de disque}:{nombre de blocs pour le cache de disque}. Normallement, votre cache de disque devrait être situé à  {{Path|/var/cache/openafs}} .
* Vérifiez la sortie de <code>lsmod</code> . Vous devriez voir une ligne commençant par le mot openafs.
* <code>pgrep afsd</code> vous dira si openafs tourne ou pas
* <code>cat /proc/mounts</code> vous dira si {{Path|/afs}} a été monté.

Si vous rencontrez des problèmes pour démarrer le serveur, ces indices devraient vous aider : 

* <code>pgrep bosserver</code> devrait vous dire si le superviseur tourne ou pas. Si vous avez plus d'un superviseur en marche, alors quelque chose s'est mal passé. Dans un tel cas, vous devriez essayer un arrêt élégant du serveur OpenAFS server avec la commande <code>bos shutdown localhost -localauth -wait</code> , vérifiez-en le résultat avec la commande <code>bos status localhost -localauth</code> , tuez tous les processus de superviseur qui restent et, finalement, vérifiez si un process serveur quelconque est encore en marche  ( <code>ls /usr/libexec/openafs</code> pour en obtenir la liste). Après cela, faites <code>/etc/init.d/openafs-server zap</code> pour remettre à zéro le statut du serveur et  <code>/etc/init.d/openafs-server start</code> pour essayer de le relancer.
* Si vous utilisez le système de journalisation propre à OpenAFS (ce qui est la configuration par défaut), vérifiez {{Path|/var/lib/openafs/logs/*}} . Si vous utilisez la journalisation système, vérifiez ses journaux pour toute information utile.

== Documentation ==

=== Obtenir la documentation  AFS  ===

Vous pouvez vous procurer la documentation IBM originale. Elle est très bien écrite et vous devriez absolument la lire si vous devez administrer un serveur AFS. 

{{Emerge|app-doc/afsdoc}}

Vous avez également l'option d'utiliser la documentation délivrée avec OpenAFS. Elle est installée quand l'option <code>doc</code> de la variable USE est activée lors de l'installation d'OpenAFS. On peut la trouver dans {{Path|/usr/share/doc/openafs-*/}}. Au moment de l'écriture de cette page, la documentation était encore en préparation. Elle peut cependant vous renseigner sur de nouvelles fonctionnalités d'OpenAFS qui ne sont pas décrites dans la documentation originale d'IBM. 

== Installation du client ==

=== Compiler le client ===

{{Emerge|net-fs/openafs}}

Au terme d'une compilation réussie, vous êtes prêt à l'utiliser. 

=== Une installation simple du client pour une navigation globale  ===

Si vous ne faites pas partie d'une cellule OpenAFS particulière à laquelle vous voulez accéder, et naviguer simplement à travers toutes les données partagées globalement disponibles, alors vous pouvez vous contenter d'installer OpenAFS, sans du tout toucher à la configuration, et démarrer {{Path|/etc/init.d/openafs-client}} .

=== Accéder à une cellule  OpenAFS particulière  ===

Si vous avez besoin d'accéder à une cellule particulière, disons, par exemple, la celule de votre université ou de votre entreprise, alors quelques ajustements de votre configuration sont nécessaires. 

Tout d'abord, vous devez mettre {{Path|/etc/openafs/CellServDB}} à jour avec les serveurs de bases de données de votre cellule. Cette information est en général disponible auprès de votre administrateur. 

En second lieu, pour être en mesure de vous connecter à la cellule OpenAFS, vous devez indiquer son nom dans  {{Path|/etc/openafs/ThisCell}} . 

{{Code|Adjusting CellServDB and ThisCell|<pre>
CellServDB:
>netlabs        #Cell name
10.0.0.1        #storage
  
ThisCell:
netlabs
</pre>
}}


{{Warning|N'utilisez que des espaces dans le fichier {{Path|CellServDB}}. Le client échouera probablement si vous utilisez des tabulations. }}

CellServDB indique à votre client quels serveurs il doit contacter pour une cellule donnée.  ThisCell devrait être tout à fait évident. Normallement vous utilisez un nom qui est unique pour votre  organisation. Votre domaine (officiel) devrait être un bon choix. 

Pour un démarrage rapide, vous pouvez maintenant démarrer  {{Path|/etc/init.d/openafs-client}} et utilise <code>klog</code> pour vous identifier et commencer à utiliser votre accès à la cellule. Pour des connexions automatiques, vous pouvez consulter la section appropriée ci-après. 

=== Ajuster le  cache ===

{{Note|Malheureusement, le client  AFS a besoin d'un système de fichiers  ext2/3 comme  cache pour fonctionner correctement. Il y a quelques problèmes quand on utilise d'autres systèmes de fichiers (par exemple, utiliser reiserfs est déconseillé). }}

Vous pouvez placer votre cache sur un système de fichiers existant (s'il est ext2/3), ou utiliser une partition séparée pour cela. L'emplacement par défaut du cache est {{Path|/var/cache/openafs}}, mais vous pouvez en changer en éditant  {{Path|/etc/openafs/cacheinfo}}. 200 Mo est une taille standard pour votre cache, mais plus ne créera aucun mal. 

=== Démarrer AFS au démarrage du système ===

La commande suivante créera les liens appropriés pour démarrer votre client afs au démarrage du système. 

{{Warning|Vous devriez toujours avoir un serveur afs en route dans votre domaine lorsque vous essayez de démarrer le client afs. Votre système ne démarrera pas avant un certain temps si votre serveur est arrêté (et cela représente un temps plutôt long). }}

{{RootCmd|rc-update add openafs-client default}}

== Installation du serveur ==

=== Compiler le  serveur ===

{{Note|Toutes les commandes doivent être écrites sur une seule ligne !! Dans ce document elles sont parfois présentées sur deux lignes pour en faciliter la lecture.}}

Si vous ne l'avez pas encore fait, la commande suivante installera les binaires nécessaires pour configurer un serveur ''et'' un client AFS. 

{{Emerge|net-fs/openafs}}

=== Lancer le serveur AFS ===

Vous devez exécuter la commande  <code>bosserver</code> pour initialiser le serveur superviseur de base (Basic OverSeer ou BOS) qui surveille et contrôle les autres processus serveurs sur sa machine serveur.  Voyez-le comme l'initialisation du système.    Incluez l'option  <code>-noauth</code> pour désactiver la vérification d'autorisation, car vous n'avez pas encore ajouté l'utilisateur admin à ce stade. 

{{Warning|Désactiver la vérification d'autorisation compromet gravement la sécurité de la cellule. Vous devez accomplir toutes les étapes subséquentes en une passe ininterrompue et ne pas laisser la machine sans surveillance avant d'avoir redémarré le serveur BOS avec la vérification d'autorisation activée. C'est ce que dit la documentation AFS.}}

{{RootCmd|bosserver -noauth &}}

Vérifiez que le serveur BOS a créé {{Path|/etc/openafs/server/CellServDB}} et {{Path|/etc/openafs/server/ThisCell}}  

{{RootCmd|ls -al /etc/openafs/server/|output=<pre>
-rw-r--r--    1 root     root           41 Jun  4 22:21 CellServDB
-rw-r--r--    1 root     root            7 Jun  4 22:21 ThisCell
</pre>
}}

=== Définir le nom de la cellule et l'appartenance aux membres pour un processus serveur ===

Assignons d'abord un nom de cellule. 

{{Important|Il y a quelques restriction sur le format des noms. Deux des plus importantes sont que le nom ne peut pas comprendre de lettre capitale et est limité à 64 caractères. Rappelez-vous que votre nom de cellule apparaîtra sous {{Path|/afs}} , aussi il vaut mieux le choisir assez court.}}

{{Note|Dans ce qui suit, et dans chacune des instructions de ce guide, remplacez l'argument SERVEUR_NAME par le nom complètement qualifié de l'hôte  de la machine sur laquelle vous réalisez l'installation (tel que '''afs.gentoo.org''').  Remplacez  l'argument   CELL_NAME par le nom complet de votre cellule  (comme '''gentoo''' )}}

Exécutez la commande  <code>bos setcellname</code> pour définir le nom de la cellule : 

{{RootCmd|bos setcellname SERVER_NAME CELL_NAME -noauth}}

=== Démarrer le processus de serveur de base de données ===

Utilisez ensuite la commande <code>bos create</code> pour créer des entrées poour les quatres processus de serveur de base de données dans rle fichier {{Path|/etc/openafs/BosConfig}}. Les quatres processus ne s'exécutent que sur des machines serveur de base de données. 

{| class="wikitable" style="text-align: left;" 
|- 
| kaserver
| The Authentication Server maintains the Authentication Database. This can be replaced by a Kerberos 5 daemon. If anybody wants to try that feel free to update this document 
|- 
| buserver
| The Backup Server maintains the Backup Database
|- 
| ptserver
| The Protection Server maintains the Protection Database
|- 
| vlserver
| The Volume Location Server maintains the Volume Location Database (VLDB). Very important 
|-
|}

{{RootCmd|bos create SERVER_NAME kaserver simple /usr/libexec/openafs/kaserver -cell CELL_NAME -noauth
|bos create SERVER_NAME buserver simple /usr/libexec/openafs/buserver -cell CELL_NAME -noauth
|bos create SERVER_NAME ptserver simple /usr/libexec/openafs/ptserver -cell CELL_NAME -noauth
|bos create SERVER_NAME vlserver simple /usr/libexec/openafs/vlserver -cell CELL_NAME -noauth}}

Vous pouvez vérifier que tous les serveurs tournent avec la commande  <code>bos status</code> : 

{{RootCmd|bos status SERVER_NAME -noauth|output=<pre>
Instance kaserver, currently running normally.
Instance buserver, currently running normally.
Instance ptserver, currently running normally.
Instance vlserver, currently running normally.
</pre>
}}

=== Initialiser la sécurité de la cellule  ===

Initialisons maintenant le mécanisme de sécurité de la cellule. Nous commencerons par créer les deux entrées initiales suivantes dans la base de données d'authentification : le compte administratif principal, appelé '''admin''' par convention et une entrée pour le processus serveur AFS, appelé <code>afs</code>. Aucun utilisateur ne se connecte sous l'identité '''afs''', mais module  service d'allocation de ticket du serveur d'authentification (TGS ou Ticket Granting Service) utilise ce compte pour chiffrer les tickets qu'il alloue aux clients AFS. Ceci ressemble beaucoup à Kerberos. 

Entrez dans le mode interactif <code>kas</code> 

{{RootCmd|kas -cell CELL_NAME -noauth}}

{{RootCmd|create afs|prompt=ka&gt; |output=<pre>
initial_password:
Verifying, please re-enter initial_password:
</pre>}}

{{RootCmd|create admin|prompt=ka&gt; |output=<pre>
initial_password:
Verifying, please re-enter initial_password:
</pre>}}

{{RootCmd|examine afs|prompt=ka&gt; |output=<pre>
User data for afs
key (0) cksum is 2651715259, last cpw: Mon Jun  4 20:49:30 2001
password will never expire.
An unlimited number of unsuccessful authentications is permitted.
entry never expires.  Max ticket lifetime 100.00 hours.
last mod on Mon Jun  4 20:49:30 2001 by <none>
permit password reuse
</pre>}}

{{RootCmd|setfields admin -flags admin|prompt=ka&gt; }}
{{RootCmd|examine admin|prompt=ka&gt; |output=<pre>
User data for admin (ADMIN)
key (0) cksum is 2651715259, last cpw: Mon Jun  4 20:49:59 2001
password will never expire.
An unlimited number of unsuccessful authentications is permitted.
entry never expires.  Max ticket lifetime 25.00 hours.
last mod on Mon Jun  4 20:51:10 2001 by <none>
permit password reuse
</pre>
}}

Exécutez la commande  <code>bos adduser</code>, pour ajouter l'utilisateur '''admin''' à {{Path|/etc/openafs/server/UserList}} 

{{RootCmd|bos adduser SERVER_NAME admin -cell CELL_NAME -noauth}}

Lancez la commande <code>bos addkey</code> pour définir la clé de chiffrage du serveur AFS dans {{Path|/etc/openafs/server/KeyFile}}  

{{Note|Si on vous demande la clé, donnez le mot de passe que vous avez saisi en créant l'entrée AFS avec <code>kas</code>}}

{{RootCmd|bos addkey SERVER_NAME -kvno 0 -cell CELL_NAME -noauth|output=<pre>
input key:
Retype input key:
</pre>
}}

Exécutez la commande <code>pts createuser</code> pour créer une entrée de  de base de donnée ''protection'' pour l'utilisateur admin. 

{{Note|Par défaut, le serveur de protection assigne AFS UID 1 à l'utilisateur  '''admin''', parce qu'il s'agit de la première entrée utilisateur que vous avez créée. Si le fichier local des mots de passe ( {{Path|/etc/passwd}} ou équivalent) possède déjà une entrée pour '''admin''' qui assigne un  UID différent, utilisez l'argument   <code>-id</code> pour créer des UIDs correspondants.}}

{{RootCmd|pts createuser -name admin -cell CELL_NAME [-id AFS_UID] -noauth}}

Exécutez la commande <code>pts adduser</code>  pour faire de l'utilisateur '''admin''' un membre du groupe des administrateurs système, et la commande <code>pts membership</code>  pour vérifier la nouvelle appartenance au groupe. 

{{RootCmd|pts adduser admin system:administrators -cell CELL_NAME -noauth
|pts membership admin -cell CELL_NAME -noauth|output=<pre>
Groups admin (id: 1) is a member of:
system:administrators
</pre>
}}

=== Redémarrer le serveur  AFS correctement ===

À ce stade, un identification correcte est possible, et le serveur OpenAFS peut être démarré d'une façon normale. Notez que l'authentification demande  aussi un client OpenAFS lancé (sa configuration est décrite dans les chapitres précédents). 

{{RootCmd|bos shutdown SERVER_NAME -wait -noauth
|killall bosserver}}

{{RootCmd|/etc/init.d/openafs-server start
|/etc/init.d/openafs-client start}}

{{RootCmd|rc-update add openafs-server default}}

{{RootCmd|klog admin}}

=== Démarrer le serveur de fichiers, le serveur de volumes et le sauveteur  ===

Démarrez le processus <code>fs</code>, qui consiste en les processus  serveur de fichiers, serveur de volumes et sauveteur. . 

{{RootCmd|bos create SERVER_NAME fs fs /usr/libexec/openafs/fileserver /usr/libexec/openafs/volserver /usr/libexec/openafs/salvager -cell CELL_NAME -noauth}}

Vérifiez que tous les processus tournent : 

{{RootCmd|bos status SERVER_NAME -long -noauth|output=<pre>
Instance kaserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/kaserver'
  
Instance buserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/buserver'
  
Instance ptserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/ptserver'
  
Instance vlserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/vlserver'
  
Instance fs, (type is fs) currently running normally.
Auxiliary status is: file server running.
Process last started at Mon Jun  4 21:09:30 2001 (2 proc starts)
Command 1 is '/usr/libexec/openafs/fileserver'
Command 2 is '/usr/libexec/openafs/volserver'
Command 3 is '/usr/libexec/openafs/salvager'
</pre>
}}

Votre prochaine action dépend du fait que vous avez ou pas déjà lancé des machines serveur AFS dans la cellule. 

Si vous installez le premier serveur AFS de la cellule, créez le premier volume AFS, '''root.afs'''. 

{{Note|Remplacez l'argument nom de partition par le nom d'une des partitions du serveur AFS de la machine. Tout système de fichiers monté sous un répertoire appelé {{Path|/vicepx}} , où x is peut aller de a à z, sera considéré et utilisé comme partition de serveur AFS. Tout système de fichiers unix conviendra (au contraire du  cache client , qui ne peut être qu'ext2/3). Truc: le serveur vérifie, pour chaque point de montage  {{Path|/vicepx}}, si un système de fichiers y est monté. Si ce n'est pas le cas, le serveur n'essayera pas de l'utiliser. Ce comportement peut être modifié en plaçant un fichier nommé {{Path|AlwaysAttach}} dans ce répertoire.}}

{{RootCmd|vos create SERVER_NAME PARTITION_NAME root.afs -cell CELL_NAME -noauth}}

S'il existe des machines serveur AFS de fichiers et de volumes dans la cellule, exécutez les commandes <code>vos sncvldb</code> et <code>vos syncserv</code> pour synchroniser le VLDB (Volume Location Database ou base de données des emplacements de volumes) avec l'état réel des volumes sur la machine locale. Cela copiera toutes les données nécessaires sur votre nouveau serveur. 

Si la commande échoue avec le message ''partition /vecepa does not exist on the serveur'', assurez-vous que la partition est montée avant de lancer les serveurs OpenAFS, ou montez le répertoire et redémarrez les processus en utilisant <code>bos restart SERVER_NAME -all -cell CELL_NAME -noauth</code> . 

{{RootCmd|vos syncvldb SERVER_NAME -cell CELL_NAME -verbose -noauth
|vos syncserv SERVER_NAME -cell CELL_NAME -verbose -noauth}}

=== Démarrer la partie serveur du serveur de mise à jour  ===

{{RootCmd|bos create SERVER_NAME upserver simple "/usr/libexec/openafs/upserver -crypt /etc/openafs/server -clear /usr/libexec/openafs" -cell CELL_NAME -noauth}}

=== Configuring the Top Level of the AFS filespace ===

First you need to set some ACLs, so that any user can lookup {{Path|/afs}} . 

{{Note|The default OpenAFS client configuration has '''dynroot''' enabled. This option turns {{Path|/afs}} into a virtual directory composed of the contents of your {{Path|/etc/openafs/CellServDB}} file. As such, the following command will not work, because it requires a real AFS directory. You can temporarily switch dynroot off by setting '''ENABLE_DYNROOT''' to '''no''' in {{Path|/etc/conf.d/openafs-client}} . Don't forget to issue a client restart after changing parameters.}}

{{RootCmd|fs setacl /afs system:anyuser rl}}

Then you need to create the root volume, mount it readonly on {{Path|/afs/<cell name>}} and read/write on {{Path|/afs/.<cell name>}} . 

{{RootCmd|vos create SERVER_NAME PARTITION_NAME root.cell
|fs mkmount /afs/CELL_NAME root.cell
|fs setacl /afs/CELL_NAME system:anyuser rl
|fs mkmount /afs/.CELL_NAME root.cell -rw}}

{{RootCmd|vos create SERVER_NAME PARTITION_NAME VOLUME_NAME
|fs mkmount /afs/CELL_NAME/MOUNT_POINT VOLUME_NAME
|fs mkmount /afs/CELL_NAME/.MOUNT_POINT VOLUME_NAME -rw
|fs setquota /afs/CELL_NAME/.MOUNT_POINT -max QUOTUM}}

Finally you're done!!! You should now have a working AFS file server on your local network. Time to get a big cup of coffee and print out the AFS documentation!!! 

{{Note|It is very important for the AFS server to function properly, that all system clocks are synchronized. This is best accomplished by installing a ntp server on one machine (e.g. the AFS server) and synchronize all client clocks with the ntp client. This can also be done by the AFS client.}}

== Basic Administration ==

=== Disclaimer ===

OpenAFS is an extensive technology. Please read the AFS documentation for more information. We only list a few administrative tasks in this chapter. 

=== Configuring PAM to Acquire an AFS Token on Login ===

To use AFS you need to authenticate against the KA Server if using an implementation AFS Kerberos 4, or against a Kerberos 5 KDC if using MIT, Heimdal, or ShiShi Kerberos 5. However in order to login to a machine you will also need a user account, this can be local in {{Path|/etc/passwd}} , NIS, LDAP (OpenLDAP), or a Hesiod database. PAM allows Gentoo to tie the authentication against AFS and login to the user account. 

You will need to update {{Path|/etc/pam.d/system-auth}} which is used by the other configurations. "use_first_pass" indicates it will be checked first against the user login, and "ignore_root" stops the local superuser being checked so as to order to allow login if AFS or the network fails. 

{{Code|/etc/pam.d/system-auth|<pre>
auth       required     pam_env.so
auth       sufficient   pam_unix.so likeauth nullok
auth       sufficient   pam_afs.so.1 use_first_pass ignore_root
auth       required     pam_deny.so
  
account    required     pam_unix.so
  
password   required     pam_cracklib.so retry=3
password   sufficient   pam_unix.so nullok md5 shadow use_authtok
password   required     pam_deny.so
  
session    required     pam_limits.so
session    required     pam_unix.so
</pre>
}}

In order for <code>sudo</code> to keep the real user's token and to prevent local users gaining AFS access change {{Path|/etc/pam.d/su}} as follows: 

{{Code|/etc/pam.d/su|<pre>
# Here, users with uid > 100 are considered to belong to AFS and users with
# uid <= 100 are ignored by pam_afs.
auth       sufficient   pam_afs.so.1 ignore_uid 100
  
auth       sufficient   pam_rootok.so
  
# If you want to restrict users begin allowed to su even more,
# create /etc/security/suauth.allow (or to that matter) that is only
# writable by root, and add users that are allowed to su to that
# file, one per line.
#auth       required     pam_listfile.so item=ruser \
#       sense=allow onerr=fail file=/etc/security/suauth.allow
  
# Uncomment this to allow users in the wheel group to su without
# entering a passwd.
#auth       sufficient   pam_wheel.so use_uid trust
  
# Alternatively to above, you can implement a list of users that do
# not need to supply a passwd with a list.
#auth       sufficient   pam_listfile.so item=ruser \
#       sense=allow onerr=fail file=/etc/security/suauth.nopass
  
# Comment this to allow any user, even those not in the 'wheel'
# group to su
auth       required     pam_wheel.so use_uid
  
auth       required     pam_stack.so service=system-auth
  
account    required     pam_stack.so service=system-auth
  
password   required     pam_stack.so service=system-auth
  
session    required     pam_stack.so service=system-auth
session    optional     pam_xauth.so
  
# Here we prevent the real user id's token from being dropped
session    optional     pam_afs.so.1 no_unlog
</pre>
}}

== Acknowledgements ==

We would like to thank the following authors and editors for their contributions to this guide:


* Stefaan De Roeck
* Holger Brueckner
* Benny Chuang
* Tiemo Kieft
* Steven McCoy
* Shyam Mani
