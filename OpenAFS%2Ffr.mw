<languages />

{{Metadata|abstract=Ce  guide explique comment installer un client et un serveur OpenAFS sur Gentoo Linux.}}

Ce guide explique comment installer un serveur et un cilent OpenAFS sur Gentoo Linux.

== Vue d'ensemble ==

=== À propos de ce document ===

Ce document vous guide à travers toutes les étapes nécessaires pour installer un serveur OpenAFS sur Gentoo Linux. Certaines parties de ce document sont issues de la FAQ AFS et du ''AFS Quick Beginnings guide'' d'IBM. Il ne sert à rien de réinventer la roue. 

=== Qu'est-ce qu'AFS ? ===

AFS est un système de fichiers distribué qui permet à des  hôtes coopérants (clients et serveurs) de partager efficacement des ressources de systèmes de fichiers à travers à la fois, le réseau local et des réseaux étendus. Les clients détiennent un cache pour les objets d'usage fréquent (fichiers), pour accélérer leur accès à ces derniers. 

AFS est basé sur un système de fichiers distribué,  développé à l'origine par l'''Information Technology Center de l'université'' de Carnegie-Mellon, appelé ''Andrew File System''. ''Andrew'' était le nom d'un projet de recherche de l'université de Carnégie-Mellon, en l'honneur de ses  fondateurs. Une fois que ''Transarc'' fut créé et que AFS devint un produit, le ''Andrew'' fut abandonné pour indiquer que AFS avait dépassé les limites du projet et était devenu un système de fichiers de qualité et un produit exportable. Néanmoins, il y avait un nombre de cellules existantes qui utilisaient /afs comme racine de leur système de fichiers. À cette époque, changer la racine d'un système de fichiers était loin d'être une entreprise triviale. Aussi, pour éviter aux  premiers site AFS d'avoir à renommer leur systèmes de fichiers, AFS fut retenu, à la fois,  comme le nom du système de fichier  et comme le nom de  sa racine. 

=== Qu'est-ce qu'une cellule  AFS ? ===

Une cellule AFS est un collection de serveurs administrativement regroupés, qui présente un système de fichiers unique et cohésif. Typiquement, une cellule AFS est un ensemble d'hôtes qui utilisent le même nom de domaine (par exemple gentoo.org). Les utilisateurs se connectent par des stations de travail clientes AFS qui demandent des informations et des fichiers à une cellules de serveurs au nom des utilisateurs. Les utilisateurs ne savent pas sur quel serveur le fichier auquel ils accèdent se trouve. Il ne se rendent même pas compte si un serveur est situé dans la pièce d'à coté dans la mesure ou chacun des volumes peut être  répliqué et déplacé vers un autre serveur sans que les utilisateurs en soient avertis. Les fichiers sont toujours accessibles. 

=== Quels sont les bénéfices de l'utilisation  d'AFS ? ===

The main strengths of AFS are its: caching facility (on client side, typically 100M to 1GB), security features (Kerberos 5 based, access control lists), simplicity of addressing (you just have one filesystem), scalability (add further servers to your cell as needed), communications protocol. 

=== Où puis-je trouver plus d'information ? ===

Lisez les [http://www.angelfire.com/hi/plutonic/afs-faq.html FAQ AFS] . 

La page d'accueil de OpenAFS est à  [http://www.openafs.org www.openafs.org] . 

AFS was originally developed by Transarc which is now owned by IBM. Since April 2005, it has been withdrawn from IBM's product catalogue. 
IBM branched the source of the AFS product, and made a copy of the source available for community development and maintenance in 2000. They called the release OpenAFS.

=== Comment résoudre les problèmes ? ===

OpenAFS possède des fonctions de journalisation importantes. Cependant, par défaut, il tient ses propres journaux au lieu d'utiliser les fonctions de journalisation de votre système. Pour que le serveur utilise les fonctions de journalisation du  système,  utilisez l'option <code>-syslog</code> pour toutes les commandes <code>bos</code>. 

== Mise à jour depuis une versions antérieure ==

=== Introduction ===

Cette section vous guide dans le processus de mise à jour d'une installation OpenAFS existante vers une version d'OpenAFS 1.4.0 ou postérieure (ou 1.2.x partant de 1.2.13. Cette dernière ne sera pas prise en compte spécifiquement car la majorité des gens désireront 1.4 pour disposer d'une prise en charge de a.o.linux-2.6, de fichiers de grande taille et de la résolution des bogues). 

Si vous disposez d'une installation fraîche de la version 1.4 d'OpenAFS, vous pouvez sans risque sauter ce chapitre. Néanmoins, si vous mettez à jour depuis une version antérieure, nous vous recommandons fortement de suivre les conseils des sections suivantes. Le script de transition dans l'ebuild est conçu pour vous assister dans la mise à jour rapide et le redémarrage. Notez que :il n'effacera pas (pour des raisons de sécurité) les fichiers de configuration et les scripts de démarrage aux anciens emplacements; ne changera pas automatiquement  votre configuration de démarrage pour utiliser les nouveaux scripts, etc. Si vous n'êtes pas encore convaincu, l'utilisation d'un ancien module du noyau OpenAFS avec le système de binaires à jour, peut rendre votre noyau imprévisible. C'est pourquoi vous devez continuer à lire pour une transition claire et facile. 


{{Note|Ce chapitre a été écrit en tenant compte de différentes configurations du système. Néanmoins, il est toujours possible que, en fonction des ajustements spécifiques qu'un utilisateur a pu apporter à sa configuration, sa situtation particulière ne soit pas décrite ici. Un utilisateur suffisamment assuré pour modifier sa configuration devrait être assez expérimenté pour mettre en œuvre les observations émises quand c'est approprié. À l'inverse, un utilisateur qui a très peu modifié son système en dehors de l'installation de l'ebuild précédent, pourra ignorer la plupart des avertissements donnés par la suite.}}


=== Différences avec les versions précédentes ===

Traditionnellement, OpenAFS a utilisé les mêmes conventions de chemin qu'IBM TransArc labs, jusqu'à ce que le code choisisse un embranchement différent. C'est compréhensible que la configuration de l'ancien AFS continue à utiliser ces conventions héritées. Des configuration plus récentes se conforment à FHS en utilisant des emplacements standards (comme dans beaucoup de distributions Linux). La table suivante est une compilation du script ''configure'' et du fichier README qui accompagne l'archive de distribution d'OpenAFS : 

{| class="wikitable" style="text-align: left;" 
|- 
! Répertoire
! But
! Mode Transarc
! Mode par défaut
! traduction pour  Gentoo
|- 
| viceetcdir
| Configuration du client
| /usr/vice/etc
| $(sysconfdir)/openafs
| /etc/openafs
|- 
| unnamed
| Binaires client 
| unspecified
| $(bindir)
| /usr/bin
|- 
| afsconfdir
| Configuration du serveur
| /usr/afs/etc
| $(sysconfdir)/openafs/server
| /etc/openafs/server
|- 
| afssrvdir
| Binaires serveur internes
| /usr/afs/bin (servers)
| $(libexecdir)/openafs
| /usr/libexec/openafs
|- 
| afslocaldir
| État du serveur
| /usr/afs/local
| $(localstatedir)/openafs
| /var/lib/openafs
|- 
| afsdbdir
| Aut/liste des serveurs/... bases de données
| /usr/afs/db
| $(localstatedir)/openafs/db
| /var/lib/openafs/db
|- 
| afslogdir
| Fichiers de journalisation
| /usr/afs/logs
| $(localstatedir)/openafs/logs
| /var/lib/openafs/logs
|- 
| afsbosconfig
| Configuration supervisatrice
| $(afslocaldir)/BosConfig
| $(afsconfdir)/BosConfig
| /etc/openafs/BosConfig
|-
|}

Il y a quelques autres curiosités, comme les binaires placés dans {{Path|/usr/vice/etc}}  pour le mode Transarc, mais cette liste ne prétend pas être exhaustive. Elle est plutôt destinée à servir de référence pour la transition créatrice de dysfonctionnements de ces fichiers de configuration. 

En conséquence des changements de chemin, l'emplacement par défaut du cache de  disque a également été changé de {{Path|/usr/vice/cache}} en {{Path|/var/cache/openafs}} . 

Plus encore, le script d'initialisation a été éclaté en une partie ''client'' et une partie ''serveur''. Vous aviez pour habitude d'avoir {{Path|/etc/init.d/afs}}, mais maintenant vous avez finalement {{Path|/etc/init.d/openafs-client}} et {{Path|/etc/init.d/openafs-server}}. Par conséquent, le fichier de configuration {{Path|/etc/conf.d/afs}} a été éclaté en {{Path|/etc/conf.d/openafs-client}} et {{Path|/etc/conf.d/openafs-server}}. Les options dans {{Path|/etc/conf.d/openafs}} pour arrêter ou démarrer le client ou le serveur sont également devenues obsolètes. 

Un autre changement au script d'initialisation, c'est qu'il ne vérifie plus la configuration de votre cache de disque. L'ancien code requérait qu'une partition ext2 séparée soit montée sur {{Path|/usr/vice/cache}}. Cela occasionnait quelques problèmes : 

* Bien qu'il s'agisse d'une configuration très logique, votre cache n'a pas besoin d'être sur une partition séparée. Tant que vous assurez que la quantité de place spécifiée dans {{Path|/etc/openafs/cacheinfo}} est réellement disponible pour le cache de disque, tout va bien. Ainsi, il n'y a réellement pas de problème à ce que le cache se trouve sur votre partition ''root''. 
* Quelques personnes utilisent des liens symboliques pour pointer vers le cache de disque réel. Le script d'initialisation n'aime pas ça, parce qu'alors, l'emplacement de ce cache n'apparaît pas dans {{Path|/proc/mounts}} .
* De nos jours, beaucoup préfèrent ext3 à ext2. Les deux systèmes de fichiers sont valides pour une utilisation en cache de disque. Tout autre système de fichiers n'est pas pris en charge (par exemple, n'essayez pas reiserfs, vous obtiendriez un énorme avertissement , et pourriez vous attendre à des plantages par la suite).

=== Transition vers les nouveaux chemins  ===

Tout d'abord, l'installation d'une nouvelle version d'OpenAFS n'écraserait pas vous anciens fichiers de configuration. Le script est conçu pour ne  remplacer aucun fichier déjà présent sur le système. C'est pourquoi, même si vous avez une configuration complètement anarchique, avec un mélange d'anciens et de nouveaux emplacements, le script ne créera pas de problèmes supplémentaires. Par ailleurs, si un serveur OpenAFS en service est détecté, l'installation avortera, empêchant ainsi une possible corruption de base de données. 

Une mise en garde cependant -- il y a eu des ebuilds traînant sur Internet qui désactivent partiellement la protection que Gentoo place sur {{Path|/etc}}. Ces ebuils n'ont jamais été distribués par Gentoo. Vous devriez vérifier la variable <code>CONFIG_PROTECT_MASK</code>  dans la sortie de la commande suivante : 

{{RootCmd|emerge info {{!}} grep "CONFIG_PROTECT_MASK"|output=<pre>
CONFIG_PROTECT_MASK="/etc/gconf /etc/terminfo /etc/texmf/web2c /etc/env.d"
</pre>
}}

Bien que rien dans cet ebuild ne toucherait les fichiers dans  {{Path|/etc/afs}} , la mise à jour causerait la suppression de votre ancienne installation d'OpenAFS. Les fichiers dans <code>CONFIG_PROTECT_MASK</code> qui appartiennent à l'ancienne installation seraient supprimés également. 

Il devrait être clair à l'utilisateur expérimenté que, s'il a mis au point son système en ajoutant les liens symboliques à la main (par exemple  {{Path|/usr/afs/etc}} vers {{Path|/etc/openafs}} ), la nouvelle installation peut continuer à bien fonctionner en continuant à utiliser les anciens fichiers de configuration. Dans ce cas, il n'y aurait pas eu de réelle transition, et le nettoyage de l'ancienne installation résulterait dans une configuration cassée d'OpenAFS. 

Maintenant que vous savez ce qui ne se produira pas, vous voulez savoir quoi faire : 

* {{Path|/usr/afs/etc}} is copied to {{Path|/etc/openafs/server}} 
* {{Path|/usr/vice/etc}} is copied to {{Path|/etc/openafs}} 
* {{Path|/usr/afs/local}} is copied to {{Path|/var/lib/openafs}} 
* {{Path|/usr/afs/local/BosConfig}} is copied to {{Path|/etc/openafs/BosConfig}} , while replacing occurrences of {{Path|/usr/afs/bin/}} with {{Path|/usr/libexec/openafs}} , {{Path|/usr/afs/etc}} with {{Path|/etc/openafs/server}} and {{Path|/usr/afs/bin}} (without the / as previously) with {{Path|/usr/bin}} 
* {{Path|/usr/afs/db}} is copied to {{Path|/var/lib/openafs/db}} 
* The configuration file {{Path|/etc/conf.d/afs}} is copied to {{Path|/etc/conf.d/openafs-client}} , as all known old options were destined for client usage only.

=== La mise à jour elle-même ===

Ainsi vous n'avez pas réussi à configurer le  serveur OpenAFS ? Ou peut-être y êtes-vous parvenu, les sections précédentes vous ont informé sur ce qui va se passer, et vous êtes toujours décidé ? 

Allons-y alors ! 

Si vous avez un serveur qui tourne, arrêtez-le maintenant. 

{{RootCmd|/etc/init.d/afs stop}}

Et ensuite, faites la mise à jour elle-même. 

{{Emerge|openafs}}

=== Redémarrer OpenAFS ===

Si vous aviez un serveur OpenAFS en service, vous pourriez n'avoir pas été forcé à l'arrêter. C'est le moment de le faire maintenant. 

{{RootCmd|/etc/init.d/afs stop}}

Vous désirerez peut-être maintenir le temps d'arrêt à un minimum, c'est pourquoi vous pouvez redémarrer le serveur OpenAFS tout de suite. 

{{RootCmd|/etc/init.d/openafs-server start}}

Vous pouvez vérifier qu'il tourne correctement avec cette commande : 

{{RootCmd|/usr/bin/bos status localhost -localauth}}

Avant de redémarrer le client OpenAFS, prenez le temps de vérifier la configuration de votre cache. Elle est fixée dans {{Path|/etc/openafs/cacheinfo}} .  Pour redémarrer le client OpenAFS, entrez la commande suivante : 

{{RootCmd|/etc/init.d/openafs-client start}}

=== Nettoyage après coup  ===

Avant de procéder au nettoyage, assurez-vous que tout fonctionne correctement et que vous avez redémarré après la mise à jour (autrement, vous pourriez être toujours en train de fonctionner sur l'ancienne installation) 

{{Important|Assusez-vous que vous n'êtes pas en train d'utiliser  {{Path|/usr/vice/cache}} comme cache de disque si vous effacez {{Path|/usr/vice}} !!}}

Les répertoires suivants peuvent être retirés du système en toute sécurité. 

*  {{Path|/etc/afs}} 
*  {{Path|/usr/vice}} 
*  {{Path|/usr/afs}} 
*  {{Path|/usr/afsws}} 

Les fichiers suivants sont également inutiles : 

*  {{Path|/etc/init.d/afs}} 
*  {{Path|/etc/conf.d/afs}} 

{{RootCmd|tar czf /root/oldafs-backup.tgz /etc/afs /usr/vice /usr/afs /usr/afsws
|rm -R /etc/afs /usr/vice /usr/afs /usr/afsws
|rm /etc/init.d/afs /etc/conf.d/afs}}

Au cas où vous auriez au préalable utilisé ebuilds=openafs-1.2.13 ou =openafs-1.3.85, vous pourriez également avoir d'autres fichiers inutiles : 

* {{Path|/etc/init.d/afs-client}} 
* {{Path|/etc/init.d/afs-server}} 
* {{Path|/etc/conf.d/afs-client}} 
* {{Path|/etc/conf.d/afs-server}} 

=== Changements au script d'initialisation ===

Maintenant, la plupart des gens devraient avoir leur système configuré pour démarrer  le client et le serveur OpenAFS automatiquement au démarrage. Ceux qui ne pratiquent pas ainsi peuvent sauter cette section sans crainte. Si votre système est configuré pour les démarrer automatiquement, vous devriez revalider ceci car les noms des scripts d'initialisation ont changé. 

{{RootCmd|rc-update del afs default
|rc-update add openafs-client default
|rc-update add openafs-server default}}

Si vous aviez <code>=openafs-1.2.13</code> ou <code>=openafs-1.3.85</code> , vous devriez retirer {{Path|afs-client}} et {{Path|afs-server}} du niveau d'exécution par défaut, au lieu de {{Path|afs}} . 

=== Dépannage : que faire si la mise à jour automatique échoue  ===

Pas de panique ! Vous ne devriez pas avoir perdu de donnée ou de fichier de configuration. Aussi nous devons analyser la situation. Postez un rapport de bogue à [http://bugs.gentoo.org bugs.gentoo.org]  dans tous les cas, de préférence avec autant d'informations que possible. 

Si vous avez des problèmes avec le démarrage du client, ceci devrait vous aider à faire un diagnostic. 

* Exécutez <code>dmesg</code> . Normalement, le client y envoie des messages d'erreur.
* Vérifiez {{Path|/etc/openafs/cacheinfo}} . Il devrait être de la forme : /afs:{chemin vers le cache de disque}:{nombre de blocs pour le cache de disque}. Normallement, votre cache de disque devrait être situé à  {{Path|/var/cache/openafs}} .
* Vérifiez la sortie de <code>lsmod</code> . Vous devriez voir une ligne commençant par le mot openafs.
* <code>pgrep afsd</code> vous dira si openafs tourne ou pas
* <code>cat /proc/mounts</code> vous dira si {{Path|/afs}} a été monté.

Si vous rencontrez des problèmes pour démarrer le serveur, ces indices devraient vous aider : 

* <code>pgrep bosserver</code> devrait vous dire si le superviseur tourne ou pas. Si vous avez plus d'un superviseur en marche, alors quelque chose s'est mal passé. Dans un tel cas, vous devriez essayer un arrêt élégant du serveur OpenAFS server avec la commande <code>bos shutdown localhost -localauth -wait</code> , vérifiez-en le résultat avec la commande <code>bos status localhost -localauth</code> , tuez tous les processus de superviseur qui restent et, finalement, vérifiez si un process serveur quelconque est encore en marche  ( <code>ls /usr/libexec/openafs</code> pour en obtenir la liste). Après cela, faites <code>/etc/init.d/openafs-server zap</code> pour remettre à zéro le statut du serveur et  <code>/etc/init.d/openafs-server start</code> pour essayer de le relancer.
* Si vous utilisez le système de journalisation propre à OpenAFS (ce qui est la configuration par défaut), vérifiez {{Path|/var/lib/openafs/logs/*}} . Si vous utilisez la journalisation système, vérifiez ses journaux pour toute information utile.

== Documentation ==

=== Obtenir la documentation  AFS  ===

Vous pouvez vous procurer la documentation IBM originale. Elle est très bien écrite et vous devriez absolument la lire si vous devez administrer un serveur AFS. 

{{Emerge|app-doc/afsdoc}}

Vous avez également l'option d'utiliser la documentation délivrée avec OpenAFS. Elle est installée quand l'option <code>doc</code> de la variable USE est activée lors de l'installation d'OpenAFS. On peut la trouver dans {{Path|/usr/share/doc/openafs-*/}}. Au moment de l'écriture de cette page, la documentation était encore en préparation. Elle peut cependant vous renseigner sur de nouvelles fonctionnalités d'OpenAFS qui ne sont pas décrites dans la documentation originale d'IBM. 

== Installation du client ==

=== Compiler le client ===

{{Emerge|net-fs/openafs}}

Au terme d'une compilation réussie, vous êtes prêt à l'utiliser. 

=== Une installation simple du client pour une navigation globale  ===

Si vous ne faites pas partie d'une cellule OpenAFS particulière à laquelle vous voulez accéder, et voulez simplement naviguer  à travers toutes les données partagées globalement disponibles, alors vous pouvez vous contenter d'installer OpenAFS, sans du tout toucher à la configuration, et démarrer {{Path|/etc/init.d/openafs-client}} .

=== Accéder à une cellule  OpenAFS particulière  ===

Si vous avez besoin d'accéder à une cellule particulière, disons, par exemple, la celule de votre université ou de votre entreprise, alors quelques ajustements de votre configuration sont nécessaires. 

Tout d'abord, vous devez mettre {{Path|/etc/openafs/CellServDB}} à jour avec les serveurs de bases de données de votre cellule. Cette information est en général disponible auprès de votre administrateur. 

En second lieu, pour être en mesure de vous connecter à la cellule OpenAFS, vous devez indiquer son nom dans  {{Path|/etc/openafs/ThisCell}} . 

{{Code|Adjusting CellServDB and ThisCell|<pre>
CellServDB:
>netlabs        #Cell name
10.0.0.1        #storage
  
ThisCell:
netlabs
</pre>
}}


{{Warning|N'utilisez que des espaces dans le fichier {{Path|CellServDB}}. Le client échouera probablement si vous utilisez des tabulations. }}

CellServDB indique à votre client quels serveurs il doit contacter pour une cellule donnée.  ThisCell devrait être tout à fait évident. Normallement vous utilisez un nom qui est unique pour votre  organisation. Votre domaine (officiel) devrait être un bon choix. 

For a quick start, you can now start {{Path|/etc/init.d/openafs-client}} and use <code>kinit; aklog</code> to authenticate yourself and start using your access to the cell. For automatic logons to you cell, you want to consult the appropriate section below. 

=== Ajuster le  cache ===

{{Note|Malheureusement, le client  AFS a besoin d'un système de fichiers  ext2/3 comme  cache pour fonctionner correctement. Il y a quelques problèmes quand on utilise d'autres systèmes de fichiers (par exemple, utiliser reiserfs est déconseillé). }}

Vous pouvez placer votre cache sur un système de fichiers existant (s'il est ext2/3), ou utiliser une partition séparée pour cela. L'emplacement par défaut du cache est {{Path|/var/cache/openafs}}, mais vous pouvez en changer en éditant  {{Path|/etc/openafs/cacheinfo}}. 200 Mo est une taille standard pour votre cache, mais plus ne créera aucun mal. 

=== Démarrer AFS au démarrage du système ===

La commande suivante créera les liens appropriés pour démarrer votre client afs au démarrage du système. 

{{Warning|Unless <code>afsd</code> is started with the <code>-dynroot</code> option, you should always have a running afs server in your domain when trying to start the afs client. Your system won't boot until it gets some timeout if your AFS server is down (and this is quite a long long time.)}}

{{RootCmd|rc-update add openafs-client default}}

== Installation du serveur ==

=== Installing the Kerberos Server ===

OpenAFS requires Kerberos 5 for authentication. The following shows how to
install the MIT Kerberos server. Alternatively, the Heimdal kerberos
implementation may be used.

{{Important|Kerberos requires clock synchronization between the Kerberos servers and
the clients. Be sure to install ntpd the server.}}

Install the MIT Kerberos server binaries with the following command:

{{Emerge|mit-krb5}}

Edit the {{Path|/etc/krb5.conf}} and {{Path|/etc/kdc.conf}} configuration files.
Replace the EXAMPLE.COM realm name with your realm name, and update the example
hostnames with your actual hostnames.

{{Note|By convention, your Kerberos realm name should match your internet
domain name, except the Kerberos realm name is in uppercase letters.}}

Create the Kerberos database like so:

{{RootCmd|mkdir /etc/krb5kdc}}
{{RootCmd|kdb5_util create -s}}

=== Compiler le  serveur ===

{{Note|Toutes les commandes doivent être écrites sur une seule ligne !! Dans ce document elles sont parfois présentées sur deux lignes pour en faciliter la lecture.}}

Si vous ne l'avez pas encore fait, la commande suivante installera les binaires nécessaires pour configurer un serveur ''et'' un client AFS. 

{{Emerge|net-fs/openafs}}

=== Keying the Server ===

As of OpenAFS version 1.6.5, the OpenAFS servers support strong crypto
(AES, etc.) for the service key, and will read the Kerberos keytab file
directly.  Create the Kerberos service key for OpenAFS and export it to
a keytab for the OpenAFS server processes, before starting the OpenAFS
services.

{{RootCmd|kadmin.local -q "addprinc -randkey afs/<cellname>"}}
{{RootCmd|kadmin.local -q "ktadd -k /etc/openafs/server/rxkad.keytab afs/<cellname>"}}

{{Important|It is critical to keep the {{Path|rxkad.keytab}} file confidential. The security
of the files in your AFS cell depends on the service key it contains.}}

=== Lancer le serveur AFS ===

You need to run the <code>bosserver</code> command to initialize the Basic OverSeer (BOS) Server, which monitors and controls other AFS server processes on its server machine. Think of it as init for the system. 

{{Note|As of OpenAFS 1.6.0, it is no longer neccessary to include the <code>-noauth</code> flag to disable authentication.  This makes the setup more secure, since there is not a window in which the servers are running with authentication disabled. This also has the nice side effect of greatly simplifying the server setup procedure.}}

Start the OpenAFS <code>bosserver</code>.

{{RootCmd|/etc/init.d/openafs-server start}}

Ensure the OpenAFS servers start on reboot:

{{RootCmd|rc-update add openafs-server default}}

Verify that the BOS Server created {{Path|/etc/openafs/server/CellServDB}} and {{Path|/etc/openafs/server/ThisCell}}:

{{RootCmd|ls -al /etc/openafs/server/|output=<pre>
-rw-r--r--    1 root     root           41 Jun  4 22:21 CellServDB
-rw-r--r--    1 root     root            7 Jun  4 22:21 ThisCell
</pre>
}}

=== Defining Cell Name for Server Processes ===

Assignons d'abord un nom de cellule. 

{{Important|There are some restrictions on the name format. Two of the most important restrictions are that the name cannot include uppercase letters or more than 64 characters. Remember that your cell name will show up under {{Path|/afs}} , so you might want to choose a short one. If your AFS service is to be accessible over the internet, you should use a registered internet domain name for your cell's name. This avoids conficts in the global AFS namespace.}}

{{Note|Dans ce qui suit, et dans chacune des instructions de ce guide, remplacez l'argument SERVEUR_NAME par le nom complètement qualifié de l'hôte  de la machine sur laquelle vous réalisez l'installation (tel que '''afs.gentoo.org''').  Remplacez  l'argument   CELL_NAME par le nom complet de votre cellule  (comme '''gentoo''' )}}

Exécutez la commande  <code>bos setcellname</code> pour définir le nom de la cellule : 

{{RootCmd|bos setcellname localhost CELL_NAME -localauth}}

=== Démarrer le processus de serveur de base de données ===

Next use the <code>bos create</code> command to create entries for the three database server processes in the {{Path|/etc/openafs/BosConfig}} file. The three processes run on database server machines only. 

{| class="wikitable" style="text-align: left;" 
|- 
| buserver
| The Backup Server maintains the Backup Database
|- 
| ptserver
| The Protection Server maintains the Protection Database
|- 
| vlserver
| The Volume Location Server maintains the Volume Location Database (VLDB). Very important :)
|-
|}

{{Note|OpenAFS includes an Kerberos 4 server, called <code>kaserver</code>. The <code>kaserver</code> is obsolete and should not be used for new installations.}}

{{RootCmd|bos create localhost buserver simple /usr/libexec/openafs/buserver -cell CELL_NAME -localauth
|bos create localhost ptserver simple /usr/libexec/openafs/ptserver -cell CELL_NAME -localauth
|bos create localhost vlserver simple /usr/libexec/openafs/vlserver -cell CELL_NAME -localauth}}

Vous pouvez vérifier que tous les serveurs tournent avec la commande  <code>bos status</code> : 

{{RootCmd|bos status localhost -localauth|output=<pre>
Instance buserver, currently running normally.
Instance ptserver, currently running normally.
Instance vlserver, currently running normally.
</pre>
}}

=== Starting the first File Server, Volume Server and Salvager ===

Démarrez le processus <code>fs</code>, qui consiste en les processus  serveur de fichiers, serveur de volumes et sauveteur. . 

{{RootCmd|bos create localhost fs fs /usr/libexec/openafs/fileserver /usr/libexec/openafs/volserver /usr/libexec/openafs/salvager -localauth}}

Vérifiez que tous les processus tournent : 

{{RootCmd|bos status localhost -long -localauth|output=<pre>
  
Instance buserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/buserver'
  
Instance ptserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/ptserver'
  
Instance vlserver, (type is simple) currently running normally.
Process last started at Mon Jun  4 21:07:17 2001 (2 proc starts)
Last exit at Mon Jun  4 21:07:17 2001
Command 1 is '/usr/libexec/openafs/vlserver'
  
Instance fs, (type is fs) currently running normally.
Auxiliary status is: file server running.
Process last started at Mon Jun  4 21:09:30 2001 (2 proc starts)
Command 1 is '/usr/libexec/openafs/fileserver'
Command 2 is '/usr/libexec/openafs/volserver'
Command 3 is '/usr/libexec/openafs/salvager'
</pre>
}}

Votre prochaine action dépend du fait que vous avez ou pas déjà lancé des machines serveur AFS dans la cellule. 

Si vous installez le premier serveur AFS de la cellule, créez le premier volume AFS, '''root.afs'''. 

{{Note|Remplacez l'argument nom de partition par le nom d'une des partitions du serveur AFS de la machine. Tout système de fichiers monté sous un répertoire appelé {{Path|/vicepx}} , où x is peut aller de a à z, sera considéré et utilisé comme partition de serveur AFS. Tout système de fichiers unix conviendra (au contraire du  cache client , qui ne peut être qu'ext2/3). Truc: le serveur vérifie, pour chaque point de montage  {{Path|/vicepx}}, si un système de fichiers y est monté. Si ce n'est pas le cas, le serveur n'essayera pas de l'utiliser. Ce comportement peut être modifié en plaçant un fichier nommé {{Path|AlwaysAttach}} dans ce répertoire.}}

{{RootCmd|vos create localhost PARTITION_NAME root.afs -localauth}}

S'il existe des machines serveur AFS de fichiers et de volumes dans la cellule, exécutez les commandes <code>vos sncvldb</code> et <code>vos syncserv</code> pour synchroniser le VLDB (Volume Location Database ou base de données des emplacements de volumes) avec l'état réel des volumes sur la machine locale. Cela copiera toutes les données nécessaires sur votre nouveau serveur. 

If the command fails with the message "partition /vicepa does not exist on the server", ensure that the partition is mounted before running OpenAFS servers, or mount the directory and restart the processes using <code>bos restart localhost -all -cell CELL_NAME -localauth</code> . 

{{RootCmd|vos syncvldb localhost -verbose -localauth
|vos syncserv localhost -verbose -localauth}}

=== Démarrer la partie serveur du serveur de mise à jour  ===

{{RootCmd|bos create localhost upserver simple "/usr/libexec/openafs/upserver -crypt /etc/openafs/server -clear /usr/libexec/openafs" -localauth}}

=== Creating the first Administrative Account ===

An administrative account is needed to complete the cell setup and perform on going administration.  The first account must be created directly on the servers. Additional accounts may then be created without direct ssh access to the servers.

{{Note|In the following descriptions and commands, substitute all instances of USERNAME with your actual user name.}}

Four tasks need to be done to create the first administrative account.

* a Kerberos principal, by convention, in the form of USERNAME/admin
* an AFS user, by convention, the form of USERNAME.admin
* membership in the built-in AFS system::administrators group
* membership in the OpenAFS superuser list

{{Note|Any name may be used for the administrator principal, for example, "admin", or "afsadmin". If you create an admin principal that does not follow the USERNAME/admin pattern, be sure to update the kerberos KDC access control list in the {{Path|kadm5.acl}} configuration file.}}

{{Important|The Kerberos principal contains as slash "/" separator, but unfortunately, AFS uses a dot "." separator. Be sure to mind the difference.}}

Create the Kerberos principal. Run this following command on the Kerberos server, as root:

{{RootCmd|kadmin.local -q "addprinc USERNAME/admin"}}

Create the AFS admin user. Run this command on the OpenAFS database server, as root:

{{RootCmd|pts createuser USERNAME.admin -localauth}}

Add the AFS admin user to the built-in admin group. Run this command on the OpenAFS database server, as root:

{{RootCmd|pts adduser USERNAME.admin system:administrators -localauth}}

Add the AFS admin user to the superuser list. Run this command on each OpenAFS server, as root:

{{RootCmd|bos adduser localhost USERNAME.admin -localauth}}

{{Note|If you have issues later, regarding insufficient permission, and your AFS Cell name is different from your Kerberos Realm name, this problem is re-mediated by putting your realm name in the {{Path|/etc/openafs/server/krb.conf}} configuration file.}}

=== Configurer le niveau sommet de l'espace de fichies AFS  ===

At this point the server configuration is complete. You will need a running AFS client to set up the top level directories in AFS and grant access rights to them.  This client does not need to be installed on the OpenAFS server.  You will need to obtain your administrative credentials.  Root access is not required for the commands in this section.

First, obtain your administrative credentials:

{{Cmd|kinit USERNAME/admin|output=<pre>
Password for USERNAME/admin@REALM: ********
</pre>}}

{{Cmd|aklog
|tokens|output=<pre>
Tokens held by the Cache Manager:
 
User's (AFS ID 1) tokens for afs@mycellname.com [Expires Oct 21 20:26]
   --End of list--
</pre>}}

Vous devez d'abord définir quelques ACLs, de manière à ce que n'importe quel utilisateur puisse inspecter {{Path|/afs}}. 

{{Note|The default OpenAFS client configuration has '''dynroot''' enabled. This option turns {{Path|/afs}} into a virtual directory composed of the contents of your {{Path|/etc/openafs/CellServDB}} file. Fortunately, '''dynroot''' provides a way to access volumes by name using the "magic" {{Path|/afs/.:mount/}} directory.  This obviates the need to disable '''dynroot''' and and client restarts.}}

{{Cmd|fs setacl /afs/.:mount/CELL_NAME:root.afs/. system:anyuser rl}}

Ensuite, vous devez créer le volume root, le monter en lecture seule sur {{Path|/afs/<cell name>}} et en lecture/écriture sur  {{Path|/afs/.<cell name>}} . 

{{Cmd|vos create SERVER_NAME PARTITION_NAME root.cell
|fs mkmount /afs/.:mount/CELL_NAME:root.afs/CELL_NAME root.cell
|fs setacl /afs/.:mount/CELL_NAME:root.afs/CELL_NAME system:anyuser rl
|fs mkmount /afs/.:mount/CELL_NAME:root.afs/.CELL_NAME root.cell -rw}}


At this point, you can create volumes for your new AFS site and add them to the filespace. Users and groups should be created and directory ACLs setup to allow users to create files and directories. To create and mount a volume:

{{Cmd|vos create SERVER_NAME PARTITION_NAME VOLUME_NAME
|fs mkmount /afs/CELL_NAME/MOUNT_POINT VOLUME_NAME
|fs mkmount /afs/CELL_NAME/.MOUNT_POINT VOLUME_NAME -rw
|fs setquota /afs/CELL_NAME/.MOUNT_POINT -max QUOTUM}}

Et voilà, c'est fini ! Vous devriez maintenant avoir un serveur AFS en fonctionnement sur votre réseau local. C'est le moment de prendre un grande tasse de café et d'imprimer la documentation AFS ! 

{{Note|Il est très important, pour le serveur AFS fonctionne correctement, que tous vos horloges système soient synchronisées. Le mieux pour cela est d'installer un serveur ntp sur une machine (par exemple le serveur AFS) et de synchroniser toutes les horloges des clients avec des clients ntp. Ceci peut également fait par le client AFS.}}

== Administration de base ==

=== Mise en garde ===

OpenAFS est une technologie extensive. Lisez la documentation AFS pour plus d'information. Nous ne faisons que citer ici quelques tâches administratives. 

=== Configurer PAM pour obtenir un jeton AFS à la connexion ===

To use AFS you need to authenticate against the Kerberos 5 KDC (MIT, Heimdal, ShiShi Kerberos 5, or Microsoft Active Directory). However in order to login to a machine you will also need a user account, this can be local in {{Path|/etc/passwd}} , NIS, LDAP (OpenLDAP), or a Hesiod database. PAM allows Gentoo to tie the authentication against AFS and login to the user account. 

{{Note|This section is out of date. See [http://docs.openafs.org/QuickStartUnix/HDRWQ41.html Enabling AFS Login on Linux Systems] }}

Vous devrez mettre {{Path|/etc/pam.d/system-auth}} à jour ; il est utilisé par d'autes configurations.  "use_first_pass" indique que  la connexion utilisateur sera vérifiée en premier, et "ignore_root" stoppe  la vérification du super-utilisateur local de manière  à autoriser la connexion si AFS ou le réseau tombe. . 

{{Code|/etc/pam.d/system-auth|<pre>
auth       required     pam_env.so
auth       sufficient   pam_unix.so likeauth nullok
auth       sufficient   pam_afs.so.1 use_first_pass ignore_root
auth       required     pam_deny.so
  
account    required     pam_unix.so
  
password   required     pam_cracklib.so retry=3
password   sufficient   pam_unix.so nullok md5 shadow use_authtok
password   required     pam_deny.so
  
session    required     pam_limits.so
session    required     pam_unix.so
</pre>
}}

Pour que  <code>sudo</code> conserve le jeton de l'utilisateur réel et pour empêcher le utilisateurs locaux d'obtenir un accès AFS, changez {{Path|/etc/pam.d/su}} comme indiqué ci-après : 

{{Code|/etc/pam.d/su|<pre>
# Here, users with uid > 100 are considered to belong to AFS and users with
# uid <= 100 are ignored by pam_afs.
auth       sufficient   pam_afs.so.1 ignore_uid 100
  
auth       sufficient   pam_rootok.so
  
# If you want to restrict users begin allowed to su even more,
# create /etc/security/suauth.allow (or to that matter) that is only
# writable by root, and add users that are allowed to su to that
# file, one per line.
#auth       required     pam_listfile.so item=ruser \
#       sense=allow onerr=fail file=/etc/security/suauth.allow
  
# Uncomment this to allow users in the wheel group to su without
# entering a passwd.
#auth       sufficient   pam_wheel.so use_uid trust
  
# Alternatively to above, you can implement a list of users that do
# not need to supply a passwd with a list.
#auth       sufficient   pam_listfile.so item=ruser \
#       sense=allow onerr=fail file=/etc/security/suauth.nopass
  
# Comment this to allow any user, even those not in the 'wheel'
# group to su
auth       required     pam_wheel.so use_uid
  
auth       required     pam_stack.so service=system-auth
  
account    required     pam_stack.so service=system-auth
  
password   required     pam_stack.so service=system-auth
  
session    required     pam_stack.so service=system-auth
session    optional     pam_xauth.so
  
# Here we prevent the real user id's token from being dropped
session    optional     pam_afs.so.1 no_unlog
</pre>
}}

[[Category:Filesystems]] {{Migrated|originalauthors=Stefaan De Roeck, Holger Brueckner, Benny Chuang, Tiemo Kieft, Steven McCoy, Shyam Mani}}
