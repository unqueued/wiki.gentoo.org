<languages />

{{Metadata|abstract=这篇HOWTO将帮助创建和安装Gentoo Linux的无盘节点。}}

这篇HOWTO将帮助创建和安装Gentoo Linux的无盘节点。

== 介绍 ==

=== 关于这篇HOWTO ===

This HOWTO will help setting up ''diskless'' workstations based on the Gentoo Linux distribution. This is guide is intended to make the process as user friendly as possible and cater to the Linux newbie, because everyone was at a certain point :) While an experienced user could easily tie the multiple HOWTOs available on diskless nodes and networking together it's hoped that this guide can ease the installation for all interested users, geeks or not.

=== 什么是无盘机？ ===

A diskless machine is a PC without any of the usual boot devices such as hard disks, floppy drives or CD-ROMs. The diskless node boots off the network and needs a server that will provide it with storage space as a local hard disk would. From now on the server will be the ''master'' , while the diskless machine gets called the ''slave'' (what's in a name :). The slave node needs a network adapter that supports PXE booting or Etherboot; check [http://www.etherboot.org Etherboot.org] for support listings. Most modern cards support PXE and many built-in adapters on motherboards will also work. 

=== 开始之前 ===

Gentoo should be installed on the master node and enough space on the master to store the file systems of the slave nodes that are going to be hosted. Also make sure there is one interface to the internet separated from the local area connection. 

== 配置master和slave ==

=== 关于内核 ===

The kernel is the software that sits between the hardware and all other software that is loaded on the machine, essentially the heart of a kernel based operating system. When a computer is started, the BIOS executes the instructions found at the reserved boot space of the hard drive. These instructions are typically a boot loader that loads a kernel. After a kernel has been loaded all processes are handled by the kernel. 

For more information on kernels and kernel configuration check out the [http://www.tldp.org/HOWTO/Kernel-HOWTO.html kernel HOWTO] . 

=== 配置master的内核 ===

master的内核可以很大也可以按照需要来定制，但是这些内核选项必须要选中。输入以下命令进入内核配置菜单： 

{{RootCmd|cd /usr/src/linux
|make menuconfig}}

这里有用来替代手动编辑{{Path|/usr/src/linux/.config}}文件的一个灰色和蓝色的GUI。如果这个内核当前工作正常，退出GUI并输入以下命令来保留当前的配置文件将会是一个好的主意： 

{{RootCmd|cp .config .config_working}}

进入下面的子目录并确保列出的条目都选择为内建（而非模块）。下面的选项是取自于2.6.10版本的内核。如果使用不同版本的内核，文字或者顺序可能会不同。只需确保至少选择了以下这些。 

{{KernelBox|title=master的内核选项|<pre>
[*] Networking support --->
  Networking options --->
    <*> Packet socket
    <*> Unix domain sockets
    [*] TCP/IP networking
    [*]   IP: multicasting
    [ ] Network packet filtering (replaces ipchains)
  
File systems --->
  Network File Systems  --->
    <*> NFS server support
    [*]   Provide NFSv3 server support
</pre>}}

如果需要通过master节点访问互联网和/或需要一个安全防火墙，确保添加了对iptables的支持：

{{KernelBox|title=启用iptables支持|<pre>
  [*] Network packet filtering (replaces ipchains)
  IP: Netfilter Configuration  --->
    <*> Connection tracking (required for masq/NAT)
    <*> IP tables support (required for filtering/masq/NAT)
</pre>
}}

如果还需要包过滤，一会再将剩下的作为模块添加。确保已阅读在[http://www.gentoo.org//doc/en/security/security-handbook.xml?part=1&chap=12 Gentoo安全手册中关于防火墙的章节]来让它正常工作。 

{{Note|这些内核配置选项仅是应该增加到原系统配置选项中，而不是完整的替换掉原有的内核配置。}}

在重新配置master的内核之后，需要对它进行重建：

{{RootCmd|make && make modules_install
|cp arch/i386/boot/bzImage /boot/bzImage-master}}

然后根据所使用引导器的不同，在{{Path|lilo.conf}}或{{Path|grub.conf}}中为新内核添加一个条目，并确保新内核是默认的那个。现在新的bzImage已经复制到了boot目录，所有所做的这些是为了在重启系统后可以载入这些新的选项。 

=== 关于slave的内核 ===

建议将slave的内核编译成无任何模块，因为通过远程引导加载和安装他们是一个困难并且没必要的过程。另外，为了有效的从网络引导，slave的内核应该尽可能的小和精简。slave的内核将在和配置master同样的位置进行编译。 

为了避免混乱和浪费时间，键入以下命令来备份master的配置文件将会是一个好主意： 

{{RootCmd|cp /usr/src/linux/.config /usr/src/linux/.config_master}}

现在，slave的内核已经配置得和master的内核的kernel一样时尚了。如果需要一个全新的配置文件，可以键入以下命令来还原默认{{Path|/usr/src/linux/.config}}文件： 

{{RootCmd|cd /usr/src/linux
|cp .config_master .config}}

现在键入以下命令进入GUI配置： 

{{RootCmd|cd /usr/src/linux
|make menuconfig}}

确保将以下的选项选择为内建而不是内核模块。 

{{KernelBox|title=slave的内核选项|<pre>
[*] Networking support --->
  Networking options --->
    <*> Packet socket
    <*> Unix domain sockets
    [*] TCP/IP networking
    [*]   IP: multicasting
    [*]   IP: kernel level autoconfiguration
    [*]     IP: DHCP support
  
File systems --->
  Network File Systems  --->
    <*> file system support
    [*]   Provide NFSv3 client support
    [*]   Root file system on NFS
</pre>
}}

{{Note|另外也可以通过安装BOOTP服务器来得到一个DHCP服务器。}}

{{Important|将节点的网络适配器添加到内核（并且不是作为模块）是重要的。尽管无盘节点使用模块通常不会有问题。}}

现在的slave需要进行编译。这里要小心不要覆盖或者弄乱为master编译的模块（如果有的话）：

{{RootCmd|cd /usr/src/linux
|make}}

现在在master上创建用来保持slave自己的及必须的系统文件的目录。这里使用的是{{Path|/diskless}}，但是仍然在这可以选择任何更好的位置。现在复制slave的bzImage到{{Path|/diskless}}目录： 


{{Note|如果要使用不同的架构，将相应配置各自保存到{{Path|.config_arch}}可能会有点用。对镜像文件也是一样的：将它们在{{Path|/diskless}}中保存为{{Path|bzImage_arch}}。}}


{{RootCmd|mkdir /diskless
|cp /usr/src/linux/arch/i386/boot/bzImage /diskless}}

=== 配置一个slave的初步文件系统 ===

master和slave的文件系统可以调整并变更一些。现在的兴趣点是获得一个有合适的配置文件和挂载点的初始的文件系统。首先需要在{{Path|/diskless}}中为第一个slave创建目录。由于共享同一系统文件将会造成权限问题及硬崩溃，每个slave需要它们各自的根文件系统。这些目录可以叫作任何管理员觉得合理的名字，但是作者建议使用惟一的并且不会混乱的slave的IP地址。第一个slave的静态IP将以<code>192.168.1.21</code> 为例： 

{{RootCmd|mkdir -p /diskless/192.168.1.21/etc}}

{{Path|/etc}}中的许多配置文件需要改变为slave所使用的。键入以下命令复制master的{{Path|/etc}}目录到新slave的根： 

{{RootCmd|cp -r /etc/* /diskless/192.168.1.21/etc/}}

这个文件系统仍然没有完成，因为它需要许多挂载点和目录。键入以下命令去创建它们： 

{{RootCmd|mkdir /diskless/192.168.1.21/home
|mkdir /diskless/192.168.1.21/dev
|mkdir /diskless/192.168.1.21/proc
|mkdir /diskless/192.168.1.21/tmp
|mkdir /diskless/192.168.1.21/mnt
|chmod a+w /diskless/192.168.1.21/tmp
|mkdir /diskless/192.168.1.21/mnt/.initd
|mkdir /diskless/192.168.1.21/root}}

{{RootCmd|mkdir /diskless/192.168.1.21/sys
|mkdir /diskless/192.168.1.21/var
|mkdir /diskless/192.168.1.21/var/empty
|mkdir /diskless/192.168.1.21/var/lock
|mkdir /diskless/192.168.1.21/var/log
|mkdir /diskless/192.168.1.21/var/run
|mkdir /diskless/192.168.1.21/var/spool
|mkdir /diskless/192.168.1.21/usr
|mkdir /diskless/192.168.1.21/opt
}}

Most of these "stubs" should be recognizable; stubs like {{Path|/dev}} , {{Path|/proc}} or {{Path|/sys}} will be populated when the slave starts, the others will be mounted later. The {{Path|/diskless/192.168.1.21/etc/conf.d/hostname}} file should also be changed to reflect the hostname of the slave. Binaries, libraries and other files will be populated later in this HOWTO right before attempting to boot the slave. 

尽管{{Path|/dev}}会在稍后被<code>udev</code>占据，仍然需要创建{{Path|console}}条目。否则，将会遇到“unable to open initial console”（无法开启初始化控制台）错误信息。 

{{RootCmd|mknod /diskless/192.168.1.21/dev/console c 5 1}}

== 配置DHCP服务器 ==

=== 关于DHCP服务器 ===

DHCP代表着动态主机配置协议。DHCP服务器将是当slave从网络启动时第一个通信的计算机。DHCP服务器的主机作用是指派IP地址。DHCP服务器能基于主机以太网的MAC地址来指派IP地址。一旦slave拥有一个IP地址，DHCP服务器将告诉slave去哪里获得它的初始化文件系统及内核。 

=== 开始之前 ===

在它们正确工作之前，有一些事情需要确认。首先检查网络连通性： 

{{RootCmd|ifconfig eth0 multicast
|ifconfig -a}}

确认有一个''eth0''设备运行。它看起来应该像这样： 

{{CodeBox|title=一个正常工作的eth0设备|1=
eth0      Link encap:Ethernet  HWaddr 00:E0:83:16:2F:D6
          inet addr:192.168.1.1  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:26460491 errors:0 dropped:0 overruns:2 frame:0
          TX packets:32903198 errors:0 dropped:0 overruns:0 carrier:1
          collisions:0 txqueuelen:100
          RX bytes:2483502568 (2368.4 Mb)  TX bytes:1411984950 (1346.5 Mb)
          Interrupt:18 Base address:0x1800
}}

它说''MULTICAST''是非常重要的，如果不是即必须重新编译包括有多播支持的内核。

=== 安装DHCP服务器 ===

如果网络中还没有安装一台DHCP服务器，现在就需要安装一台： 

{{Emerge|dhcp}}

如果网络中已经安装有一台DHCP服务器，编辑配置文件来使PXE引导能正常工作。 

=== 配置DHCP服务器 ===

在启动DHCP服务器之前，只需要编辑一个配置文件：{{Path|/etc/dhcp/dhcpd.conf}}。复制并编辑提供的示例文件： 

{{RootCmd|cp /etc/dhcp/dhcpd.conf.sample /etc/dhcp/dhcpd.conf
|nano -w /etc/dhcp/dhcpd.conf}}

通常文件应该做成一个时尚的缩进式布局，看起来像这样： 

{{CodeBox|title={{Path|dhcpd.conf}}示例|1=
# global options here
ddns-update-style none;
shared-network LOCAL-NET {
  # shared network options here
  subnet 192.168.1.0 netmask 255.255.255.0 {
    # subnet network options here
    host slave{
        # host specific options here
    }
    group {
        # group specific options here
    }
  }
}
}}

<code>shared-network</code>块是可选的，并且应该用于需要将IP指派到同一网络拓扑中。至少一个<code>subnet</code>应该被声明并且可选的<code>group</code>块允许选项中其中被分组。一个好的{{Path|dhcpd.conf}}示例看起来像这样： 

{{CodeBox|title={{Path|dhcpd.conf}}示例|1=
#
# Sample dhcpd.conf for diskless clients
#
  
# Disable dynamic DNS
ddns-update-style none;
  
# Assume one default gateway for IP traffic will do
option routers 192.168.1.1;
  
# Provide DNS info to clients
option domain-name-servers 192.168.1.1;
option domain-name "mydomain.com";
  
# Specify the TFTP server to be used
next-server 192.168.1.1;
  
# Declare a vendor-specific option buffer for PXE clients:
# Code 1: Multicast IP address of boot file server
# Code 2: UDP port that client should monitor for MTFTP responses
# Code 3: UDP port that MTFTP servers are using to listen for MTFTP requests
# Code 4: Number of seconds a client must listen for activity before trying
#         to start a new MTFTP transfer
# Code 5: Number of seconds a client must listen before trying to restart
#         a MTFTP transfer
  
option space PXE;
option PXE.mtftp-ip               code 1 = ip-address;
option PXE.mtftp-cport            code 2 = unsigned integer 16;
option PXE.mtftp-sport            code 3 = unsigned integer 16;
option PXE.mtftp-tmout            code 4 = unsigned integer 8;
option PXE.mtftp-delay            code 5 = unsigned integer 8;
option PXE.discovery-control      code 6 = unsigned integer 8;
option PXE.discovery-mcast-addr   code 7 = ip-address;
  
# Declare the subnet where our diskless nodes will live
subnet 192.168.1.0 netmask 255.255.255.0 {
  
  # Provide PXE clients with appropriate information
  class "pxeclient" {
    match if substring(option vendor-class-identifier, 0, 9) = "PXEClient";
    vendor-option-space PXE;
  
    # At least one of the vendor-specific PXE options must be set in
    # order for the client boot ROMs to realize that we are a PXE-compliant
    # server.  We set the MCAST IP address to 0.0.0.0 to tell the boot ROM
    # that we can't provide multicast TFTP.
  
    option PXE.mtftp-ip 0.0.0.0;
  
    # This is the name of the file the boot ROMs should download.
    filename "pxelinux.0";
  }
  
  # Provide Etherboot clients with appropriate information
  class "etherboot" {
    match if substring(option vendor-class-identifier, 0, 9) = "Etherboot";
    filename "vmlinuz_arch";
  }
  
  # Add one host declaration for each diskless host
  host slave21 {
    hardware ethernet 00:02:A5:04:3B:66;
    fixed-address 192.168.1.21;
  }
}
}}

{{Note|没有任何事物阻止PXE引导和Etherboot同时使用。上面的Code Listing只是一个例子；如果仍然有问题，请参考DHCPd文档。}}

跟在<code>next-server</code>后面的IP地址将会被查询指定的<code>filename</code>。这个IP地址应该是tftp服务器的IP，通常就是master的IP地址。<code>filename</code>是相对于{{Path|/diskless}}目录的（这将会在稍后提到的tftp服务器选项中指定）。在<code>host</code>块内，<code>hardware ethernet</code>选项指定一个MAC地址，同时<code>fixed-address</code>指派一个固定IP地址到那个特有的MAC地址。这里有一个相当不错的{{Path|dhcpd.conf}}的man页解释这篇HOWTO中所使用的选项。可以键入以下命令来阅读这个man页： 

{{Cmd|man dhcpd.conf}}

=== 启动DHCP服务器 ===

Before starting the dhcp initialization script edit the {{Path|/etc/conf.d/dhcp}} file so that it looks something like this: 

{{CodeBox|title={{Path|/etc/conf.d/dhcp}}示例|lang=bash|1=
IFACE="eth0"
# Insert any customizations needed
}}

The <code>IFACE</code> variable is the device that the DHCP server will be running on, in this case <code>eth0</code>. Adding more arguments to the <code>IFACE</code> variable can be useful for a complex network topology with multiple Ethernet cards. To start the dhcp server type: 

{{RootCmd|/etc/init.d/dhcpd start}}

To add the dhcp server to the start-up scripts type: 

{{RootCmd|rc-update add dhcpd default}}

=== 排查DHCP服务器 ===

To see if a node boots, take a look at {{Path|/var/log/messages}}. If the node successfully boots, the {{Path|messages}} file should have some lines at the bottom looking like this: 

{{CodeBox|title=dhcp产生的日志文件条目示例|<pre>
DHCPDISCOVER from 00:00:00:00:00:00 via eth0
DHCPOFFER on 192.168.1.21 to 00:00:00:00:00:00 via eth0
DHCPREQUEST for 192.168.1.21 from 00:00:00:00:00:00 via eth0
DHCPACK on 192.168.1.21 to 00:00:00:00:00:00 via eth0
</pre>
}}

{{Note|This log file can also help in discovering the slaves' MAC addresses.}}

If the following message is encountered it probably means there is something wrong in the configuration file but that the DHCP server is broadcasting correctly. 

{{CodeBox|title=dhpc服务器错误示例|1=
no free leases on subnet LOCAL-NET
}}

Every time after changing the configuration file the DHCP server must be restarted. To restart the server type: 

{{RootCmd|/etc/init.d/dhcpd restart}}

== 配置TFTP服务器和PXE Linux引导器和/或Etherboot ==

=== 关于TFTP服务器 ===

TFTP stands for Trivial File Transfer Protocol. The TFTP server is going to supply the slaves with a kernel and an initial filesystem. All of the slave kernels and filesystems will be stored on the TFTP server, so it's probably a good idea to make the master the TFTP server. 

=== 安装TFTP服务器 ===

A highly recommended tftp server is available as the tftp-hpa package. This tftp server happens to be written by the author of SYSLINUX and it works very well with pxelinux. To install simply type: 

{{Emerge|tftp-hpa}}

=== 配置TFTP服务器 ===

Edit {{Path|/etc/conf.d/in.tftpd}}. The tftproot directory needs to specified with <code>INTFTPD_PATH</code> and any command line options with <code>INTFTPD_OPTS</code>. It should look something like this: 

{{FileBox|filename=/etc/conf.d/in.tftpd|lang=bash|1=
INTFTPD_PATH="/diskless"
INTFTPD_OPTS="-l -v -s ${INTFTPD_PATH}"
}}

The <code>-l</code> option indicates that this server listens in stand alone mode so inetd does not have to be run. The <code>-v</code> indicates that log/error messages should be verbose. The <code>-s /diskless</code> specifies the root of the tftp server.

=== 启动TFTP服务器 ===

To start the tftp server type: 

{{RootCmd|/etc/init.d/in.tftpd start}}

This should start the tftp server with the options that were specified in the {{Path|/etc/conf.d/in.tftpd}}. If this server is to be automatically started at boot type: 

{{RootCmd|rc-update add in.tftpd default}}

=== 关于PXELINUX ===

This section is not required if only Etherboot is being used. PXELINUX is the network bootloader equivalent to LILO or GRUB and will be served via TFTP. It is essentially a tiny set of instructions that tells the client where to locate its kernel and initial filesystem and allows for various kernel options. 

=== 开始之前 ===

Now the file pxelinux.0 is required, which comes in the SYSLINUX package by H. Peter Anvin. This package can be installed by typing: 

{{Emerge|syslinux}}

=== 安装PXELINUX ===

{{Note|This isn't needed for Etherboot}}

Before starting the tftp server pxelinux needs to be set up. First copy the pxelinux binary into the {{Path|/diskless}} directory: 

{{RootCmd|cp /usr/share/syslinux/pxelinux.0 /diskless
|mkdir /diskless/pxelinux.cfg
|touch /diskless/pxelinux.cfg/default}}

This will create a default bootloader configuration file. The binary {{Path|pxelinux.0}} will look in the {{Path|pxelinux.cfg}} directory for a file whose name is the client's IP address in hexadecimal. If it does not find that file it will remove the rightmost digit from the file name and try again until it runs out of digits. Versions 2.05 and later of syslinux first perform a search for a file named after the MAC address. If no file is found, it starts the previously mentioned discovery routine. If none is found, the {{Path|default}} file is used. 

{{CodeBox|title=PXE在{{Path|pxelinux.cfg/}}中查找文件的顺序|1=
## (Leading 01 means Ethernet, next bytes match our slave's MAC address)
01-00-40-63-c2-ca-c9
  
## (Assigned IP in hexadecimal)
C0A80115
C0A8011
C0A801
C0A80
C0A8
C0A
C0
C
  
default
}}

{{Note|These are all in lowercase.}}

Let's start with the {{Path|default}} file: 

{{CodeBox|title={{Path|pxelinux.cfg/default}}示例|1=
DEFAULT gentoo
LABEL gentoo
LINUX /bzImage
APPEND ip=dhcp root=/dev/nfs nfsroot=192.168.1.1:/diskless/192.168.1.21
}}

The <code>DEFAULT</code> tag directs pxelinux to the kernel bzImage that was compiled earlier. The <code>APPEND</code> tag appends kernel initialisation options. Since the slave kernel was compiled with <code>NFS_ROOT_SUPPORT</code> , the nfsroot will be specified here. The first IP is the master's IP and the second IP is the directory that was created in {{Path|/diskless}} to store the slave's initial filesystem.

=== 关于Etherboot ===

{{Note|This isn't required if PXE boot is being used.}}

Etherboot boots network boot images from a TFTP server. As the PXE this is equivalent to LILO or GRUB. The <code>mknbi</code> utility enables the creation of different images using different options. 

=== 开始之前 ===

The <code>mknbi</code> (utility for making tagged kernel images useful for netbooting) package is needed to create the Etherboot images. This tool will create a preconfigured kernel image from the original kernel. This contains the boot options as shown further down. 

{{Emerge|mknbi}}

=== 安装Etherboot ===

In this section a simple etherboot image will be created. As the dhcp server gives out the clients root-path in the "option root-path" dhcp.conf, this does not have to be included here. More details can be found in the mknbi manual. 

{{Cmd|man mknbi}}

Making the boot images. This will create a ELF bootable image capable of passing dhcp and the rootpath to the kernel. Also forcing the kernel to browse the network for a dhcp server. 

{{RootCmd|mkelf-linux -ip{{=}}dhcp /diskless/bzImage > /diskless/vmlinuz }}

{{Note|For the arch specific images <code>bzImage_arch</code> and <code>vmlinuz_arch</code> have to be typed.}}

=== 排查网络启动过程 ===

There are a few things that can be done to debug the network boot process. Primarily a tool called <code>tcpdump</code> can be used. To install <code>tcpdump</code> type: 

{{Emerge|tcpdump}}

Now various network traffic can be listened to, to make sure the client/server interactions are functioning. If something isn't working there are a few things that could be checked. First make sure that the client/server is physically connected properly and that the networking cables are not damaged. If the client/server is not receiving requests on a particular port make sure that there is no firewall interference. To listen to interaction between two computers type: 

{{RootCmd|tcpdump host client_ip and server_ip}}

The <code>tcpdump</code> command can also be configured to listen on particular port such as the tftp port by typing: 

{{RootCmd|tcpdump port 69}}

A common error that might be received is: "PXE-E32: TFTP open time-out". This is probably due to firewall issues. If <code>TCPwrappers</code> is being used, it might be worth checking {{Path|/etc/hosts.allow}} and {{Path|etc/hosts.deny}} and make sure that they are configured properly. The client should be allowed to connect to the server.

== 配置NFS服务器 ==

=== 关于NFS服务器 ===

NFS stands for Network File System. The NFS server will be used to serve directories to the slave. This part can be somewhat personalized later, but right now all that is wanted is a preliminary slave node to boot diskless. 

=== 关于Portmapper ===

Various client/server services do not listen on a particular port, but instead rely on RPCs (Remote Procedure Calls). When the service is initialised it listens on a random port and then registers this port with the Portmapper utility. NFS relies on RPCs and thus requires Portmapper to be running before it is started. 

=== 开始之前 ===

The NFS Server needs kernel level support so if the kernel does not have this, the master's kernel needs to be recompiled. To double check the master's kernel configuration type: 

{{RootCmd|grep NFS /usr/src/linux/.config_master}}

The output should look something like this if the kernel has been properly configured: 

{{KernelBox|title=在master的内核配置中，配置NFS特需的选项|<pre>
CONFIG_PACKET=y
# CONFIG_PACKET_MMAP is not set
# CONFIG_NETFILTER is not set
CONFIG_NFS_FS=y
CONFIG_NFS_V3=y
# CONFIG_NFS_V4 is not set
# CONFIG_NFS_DIRECTIO is not set
CONFIG_NFSD=y
CONFIG_NFSD_V3=y
# CONFIG_NFSD_V4 is not set
# CONFIG_NFSD_TCP is not set
</pre>
}}

=== 安装NFS服务器 ===

The NFS package that can be acquired through portage by typing: 

{{Emerge|nfs-utils}}

This package will emerge a portmapping utility, nfs server, and nfs client utilities and will automatically handle initialisation dependencies. 

=== 配置NFS服务器 ===

There are three major configuration files that will have to be edited: 

{{CodeBox|title=Nfs配置文件|1=
/etc/exports
/diskless/192.168.1.21/etc/fstab
/etc/conf.d/nfs
}}

The {{Path|/etc/exports}} file specifies how, to who and what to export through NFS. The slave's fstab will be altered so that it can mount the NFS filesystems that the master is exporting. 

A typical {{Path|/etc/exports}} for the master should look something like this: 

{{FileBox|filename=/etc/exports|title=master exports file|1=
# one line like this for each slave
/diskless/192.168.1.21   192.168.1.21(sync,rw,no_root_squash,no_all_squash)
# common to all slaves
/opt   192.168.1.0/24(sync,ro,no_root_squash,no_all_squash)
/usr   192.168.1.0/24(sync,ro,no_root_squash,no_all_squash)
/home  192.168.1.0/24(sync,rw,no_root_squash,no_all_squash)
# if you want to have a shared log
/var/log   192.168.1.21(sync,rw,no_root_squash,no_all_squash)
}}

The first field indicates the directory to be exported and the next field indicates to who and how. This field can be divided in two parts: who should be allowed to mount that particular directory, and what the mounting client can do to the filesystem: <code>ro</code> for read only, <code>rw</code> for read/write; <code>no_root_squash</code> and <code>no_all_squash</code> are important for diskless clients that are writing to the disk, so that they don't get "squashed" when making I/O requests. The slave's fstab file, {{Path|/diskless/192.168.1.21/etc/fstab}} , should look like this: 

{{CodeBox|title=slave的{{Path|fstab}}示例|1=
# these entries are essential
master:/diskless/192.168.1.21   /         nfs     sync,hard,intr,rw,nolock,rsize=8192,wsize=8192    0 0
master:/opt                     /opt      nfs     sync,hard,intr,ro,nolock,rsize=8192,wsize=8192    0 0
master:/usr                     /usr      nfs     sync,hard,intr,ro,nolock,rsize=8192,wsize=8192    0 0
master:/home                    /home     nfs     sync,hard,intr,rw,nolock,rsize=8192,wsize=8192    0 0
none                            /proc     proc    defaults                                     0 0
# useful but superfluous
master:/var/log                 /var/log  nfs     hard,intr,rw                                 0 0
}}

In this example, ''master'' is just the hostname of the master but it could easily be the IP of the master. The first field indicates the directory to be mounted and the second field indicates where. The third field describes the filesystem and should be NFS for any NFS mounted directory. The fourth field indicates various options that will be used in the mounting process (see mount(1) for info on mount options). Some people have had difficulties with soft mount points so here they are made hard mounts, a look into various {{Path|/etc/fstab}} options should be done to make the cluster more efficient. 

The last file that should be edited is {{Path|/etc/conf.d/nfs}} which describes a few options for nfs when it is initialised and looks like this: 

{{CodeBox|title=master的{{Path|/etc/conf.d/nfs}}示例|1=
# Config file for /etc/init.d/nfs
  
# Number of servers to be started up by default
RPCNFSDCOUNT=8
  
# Options to pass to rpc.mountd
RPCMOUNTDOPTS=""
}}

The <code>RPCNFSDCOUNT</code> should be changed to the number of diskless nodes on the network. 

=== 启动NFS服务器 ===

The nfs server should be started with its init script located in {{Path|/etc/init.d}} by typing: 

{{RootCmd|/etc/init.d/nfs start}}

If this script is to be started every time the system boots simply type: 

{{RootCmd|rc-update add nfs default}}

== 完成slave的文件系统 ==

=== 复制缺失的文件 ===

Now the slave's file system will be made in sync with the master's and provide the necessary binaries while still preserving slave specific files. 

{{RootCmd|rsync -avz /bin /diskless/192.168.1.21
|rsync -avz /sbin /diskless/192.168.1.21
|rsync -avz /lib /diskless/192.168.1.21}}

{{Note|The reason for rsync -avz instead of cp is to maintain symlinks and permissions.}}

=== 配置无盘网络 ===

In order to prevent the networking initscript from killing the connection to the NFS server, an option needs to be added to {{Path|/etc/conf.d/net}} on the diskless client's filesystem. 

{{CodeBox|title=编辑{{Path|/etc/conf.d/net}}|1=
config_eth0=( "noop" )
}}

{{Note|For more information, please read {{Path|/usr/share/doc/openrc-*/net.example.bz2}} .}}

=== 初始化脚本 ===

Init scripts for slaves are located under {{Path|/diskless/192.168.1.21/etc/runlevels}} for services needed on the diskless nodes. Each slave can be set up and customized here, it all depends on what each slave is meant to do. 

{{Warning|Do not use the <code>rc-update</code> program to add or remove scripts from the slave runlevels when logged on to the master. This would change the master runlevels. The links need to be manually created or by logging into the slave nodes using ssh or connecting a screen and keyboard to the slave.}}

{{CodeBox|title=slave的典型runlevels|1=
/diskless/192.168.1.21/etc/runlevels/:
total 16
drwxr-xr-x    2 root     root         4096 2003-11-09 15:27 boot
drwxr-xr-x    2 root     root         4096 2003-10-01 21:10 default
drwxr-xr-x    2 root     root         4096 2003-03-13 19:05 nonetwork
drwxr-xr-x    2 root     root         4096 2003-02-23 12:26 single
  
/diskless/192.168.1.21/etc/runlevels/boot:
total 0
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 bootmisc -> /etc/init.d/bootmisc
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 checkfs -> /etc/init.d/checkfs
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 clock -> /etc/init.d/clock
lrwxrwxrwx    1 root     root           22 2003-10-18 17:28 domainname -> /etc/init.d/domainname
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 hostname -> /etc/init.d/hostname
lrwxrwxrwx    1 root     root           22 2003-10-18 17:28 localmount -> /etc/init.d/localmount
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 modules -> /etc/init.d/modules
lrwxrwxrwx    1 root     root           18 2003-10-18 17:28 net.lo -> /etc/init.d/net.lo
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 netmount -> /etc/init.d/netmount
lrwxrwxrwx    1 root     root           21 2003-10-18 17:28 rmnologin -> /etc/init.d/rmnologin
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 urandom -> /etc/init.d/urandom
  
/diskless/192.168.1.21/etc/runlevels/default:
total 0
lrwxrwxrwx    1 root     root           23 2003-10-18 17:28 consolefont -> /etc/init.d/consolefont
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 distccd -> /etc/init.d/distccd
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 keymaps -> /etc/init.d/keymaps
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 local -> /etc/init.d/local
lrwxrwxrwx    1 root     root           16 2003-10-18 17:28 sshd -> /etc/init.d/sshd
lrwxrwxrwx    1 root     root           21 2003-10-18 17:28 syslog-ng -> /etc/init.d/syslog-ng
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 vixie-cron -> /etc/init.d/vixie-cron
  
/diskless/192.168.1.21/etc/runlevels/nonetwork:
total 0
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 local -> /etc/init.d/local
  
/diskless/192.168.1.21/etc/runlevels/single:
total 0
}}

Now is a good time to boot the slave and cross some fingers. It works? Congratulations, you are now the proud owner of (a) diskless node(s).

{{Migrated|originalauthors=Michael Andrews, Kristian Jerpetjoen, Sven Vermeulen, Xavier Neys}}
