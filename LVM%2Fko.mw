<languages />

{{Metadata|abstract=LVM은 관리자가 파일 시스템과 사용중인 물리 저장소간의 추상 레이어를 제공하여 메타 장치를 만들 수 있도록 합니다.}}

{{InfoBox stack
|{{InfoBox wikipedia|Logical Volume Manager (Linux)|header=true}}
}}

'''LVM'''('''L'''ogical '''V'''olume '''M'''anager)은 관리자가 파일 시스템과 사용 중인 물리 저장소 사이의 추상 레이어를 제공하여 메타 장치를 만들 수 있게 합니다. (파일 시스템이 있는)메타 장치는 ''논리 볼륨''이며, 저장소 풀에서 사용하는 저장소를 ''볼륨 그룹'' 이라고 합니다. 볼륨 그룹은 데이터를 저장하는 하나 이상의 ''실제 장치''로 구성되어있습니다.

물리 볼륨은 파티션으로 구성되어 있고, 전체 SATA 하드 디스크 드라이브는 JBOD('''J'''ust a '''B'''unch '''O'''f '''D'''isks), RAID 체계, iSCSI, 광 채널, eSATA 등으로 묶습니다.

== 설치 ==

LVM은 설정을 관리하기 위해 커널 수준의 드라이버와 사용자 영역 프로그램으로 다룹니다.

=== 커널 ===

다음 커널 옵션을 활성화하십시오:

{{Kernel||<pre>
Device Drivers  --->
   Multiple devices driver support (RAID and LVM)  --->
       <*> Device mapper support
           <*> Crypt target support
           <*> Snapshot target
           <*> Mirror target
       <*> Multipath target
           <*> I/O Path Selector based on the number of in-flight I/Os
           <*> I/O Path Selector based on the service time
</pre>}}

{{Note/ko|모두 활성화 할 필요는 없습니다. 어떤 옵션은 [[#LVM2_Snapshots_and_LVM2_Thin_Snapshots|LVM2 스냅샷, LVM2 씬 스냅샷]], [[#LVM2_Mirrors|LVM2 미러]], [[#LVM2_RAID_0.2FStripeset|LVM2 RAID 0/스트라이프 집합]], 암호화에 필요합니다.}}

=== 프로그램 ===

{{Package|sys-fs/lvm2}}를 설치하십시오:

{{USEflag|package=sys-fs/lvm2
|clvm
|cman
|lvm1+yes
|readline+yes
|selinux++no
|static
|static-libs
|thin+yes
|udev+yes
}}

{{Emerge|lvm2}}

== 설정 ==

LVM 설정은 다음 몇가지 단계에서 처리할 수 있습니다:
# 관리 유틸리티를 통한 LV, PV, VG 관리
# 설정 파일을 통한 LVM 하위시스템 세부 설정
# 분산 차원 서비스 관리
# 초기화 RAM 파일 시스템 설정

논리, 물리 볼륨 및 볼륨 그룹의 관리는 [[#Usage|사용법]] 장에서 다룹니다.

=== LVM 설정 파일 ===

LVM은 {{Path|/etc/lvm/lvm.conf}}에 더 많이 설정할 수 있는 파일이 있습니다. 대부분의 사용자는 LVM 사용을 시작하는데 이 파일의 설정을 수정할 필요가 없습니다.�

=== 서비스 관리 ===

젠투에서는 볼륨 그룹과 논리 볼륨을 자동으로 감지하고 활성화 하는 LVM 서비스를 제공합니다.

서비스는 init 시스템에서 관리할 수 있습니다.

==== openrc ====

LVM을 별도로 시작하려면:

{{RootCmd|/etc/init.d/lvm start}}

부팅시 LVM을 시작하려면:

{{RootCmd|rc-update add lvm boot}}

==== systemd ====

lvm을 별도로 시작하려면:

{{RootCmd|systemctl start lvm2-monitor.service}}

부팅할 때 LVM을 시작하려면:

{{RootCmd|systemctl enable lvm2-monitor.service}}

=== initramfs에서 LVM 사용하기 ===

대부분의 부트 로더는 LVM에서 직접 부팅할 수 있습니다. 기존의 GRUB은 물론이고 LILO에서도 안됩니다. Grub2는 LVM 선형 논리 볼륨, 미러링한 논리 볼륨, 몇가지 RAID 논리 볼륨으로 부팅할 수 있습니다. 씬 논리 볼륨을 지원하는 부트로더는 없습니다. 

이런 이유로, /boot 파티션은 비 LVM 파티션으로 사용하고 initramfs에서 LVM 루트를 마운트하는 방식을 권장합니다. initramfs 같은요소는 [[Genkernel|genkernel]], genkernel-next, [[dracut]]에서 자동으로 만들 수 있습니다:

* '''genkernel'''은 씬 볼륨(빌드 호스트에서 나온 thin-provisioning-tools 바이너리 사본이나 빌드도 마찬가지로)과 RAID10(RAID10은 LVM10 2.02.98을 필요로 하겠지만, genkernel은 2.02.89를 빌드하는데, 정적 바이너리가 있다면 복사할 수 있습니다)을 제외한 모든 형식의 파티션에서 부팅할 수 있습니다.
* '''genkernel-next'''에서는 모든 형식의 볼륨에서 부팅할 수 있습니다만, 충분히 최신의 app-misc/pax-utils가 필요하며, 그렇지 않으면 씬 바이너리가 깨집니다({{Bug|482504}} 참고)
* '''dracut'''은 모든 형식의 볼륨에서 부팅하지만, 씬 루트가 있는 상태에서 호스트가 동작하는 경우 initramfs에서 씬을 지원하는 호스트에서만 부팅합니다.

==== Genkernel/Genkernel-next ====

{{Package|sys-kernel/genkernel}} 또는 {{Package|sys-kernel/genkernel-next}} 둘 중 하나를 이머지하십시오. {{Package|sys-fs/lvm2}} 패키지를 이머지할 때는 static USE 플래그를 활성화하여 genkernel이 시스템 바이너리를 사용할 수 있게 하십시오(그렇지 않으면 자체 사본을 만듭니다). 다음 예제에서는 initramfs(전체 커널 아님)만 빌드하며 lvm 지원을 활성화합니다.

{{RootCmd|genkernel --lvm initramfs}}

genkernel 맨페이지에서는 시스템 요구사항에 따라 다른 옵션을 설명합니다.

initrd는 lvm 시작 방법을 알리는 매개 변수가 필요하며, 다른 커널 매개 변수를 넣는 동일한 방식으로 처리합니다. 예를 들면:

{{File|/etc/default/grub|dolvm을 커널 부팅 매개변수로 넣기|<pre>
GRUB_CMDLINE_LINUX="dolvm"
</pre>}}

==== Dracut ====

{{Package|sys-kernel/dracut}} 꾸러미는 레드햇 프로젝트에서 이식했으며, initramfs를 만드는 유사한 도구를 제공합니다. 시험 목적으로 ~arch 상태에 있기 때문에 이머지를 하려면 사용자 여러분은( {{Path|/etc/portage/package.accept_keywords}} 에서)[[Knowledge_Base:Accepting_a_keyword_for_a_single_package|이 글대로 하셔야합니다]]. 이 과정을 수행하기 전에 {{Path|/etc/portage/make.conf}}에 <code>DRACUT_MODULES="lvm"</code>를 추가해야 합니다. 다른 모듈을 사용한다면, [[Dracut]]을 참고하십시오. 보통 다음 명령을 통해, 활용 가능한 기본 initramfs를 만듭니다.

{{RootCmd|dracut -a lvm}}

initrd는 lvm 시작 방법을 알리는 매개 변수가 필요하며, 다른 커널 매개 변수를 넣는 동일한 방식으로 처리합니다. 예를 들면:

{{File|/etc/default/grub|LVM 지원을 커널 부팅 매개변수로 넣기|<pre>
GRUB_CMDLINE_LINUX="rd.lvm.vg=vol00"
</pre>}}

dracut에서 활용하는 lvm 옵션 실제 목록을 보려면 [https://www.kernel.org/pub/linux/utils/boot/dracut/dracut.html#_lvm Dracut 설명서]의 LVM 장을 참고하십시오.

== 사용법 ==

LVM은 다음 세가지 레벨의 저장소로 구성되어 있습니다:
* 하드 디스크 드라이브, 파티션, RAID 시스템 또는 저장소의 다른 개념을 물리 볼륨(PV)으로 초기화합니다
* 물리 볼륨(PV)은 볼륨 그룹(VG)으로 묶습니다
* 논리 볼륨(LV)은 볼륨 그룹(VG)에서 관리합니다

=== PV(물리 볼륨) ===
물리 볼륨은 LVM을 구축할 실제 하드웨어 또는 저장장치 입니다.

==== 공간 분할 ====

{{Note/ko|단일 LVM 볼륨 그룹에 대해 전체 디스크를 활용하고 싶지 않을 경우에만 볼륨 그룹으로 저장소를 관리하려는 목적의 각 분할 공간 활용이 필요합니다. 전체 디스크를 활용할 가능성이 있다면 이 단계를 건너뛰고 전체 하드디스크 드라이브를 물리 볼륨으로 초기화 하십시오.}}

''LVM''의 분할 공간 형식은 ''8e''(Linux LVM)입니다.

가령,  <code>fdisk</code>로 {{Path|/dev/sda}}의 파티션을 설정한다면:

{{RootCmd|fdisk /dev/sda}}

<code>fdisk</code>에서, 분할 공간을 만들려면 '''n'''키를 사용하고, '''t'''키를 사용하여 분할 공간 형식을 ''8e''로 바꾸십시오.

=== PV 만들기 ===

물리 볼륨은 <code>pvcreate</code>명령으로 만들고 초기화 할 수 있습니다.

가령, 다음 명령을 사용하면 {{Path|/dev/sda}}와 {{Path|/dev/sdb}}의 첫번째 처음 파티션의 물리 볼륨을 만듭니다:

{{RootCmd|pvcreate /dev/sd[ab]1}}

==== PV 목록 표시 ====

<code>pvdisplay</code> 명령으로 시스템에 활성화 된 모든 물리 볼륨의 개요를 볼 수 있습니다.

{{RootCmd|pvdisplay|output=<pre>
 --- Physical volume ---
  PV Name               /dev/sda1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               4098
  Allocated PE          36864
  PV UUID               3WHAz3-dh4r-RJ0E-5o6T-9Dbs-4xLe-inVwcV
  
 --- Physical volume ---
  PV Name               /dev/sdb1
  VG Name               volgrp
  PV Size               160.01 GiB / not usable 2.31 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              40962
  Free PE               40962
  Allocated PE          0
  PV UUID               b031x0-6rej-BcBu-bE2C-eCXG-jObu-0Boo0x
</pre>}}

더 많은 물리 볼륨을 표시해야 한다면, <code>pvscan</code> 명령으로 비활성화된 물리 볼륨을 감지하고, 활성화 할 수 있습니다.

{{RootCmd|pvscan|output=<pre>
  PV /dev/sda1  VG volgrp        lvm2 [160.01 GiB / 16.01 GiB free]
  PV /dev/sdb1  VG volgrp        lvm2 [160.01 GiB / 160.01 GiB free]
  Total: 2 [320.02 GB] / in use: 2 [320.02 GiB] / in no VG: 0 [0]
</pre>}}

==== PV 제거 ====

LVM은 (다른 방식을 언급하지 않는 한)존재하는 모든 물리 볼륨에 데이터를 넣는데, 연속적인 접근 방식으로 넣습니다. (볼륨 그룹 내)논리 볼륨 논리 볼륨이 단일 물리 볼륨의 남은 공간보다 적다면, 논리 볼륨의 모든 공간을 (단일) 물리 볼륨에 연속적인 형태로 위치하도록 합니다. 이러한 조치는 성능상 이유로 처리됩니다.

볼륨 그룹에서 물리 볼륨을 제거해야 한다면, 물리 볼륨에서 데이터를 먼저 이동해야 합니다. <code>pvmove</code> 명령을 사용하면, 동일한 볼륨 그룹 내에서 물리 볼륨의 모든 데이터를 다른 물리 볼륨으로 이동합니다.

{{RootCmd|pvmove -v /dev/sda1}}

이런 과정은 옮겨야 하는 데이터의 양에 따라 시간이 걸릴 수 있습니다. 이 과정이 끝나면, 장치에 남은 데이터가 없어야 합니다. <code>pvdisplay</code> 명령으로 물리 볼륨을 어떤 논리 볼륨에서도 더 이상 사용하지 않는지 확인하십시오.

다음 단계는 <code>vgreduce</code> 명령으로 볼륨 그룹에서 물리 볼륨을 제거할 차례이며, <code>pvremove</code> 명령으로 물리 볼륨의 ''선택을 해제'' 할 수 있습니다.

{{RootCmd|vgreduce vg0 /dev/sda1 && pvremove /dev/sda1}}

=== VG(볼륨 그룹) ===

볼륨 그룹(VG)은 수많은 물리 볼륨을 묶고 장치 파일 시스템에 {{Path|/dev/VG_NAME}}와 같은 식으로 보여줍니다. 볼륨 그룹의 이름은 관리자가 선택합니다.

==== VG 만들기 ====

다음 명령은 {{Path|/dev/sda1}}과 {{Path|/dev/sdb1}} 물리 볼륨을 묶어 ''vg0''이라 하는 볼륨 그룹을 만듭니다.

{{RootCmd|vgcreate vg0 /dev/sd[ab]1}}

==== VG 목록 표시 ====

모든 활성화 볼륨 그룹의 목록을 표시하려면, <code>vgdisplay</code> 명령을 사용하십시오:

{{RootCmd|vgdisplay|output=<pre>
  --- Volume group ---
  VG Name               vg0
  System ID             
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  8
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                6
  Open LV               6
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               320.02 GiB
  PE Size               4.00 MiB
  Total PE              81924
  Alloc PE / Size       36864 / 144.00 GiB
  Free  PE / Size       45056 /176.01 GiB
  VG UUID               mFPXj3-DdPi-7YJ5-9WKy-KA5Y-Vd4S-Lycxq3
</pre>}}

볼륨 그룹이 빠져있으면 볼륨 그룹을 찾아 가리키는 <code>vgscan</code> 명령을 사용하십시오:

{{RootCmd|vgscan|output=<pre>
  Reading all physical volumes.  This may take a while...
  Found volume group "vg0" using metadata type lvm2
</pre>}}

==== VG 확장 ====

볼륨 그룹은 관리자가 파일 시스템에 할당하는 저장소 자원 풀을 사용하도록 하며, 물리 볼륨을 묶습니다. 볼륨 그룹이 충분한 저장소 자원을 가지지 않았다면, 추가 물리 볼륨에 대해 볼륨 그룹을 확장할 필요가 있습니다.�

다음 예제 에서는 ''vg0'' 그룹을  {{Path|/dev/sdc1}} 물리 볼륨으로 확장합니다:

{{RootCmd|vgextend vg0 /dev/sdc1}}

물리 볼륨을 각각 준비해야 함을 기억하십시오!

==== VG 줄이기 ====

논리 볼륨을 볼륨 그룹에서 제거해야 한다면, 물리 볼륨에서 사용중인 모든 데이터를 볼륨 그룹의 다른 물리 볼륨으로 이동해야 합니다. 앞에서 보신 바와 같이, <code>pvmove</code> 명령으로 처리할 수 있으며, 그 다음에 <code>vgreduce</code> 명령으로 볼륨 그룹에서 물리 볼륨을 제거할 수 있습니다:

{{RootCmd|pvmove -v /dev/sdc1
|vgreduce vg0 /dev/sdc1}}

==== VG 제거 ====

볼륨 그룹이 더이상 필요하지 않다면(또는, 다른 말로, 저장소 풀을 더이상 사용하지 않으며, 다른 목적으로 물리 볼륨을 해제해야 할 경우),  <code>vgremove</code> 명령으로 볼륨 그룹을 제거할 수 있습니다. 볼륨 그룹에 정의한 논리 볼륨이 없고 하나의 완전한 물리 볼륨을 풀에서 제거 했을 경우에만 동작합니다.

{{RootCmd|vgremove vg0}}

=== LV(논리 볼륨) ===

논리 볼륨은 시스템에 존재하는 최종 메타 장치이며, 보통 파일 시스템에 만듭니다. 볼륨 그룹에 만들고 관리하며 {{Path|/dev/VG_NAME/LV_NAME}} 형식으로 나타납니다. 볼륨 그룹처럼, 논리 볼륨에 사용하는 이름은 관리자가 결정합니다.

==== LV 만들기 ===

논리 볼륨을 만들려면 <code>lvcreate</code> 명령을 사용합니다. 명령의 매개 변수는 논리 볼륨에 요청하는 크기(볼륨 그룹의 남은 공간 용량보다 클 수 없음), 요청한 볼륨 그룹, 만들 논리 볼륨 공간의 이름으로 구성됩니다.

다음 예제에서는 ''vg0'' 볼륨 그룹에 150MB 용량의 ''lvol1'' 논리 볼륨을 만듭니다:

{{RootCmd|lvcreate -L 150M -n lvol1 vg0}}

<code>lvcreate</code> 명령으로 볼륨 그룹 내의 모든 남은 용량을 사용하도록 할 수 있습니다. (판독할 수 있는) 크기를 적기보다는 ''확장 용량'' 모두를 선택하는 ''-l'' 매개 변수로 처리할 수 있습니다. 논리 볼륨은 볼륨 그룹 내의 데이터 덩어리인 ''논리 확장''으로 나뉩니다. 모든 논리 그룹의 확장은 동일한 크기를 갖습니다. ''-l'' 매개 변수를 활용하면 <code>lvcreate</code> 명령으로 전체 남은 확장 공간을 할당하도록 요청할 수 있습니다.

{{RootCmd|lvcreate -l 100%FREE -n lvol1 vg0}}

''FREE'' 다음에 ''VG'' 키를 사용하여 볼륨 그룹의 전체 크기를 표시할 수 있습니다.

==== LV 목록 표시 ====

모든 논리 볼륨 내용을 표시하려면 <code>lvdisplay</code> 명령을 사용하십시오:

{{RootCmd|lvdisplay}}

논리 볼륨이 빠져있다면, <code>lvscan</code> 명령으로 존재하는 모든 볼륨 그룹의 논리 볼륨을 검색할 수 있습니다.

{{RootCmd|lvscan}}

==== LV 확장 ====

논리 볼륨을 확장하려면, <code>lvextend</code> 명령으로 논리 볼륨에 할당한 공간을 늘릴 수 있습니다.

가령, 논리 볼륨 ''lvol1''의 전체 용량을 500MB로 확장하려면:

{{RootCmd|lvextend -L500M /dev/vg0/lvol1}}

전체 용량보다 더 큰 용량을 추가할 수도 있습니다:

{{RootCmd|lvextend -L+350MB /dev/vg0/lvol1}}

확장 볼륨 그룹은 최종 사용자에게 추가 저장소로서 바로 제공할 수 없습니다. 그렇기에, 볼륨 그룹의 최상단에 있는 파일 시스템을 마찬가지로 늘려야 합니다. 마운트한 상태에서 모든 파일 시스템의 크기를 조정할 수 있는 것은 아니기에, 파일 시스템의 궁금증에 대해 더 많은 내용을 살펴보려면 문서를 확인하십시오.

가령, ext4 파일 시스템ㅁ의 크기를 500MB 크기로 조절하려면:

{{RootCmd|resize2fs /mnt/data 500M}}

==== LV 줄이기 ====

논리 볼륨의 크기를 줄여야 한다면, 먼저 파일 시스템 자체의 크기를 줄이십시오. 모든 파일 시스템이 마운트한 상태에서 용량 줄이기 기능을 지원하는 것은 아닙니다.

가령, ext4는 마운트한 상태에서 용량 줄이는 기능을 지우너하지 않으므로, 먼저 파일 시스템의 마운트를 해제해야합니다. 그리고 파일 시스템을 검사하여 파일 시스템의 무결성 확인을 추천합니다:

{{RootCmd|umount /mnt/data
|e2fsck -f /dev/vg0/lvol1
|resize2fs /dev/vg0/lvol1 150M}}

용량이 줄어든 파일 시스템을 통해, 마찬가지로, 이제 논리 볼륨의 용량을 줄일 수 있습니다:

{{RootCmd|lvreduce -L150M /dev/vg0/lvol1}}

==== LV 사용 권한 ====

LVM에서는 논리 볼륨에 대해 권한 상태 조정 기능을 지원합니다.

가령, <code>lvchange</code> 명령으로 논리 볼륨을 ''읽기 전용'' 상태로 설정할 수 있습니다:

{{RootCmd|lvchange -p r /dev/vg0/lvol1
|mount -o remount /dev/vg0/lvol1}}

바뀐 내용을 즉시 강제로 적용하지 않았기 때문에 다시 마운트해야 합니다.

논리 볼륨을 쓰기 가능상태로 다시 처리하려면 ''rw'' 퍼미션 비트를 사용하십시오:

{{RootCmd|lvchange -p rw /dev/vg0/lvol1 && mount -o remount /dev/vg0/lvol1}}

==== LV 제거 ====

논리 볼륨을 제거하기 전에 더이상 마운트한 볼륨이 없는지 확인하십시오:

{{RootCmd|umount /dev/vg0/lvol1}}

논리 볼륨을 비활성화하여 더이상 쓰기 동작을 할 수 없게 하십시오:

{{RootCmd|lvchange -a n /dev/vg0/lvol1}}

볼륨 마운트를 해제하여 비활성화 하면, 이제 제거하고, 볼륨 그룹에서 다른 논리 볼륨이 사용하도록 확장 할당을 해제할 수 있습니다.

{{RootCmd|lvremove /dev/vg0/lvol1}}

== 기능 ==

LVM에서는 저장소 관리자에게 다음과 같은 몇가지(라지만 약간 제한이 있는) 괜찮은 기능을 제공합니다
* 씬 관리(오버 커밋 저장소)
* 스냅샷 지원
* 다른 저장소 할당 방식에 따른 볼륨 형식

=== 씬 관리 ===

LVM2 최근 버전(2.02.89)에서는 ''씬'' 볼륨을 지원합니다. 씬 볼륨은 파일 시스템에 파일이 드문드문 분산해서 들어가는 블록 장치입니다. 따라서, 풀에 있는 씬 논리 볼륨은 ''오버 커밋'' 이 가능합니다. 즉, 할당한 크기보다 나타난 크기가 클 수는 있습니다. 풀 자체 크기보다 클 수도 있습니다. 드문드문 분산된 파일 처럼, 확장체는 블록 장치로 할당됩니다. 파일을 제거했을 때 다시 빈 공간이 늘어나 남은 영역을 파일 시스템에서 ''버리는'' 기능을 지원한다면 풀의 공간 가용성이 줄어듭니다.

LVM에서 각각의 씬 풀은 특별한 형식의 논리 볼륨이며, 논리 볼륨을 자체적으로 제공할 수 있습니다.

=== 씬 풀 만들기 ===

{{Warning/ko|씬 풀 메타데이터에서 오버플로우가 발생하면 풀이 깨집니다. '''LVM에서는 이러한 현상을 복구할 수 없습니다'''.}} 

{{Note/ko|씬 풀의 용량이 고갈되면 씬 풀을 확장하거나 프로세스에서 SIGKILL 시그널을 받기 전까지는, 어떤 프로세스든 (존재하지 않는)더 많은 공간을 할당하려는 씬 풀의 상태가 ''죽일 수 있는 대기'' 상태에 봉착합니다.}}

각각의 씬 풀에는 관련 메타데이터가 있으며, 씬 풀 용량에 추가됩니다. LVM에서는 크기가 어떻게 되든지간에 최소한 <tt>pool_chunks * 64 bytes</tt> 또는 2MiB 만큼 씬 풀 크기를 기반으로 메타데이터 크기를 계산합니다. 관리자는 마찬가지로 메타데이터 크기를 달리 선택할 수 있습니다.

씬 풀을 만들려면 <code>lvcreate</code> 명령에 ''--type thin-pool --thinpool thin_pool'' 매개변수를 추가하십시오:

{{RootCmd|lvcreate -L 150M --type thin-pool --thinpool thin_pool vg0}}

위의 예제에서는 ''thin_pool''을 총 150MB의 용량으로 만듭니다. 150MB는 씬 풀에 실제 할당한 크기입니다(그렇기 때문에 실제 저장소에서 활용할 수 있는 전체 공간이 됩니다).

각각의 메타데이터 크기를 분명하게 요청하려면 ''--metadatasize'' 매개변수를 사용하십시오:

{{RootCmd|lvcreate -L 150M --metadatasize 2M --type thin-pool --thinpool thin_pool vg0}}

씬 풀에 추가한 메타데이터 때문에, 볼륨 그룹에서 논리 볼륨에 대해 사용 가능한 전체 공간을 활용하는 직관적인 방법이 먹혀들지 않습니다(LVM 버그 [https://bugzilla.redhat.com/show_bug.cgi?id=812726|812726] 참고).

{{RootCmd|lvcreate -l 100%FREE --type thin-pool --thinpool thin_pool vg0|output=<pre>
Insufficient suitable allocatable extents for logical volume thin_pool: 549 more required
</pre>}}

씬 풀에는 다른 LV의 노드처럼 관련 장치 노드가 있는것이 아닙니다.

==== 씬 논리 볼륨 만들기 ====

''씬 논리 볼륨''은 씬 풀에 있는 논리 볼륨입니다(씬 풀 자체는 논리 볼륨입니다). 씬 논리 볼륨이 ''듬성듬성'' 하기에, ''-V'' 매개 변수로 물리 크기 대신 가상 크기를 설정합니다:

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -n lvol1}}

이 예제에서, 실제 할당한 저장소의 크기가 150MB라 하더라도, (씬) 논리 볼륨 ''lvol1''은 300MB 크기의 장치로 나타납니다.

씬 풀의 논리 볼륨처럼 각각의 씬 풀을 하나의 명령으로 만들 수 있습니다:

{{RootCmd|lvcreate -T vg0/thin_pool -V 300M -L150M -n lvol1}}

==== 씬 풀과 씬 논리 볼륨 목록 표시 ====

씬 풀과 씬 논리 볼륨은 논리 볼륨의 특별한 형식이며, <code>lvdisplay</code> 명령으로 표시합니다. <code>lvscan</code> 명령은 이들 논리 볼륨도 감지합니다.

==== 씬 풀 확장 ====

{{Warning/ko|LVM2 2.02.89에서는 씬 풀의 메타데이터 크기가 만들 때부터 정해져 있어 늘릴 수 없습니다}}

<code>lvextend</code> 명령을 사용하면 씬 논리 볼륨이 아닌 다른 볼륨처럼 확장할 수 있습니다. 예를 들면 다음과 같습니다:

{{RootCmd|lvextend -L500M vg0/thin_pool}}

==== 씬 논리 볼륨 확장 ====

씬 논리 볼륨은 보통 논리 볼륨처럼 확장됩니다:

{{RootCmd|lvextend -L1G vg0/lvol1}}

<code>lvextend</code> 명령에서 ''-L'' 옵션(또는 확장 카운트를 활용한다면 ''-l'')을 활용하며 씬 논리 볼륨을 만들 때 활용했던 ''가상 크기'' 옵션이 아닙니다. 

==== 씬 풀 줄이기 ====

현재 LVM에서는 씬 풀의 크기를 줄일 수 없습니다. LVM 버그 [https://bugzilla.redhat.com/show_bug.cgi?id=812731|812731]을 참고하십시오.

==== 씬 논리 볼륨 줄이기 ====

씬 논리 볼륨은 보통 논리 볼륨처럼 줄입니다.

가령:
{{RootCmd|lvreduce -L300M vg0/lvol1l}}

<code>lvreduce</code> 명령은 ''-L'' 옵션(또는 확장 카운트를 사용할 경우 ''-l'')을 사용하며, 만들기 과정에 사용한 ''가상 크기'' 옵션은 아님에 유의하십시오.

==== 씬 풀 제거 ====

씬 풀은 내부에 있는 모든 씬 논리 볼륨을 제거하기 전까지는 제거할 수 없습니다.

씬 풀에서 더 이상 어떤 씬 논리 볼륨을 제공하지 않는다면, <code>lvremove</code>명령으로 제거할 수 있습니다:

{{RootCmd|lvremove vg0/thin_pool}}

=== LVM2 스냅샷과 씬 스냅샷 ===

스냅샷은 다른 논리 볼륨의 사본처럼 동작하는 논리 볼륨입니다. 스냅샷을 만든 횟수만큼 원래 논리 볼륨의 상태를 나타냅니다.

=== 스냅샷 논리 볼륨 만들기 ===

스냅샷 논리 볼륨은 <code>lvcreate</code> 명령에 ''-s'' 옵션을 사용하여 만듭니다. 스냅샷 논리 볼륨은 본래 논리 볼륨에서 바뀐 상태를 저장하는 LVM ''레지스터'' 처럼 할당한 상태 저장소이며, 스냅샷에 할당한 저장소에 이들 바뀐 내용을 저장합니다. 스냅샷 상태를 요청하면, LVM에서는 초기 논리 볼륨에서 시작해서 등록한 모든 바뀐 상태를 검사하며, 사용자에게 결과를 보여주기 전에 바뀐 내용을 ''실행 취소'' 처리합니다.

A snapshot logical volume henceforth "growths" at the rate that changes are made on the original logical volume. When the allocated storage for the snapshot is completely used, then the snapshot will be removed automatically from the system.

{{RootCmd|lvcreate -l 10%VG -s -n 20140412_lvol1 /dev/vg0/lvol1}}

위 예제에서 ''vg0'' 볼륨 그룹의 ''lvol1'' 논리 볼륨을 기반으로 ''20140412_lvol1''라고 하는 스냅샷 논리 볼륨을 만듭니다. 볼륨 그룹에 할당한 공간의 10%(실제로 더 많이)를 사용합니다.

==== 스냅샷 논리 볼륨 접근 ====

스냅샷 논리 볼륨은 보통 논리 볼륨처럼 마운트 할 수 있습니다. 심지어 읽기 전용 처리에 구애받지 않습니다. 스냅샷을 수정할 수도 있기 때문에 ''프로덕션'' 파일 시스템에서 뭔가를 수행하기 전에 바뀐 내용을 시험하는 등의 용도로 활용합니다.

스냅샷 논리 볼륨이 존재하는 동안, 보통의 원래 논리 볼륨의 크기를 줄이거나 제거할 수 없습니다.

==== LVM 씬 스냅샷 ====

{{Note/ko|씬 스냅샷은 씬 논리 볼륨의 씬 풀에서만 취할 수 있습니다. 씬 장치 매퍼 타겟은 읽기 전용 비 씬 논리 볼륨의 씬 스냅샷을 지원하지만 LVM2 도구에선 지원하지 않습니다. 다만, 씬 논리 볼륨의 일반(비 씬) 스냅샷 논리 볼륨을 만들 수는 있습니다.}}

씬 스냅샷을 만들려면, <code>lvcreate</code> 명령에 <code>-s</code> 옵션을 붙여 사용하십시오. 크기를 지정하여 전달할 필요가 없습니다:

{{RootCmd|lvcreate -s -n 20140413_lvol1 /dev/vg0/lvol1}}

씬 논리 볼륨 스냅샷은 초기 씬 논리 볼륨과 동일한 크기를 지니며, 물리 할당 0번은 다른 모든 씬 논리 볼륨과 동일하게 활용합니다. 

{{Important/ko|''-l''또는 ''-L''을 지정해도 스냅샷을 만듯지만, 결과 스냅샷은 씬 스냅샷이 아닌 일반 스냅샷이 됩니다.}}

스냅샷의 스냅샷을 취할 수도 있습니다:

{{RootCmd|lvcreate -s -n 1_20140413_lvol1 /dev/vg0/20140413_lvol1}}

씬 스냅샷을 기존 스냅샷에 비해 여러가지 장점이 있습니다. 먼저, 씬 스냅샷은 원래 만들어놓은 논리 볼륨에 독립적입니다. 초기 논리 볼륨은 스냅샷에 영향을 주지 않고 크기를 줄이거나 삭제할 수 있습니다. 두번째로, 씬 스냅샷은 일반 재귀적 LVM 스냅샷의 ''체이닝'' 오버헤드 없이 효율적으로 재귀적으로(스냅샷의 스냅샷) 만들 수 있습니다.

==== 스냅샷 상태로 되돌리기 ====

스냅샷의 버전으로 논리 볼륨을 되돌리려면 다음 명령을 사용하십시오:

{{RootCmd|lvconvert --merge /dev/vg0/20140413_lvol1}}

볼륨의 크기에 따라 몇 분 걸릴 수도 있습니다.

{{Important/ko|스냅샷이 사라지며, 바뀐 내용은 되돌릴 수 없습니다}}

==== 씬 스냅샷으로 되돌리기 ====

씬 볼륨에 대해, <code>lvconvert --merge</code> 명령은 동작하지 않습니다. 대신 원래 논리 볼륨을 삭제하고 스냅샷의 이름을 바꿉니다.

{{RootCmd|umount /dev/vg0/lvol1
|lvremove /dev/vg0/lvol1
|lvrename vg0/20140413_lvol1 lvol1}}

=== 다른 저장소 할당 방법 ===

LVM에서는 저장소에 대해 여러가지 할당 방식을 지원합니다:
* 선형 볼륨(기본)
* 미러링(복제) 볼륨(활성화/대기 설정이 더 혹은 덜할 수 있음)
* 스트라이핑(RAID0)
* 미러링(복제) 볼륨(RAID1 - 활성화/활성화 설정이 더 많음)
* 패리티 스트라이핑(RAID 4/5)
* 이중 패리티 스트라이핑(RAID 6)
* 스트라이핑+미러링(복제) (RAID10)

==== 선형 볼륨 ====

리니어 볼륨은 대부분의 LVM 볼륨 중 한 종류입니다. LVM은 가능한한 물리적으로 연속된 공간으로 논리 볼륨을 할당하려 할 것입니다. 충분히 큰 용량을 지닌 전체 논리 볼륨이 되도록 하는 물리 볼륨이 있다면, LVM이 해당 물리 볼륨을 할당할 것이며, 그렇지 않으면 가능한한 최소한으로 볼륨을 쪼갭니다.

볼륨 그룹과 논리 볼륨을 만드는데 앞에서 언급한 명령으로 선형 볼륨을 만드십시오.

선형 볼륨에는 특별한 요구사항이 없기 때문에 조작하기 쉬우며, 크기를 조절하고 위치를 다시 잡을 수 있습니다. 논리 볼륨을 다중 물리 볼륨에 걸쳐 할당했는데, 어떤 물리 볼륨이 존재하지 않게 되면, 논리 볼륨을 더이상 시작할 수 없고 사용할 수 없게 됩니다.

==== 미러링 볼륨 ====

LVM 에서는 ''미러링''(복제) 볼륨을 지원하며, 드라이브가 망가진 상황에서 내고장성을 보장합니다. RAID1과는 달리 성능 이득은 없습니다. 모든 읽기 쓰기 동작은 단일 미러로 처리합니다.

미러 상태를 유지하려, LVM 에서는 유지 ''로그''가 필요합니다. 그 어떤 미러 논리 볼륨이 들어있지 않은 물리 볼륨의 로그에 이 로그를 넣으시는 것이 좋(으며 심지어는 필수로 권장)습니다. 미러에 활용할 로그에는 세가지 종류가 있습니다:

# '''Disk''' is the default log type. All changes made are logged into extra metadata extents, which LVM manages. If a device fails, then the changes are kept in the log until the mirror can be restored again.
# '''Mirror''' logs are '''disk''' logs that are themselves mirrored. 
# '''Core''' mirror logs record the state of the mirror in memory only. LVM will have to rebuild the mirror every time it is activated. This type is useful for temporary mirrors.

단일 미러에 논리 볼륨을 만들려면 ''-m 1'' 인자를 전달하고 각각의 로그 형식을 선택하려면 ''--mirrorlog''를 추가로 선택하십시오:

{{RootCmd|lvcreate -m 1 --mirrorlog mirror -l 40%VG --nosync -n lvol1 vg0}}

<tt>-m 1</tt>옵션이 LVM에게 하나의 (추가) 미러를 만들으라고 지시하므로, 2개의 물리 볼륨을 필요로 합니다. <tt>--nosync</tt> 옵션은 최적화 목적입니다. 이 옵션이 없으면 LVM에서는 하나의 논리 볼륨으로부터 다른 논리 볼륨으로 빈 섹터를 복사하는 미러 동기화를 시도합니다.

현재 논리 볼륨의 미러를 만들 수 있습니다:

{{RootCmd|lvconvert -m 1 -b vg0/lvol1}}

''-b'' 옵션은 백그라운드에서 컨버전을 수행하며 조금 걸릴 수 있습니다.

미러를 제거하려면, 미러 번호를 0으로 (되돌려) 설정하십시오:

{{RootCmd|lvconvert -m0 vg0/lvol1}}

미러 부분을 사용할 수 없다면(보통 물리 볼륨이 들어간 디스크가 망가졌기 때문), 볼륨 그룹을 디그레이드 모드로 전환해야 합니다:

{{RootCmd|vgchange -ay --partial vg0}}

초기 기록시, LVM에서는 미러가 깨졌음을 알립니다. 기본 정책(''remove'')은 존재하는 부분의 수에 따라 미러를 자동으로 줄이거나 해제합니다. 물리 볼륨이 빠진 3-웨이 미러는 2-웨이 미러로 줄어듭니다. 이런식으로 2-웨이 미러는 일반 선형 볼륨으로 줄어듭니다. 고장이 일시적이고, LVM이 미러를 깨먹고 난 후 물리 볼륨이 돌아온다면, 미러링한 논리 볼륨을 다시 만들어야합니다. 

미러를 복원하려면 고장난 물리 볼륨을 볼륨 그룹에서 제거해야 하며 교체한 물리 볼륨을 추가해야 합니다(또는 볼륨 그룹에 물리 뵬륨이 없다면, 물리 볼륨을 하나 만들 수 있습니다). 이렇게 하고 나면 볼륨 그룹에서 제거할 수 있는 이전 물리 볼륨을 가리키는 지점에 <tt>lvconvert</tt> 명령으로 미러를 다시 만들 수 있습니다:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert -b -m 1 --mirrorlog disk vg0/lvol1
|vgreduce --removemissing vg0}}

이 명령을 수행하면 한쪽에서 고장이 나면 LVM이 다른 물리 볼륨에 자유 확장 공간으로 미러를 다시 만들게 할 수 있습니다. 동작을 수행하려면 {{Path|lvm.conf}}에 <code>mirror_image_fault_policy</code>값을 ''allocate''로 설정하십시오.

==== 씬 미러 ====

It is not (yet) possible to create a mirrored thin pool or thin volume. It is possible to create a mirrored thin pool my creating a normal mirrored logical volume and then converting the logical volume to a thin pool with <tt>lvconvert</tt>. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning/ko|제대로 동작하게 하려면 LVM 2.02.98 이상이 필요합니다. 이전 버전은 이 기능을 활용할 수 없을 뿐더러 세그 폴트를 일으키고, 볼륨 그룹을 깨먹을 수 있습니다. 또한 미러를 씬 풀로 변환하는 동작으로 미러상의 모든 데이터를 '''파괴'''합니다!}}

{{RootCmd|lvcreate -m 1 --mirrorlog mirrored -l40%VG -n thin_pool vg0
|lvcreate -m 1 --mirrorlog mirrored -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== 스트라이핑(RAID0) ====

선형 볼륨과는 달리, 다중 연속 물리 볼륨이 붙는 경우, 보다 나은 성능을 위해 ''스트라이핑'' 또는 ''RAID 0'' 만들 수 있습니다. 여러 존재하는 물리 볼륨에 대한 저장소 할당 방식을 대체합니다.

세 개의 물리 볼륨에 스트라이프 볼륨을 만들려면:

{{RootCmd|lvcreate -i 3 -l 20%VG -n lvol1_stripe vg0|output=<pre>
Using default stripesize 64.00 KiB
</pre>}}

-i 옵션은 몇 개의 물리 볼륨을 스트라이핑 할 것인지를 나타냅니다.

스트라이프 집합을 미러링 할 수 있습니다. 스트라이프 미러링을 하기 위해 -i와 -m 옵션을 조합할 수 있습니다:

{{RootCmd|lvcreate -i 2 -m 1 -l 10%VG vg0}}

이 명령은 4개의 물리 볼륨에 대해 2개의 물리 볼륨 스트라이프 모음을 만들고 2개의 각기 다른 물리 볼륨에 미러링을 수행합니다. 기존 스트라이프 모음은 <tt>lvconvert</tt> 명령으로 미러링 할 수 있습니다.

다른 논리 볼륨처럼 씬 풀을 스트라이핑 할 수 있습니다. 모든 씬 볼륨은 설정에 따라 풀에서 만들 수 있습니다. 씬 볼륨을 만들때 직접 지정하지마십시오.

기존 볼륨을 스트라이핑 할 수 없을 뿐더러 여러 물리 볼륨에 대해 스트라이핑을 다시 재구성 할 수도 없거니와 다른 RAID 레벨, 선형 볼륨으로 변환할 수도 없습니다. 스트라이프 집합은 미러링 할 수 있습니다. 추가 물리 볼륨으로 스트라이프 집합을 확장할 수 있지만, 초기의 다중 스트라이프 셋에 추가해야 합니다(새 스트라이프 집합이 선형으로 붙는 결과를 가져옵니다).

==== 미러링(RAID1) ====

스트라이핑을 하는 RAID 0과는 달리, RAID 1은 미러링 방식이지만, 원래 LVM 미러링과는 다른 방식으로 구현했습니다. RAID 1에서는, 성능 향상을 위해 물리 볼륨 전체를 읽어들입니다. RAID1 미러가 고장나면 장치를 차단하기 위해 I/O 가 일어나지 않는데, LVM 에서는 기록 과정을 멈출 필요가 없기 때문입니다.

LVM 미러를 활용할 수 있는 곳에서는, RAID1 미러를 각 위치에서 사용할 수 있습니다.  {{Path|lvm.conf}}에 <tt>mirror_segtype_default</tt> 값을 ''raid1''으로 설정하면 LVM에서 보통 미러대신 RAID1 미러를 무조건 만들 수 있습니다.

논리 볼륨을 단일 미러로 만들려면:

{{RootCmd|lvcreate -m 1 --type raid1 -l 40%VG --nosync -n lvm_raid1 vg0}}

미러를 만드는 방식과는 차이점이 있습니다: ''mirrorlog''를 지정하지 않는데, RAID1 논리 볼륨에선 확실한 미러 로그를 지니고 있지 않습니다. 논리 볼륨 안에 만들기 때문입니다.

기존 논리 볼륨을 RAID 1으로 변환할 수 있습니다:

{{RootCmd|lvconvert -m 1 --type raid1 -b vg0/lvol1}}

RAID 1 미러를 제거하려면, 미러 갯수를 0으로 설정하십시오:

{{RootCmd|lvconvert -m0 vg0/lvm_raid1}}

RAID1 부분을 사용할 수 없다면(보통 물리 볼륨이 들어간 디스크가 망가졌기 때문), 볼륨 그룹을 디그레이드 모드로 전환해야합니다:

{{RootCmd|vgchange -ay --partial vg0}}

LVM 미러와는 달리, 기록 동작은 미러링을 깨먹지 않습니다. 고장 현상이 일시적이고, 빠진 물리 볼륨 상태가 되돌아온다면, LVM에서는 전체 논리 볼륨 대신에 오래된 부분을 복제하여 미러를 다시 동기화합니다. 계속 고장 현상이 지속된다면, 고장난 물리 볼륨을 볼륨 그룹에서 제거하고, 교체한 물리 볼륨을 추가해야 합니다(또는 볼륨 그룹에 물리 볼륨이 없다면 다른 물리 볼륨을 추가할 수 있습니다). 그런 다음에야 ''lvconvert''로 미러를 복원할 수 있으며, 이전 물리 볼륨을 볼륨 그룹에서 제거할 수 있습니다:

{{RootCmd|vgextend vg0 /dev/sdc1
|lvconvert --repair -b vg0/lvm_raid1
|vgreduce --removemissing vg0}}

==== 씬 RAID1 ====

(아직은) RAID 1 씬 풀이나 씬 볼륨을 만들 수 없습니다. RAID 1 씬 풀을 보통의 미러링 논리 볼륨을 만들어서 만들 수는 있으며, 이 과정을 거치고 나면 <tt>lvconvert</tt> 명령으로 논리 볼륨을  씬 풀로 변환할 수 있습니다. 2개의 논리 볼륨이 필요합니다: 하나는 씬 풀에 사용하며 하나는 씬 메타 데이터를 위해 사용합니다. 변환 과정을 통해 이들을 단일 논리 볼륨으로 합칩니다.

{{Warning/ko|제대로 동작하려면 LVM 2.02.98 이상이 필요합니다. 이전 버전에서는 기능을 사용할 수 없거나, 세그폴트를 일으키기도 하며 볼륨 그룹을 깨먹습니다. RAID 1을 씬 풀로 변환하면 미러상의 모든 데이터를 '''파괴합니다'''!}}

{{RootCmd|lvcreate -m 1 --type raid1 -l40%VG -n thin_pool vg0
|lvcreate -m 1 --type raid1 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== 패리티 스트라이핑(RAID4와 RAID5) ====

{{Note/ko|패리티 스트라이핑 방식은 최소한 3개의 물리 볼륨이 필요합니다.}}

RAID 0에는 내고장성 보증이 없습니다. 물리 볼륨중 하나가 고장나면 논리 볼륨을 사용할 수 없습니다 RAID 0에 패리티 스트라이프를 추가하면 물리 볼륨이 빠져도 논리 볼륨은 제 기능을 할 수 있습니다. 그런 다음에야 새 물리 볼륨을 내고장성 복원을 위해 추가할 수 있습니다.

Stripsets with parity come in 2 flavors: RAID 4 and RAID 5. Under RAID 4, all the parity stripes are stored on the same physical volume. This can become a bottleneck because all writes hit that physical volume, and it gets worse the more physical volumes are in the array. With RAID 5, the parity data is distributed evenly across the physical volumes so none of them become a bottleneck. For that reason, RAID 4 is rare and is considered obsolete/historical. In practice, all stripesets with parity are RAID 5.

{{RootCmd|lvcreate --type raid5 -l 20%VG -i 2 -n lvm_raid5 vg0}}

데이터 물리 볼륨은 -i로만 정의할 수 있으며, LVM은 패리티 목적으로 자동으로 추가합니다. 따라서 3개의 물리 볼륨이 있는 RAID5에서, ''-i 2''을 전달해야지 ''-i 3''을 전달하면 안됩니다.

물리 볼륨이 고장나면, 볼륨 그룹을 디그레이드 모드로 전환해야합니다:

{{RootCmd|vgchange -ay --partial vg0}}

이 시점에서 볼륨은 정상적으로 동작합니다만, 교체 물리 볼륨을 추가하기 전에는 이 명령으로 어레이를 RAID 0로 강등합니다. 어레이는 강등되지만 성능에는 전혀 영향이 없습니다. 비록 패리티로 빠진 데이터를 재계산 처리할 필요가 있긴 하지만,  남은 데이터에 대한 패리티 블록은 단순한 XOR 연산만을 필요로 합니다. 부하는 디스크 입출력에 비하면 무시해도 될 정도의 수준입니다.

RAID5를 복원하려면:

{{RootCmd|lvconvert --repair vg0/lvm_raid5
|vgreduce --removemissing vg0}}

마찬가지로 RAID5에서 동작하는 물리 볼륨을 바꿀 수 있습니다:

{{RootCmd|lvconvert --replace /dev/sdb1 vg0/lvm_raid5
|vgreduce vg0 /dev/sdb1}}

The same restrictions of stripe sets apply to stripe sets with parity as well: it is not possible to enable striping with parity on an existing volume, nor reshape the stripes with parity across more/less physical volumes, nor to convert to a different RAID level/linear volume. A stripe set with parity can be mirrored. It is possible to extend a stripe set with parity across additional physical volumes, but they must be added in multiples of the original stripe set with parity (which will effectively linearly append a new stripe set with parity).

==== 씬 RAID5 논리 볼륨 ====

It is not (yet) possible to create stripe set with parity (RAID5) thin pools or thin logical volumes. It is possible to create a RAID5 thin pool by creating a normal RAID5 logical volume and then converting the logical volume into a thin pool with <tt>lvconvert</tt>. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, coversion of a RAID5 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid5 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid5 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg00/thin_meta}}

==== Striping with double parity (RAID6) ====

{{Note|RAID6 requires at least 5 physical volumes.}}

RAID 6는 RAID 5와 유사하지만, RAID 6에서는 '''두 개'''의 물리 볼륨 고장을 구할 수 있어, 추가 물리 볼륨에 비용이 들어가는 만큼 RAID5보다 더 우수한 내고장성을 보장합니다. 

{{RootCmd|lvcreate --type raid6 -l 20%VG -i 3 -n lvm_raid6 vg00}}

Like raid5, the -i option is used to specify the number of physical volumes to stripe, excluding the 2 physical volumes for parity. So for a 5 physical volume RAID6, pass on ''-i 3'' and not ''-i 5''.

RAID6 복구는 RAID5와 같습니다.

{{Note|Unlike RAID5 where parity block is cheap to recompute vs disk I/O, this is only half true in RAID6. RAID6 uses 2 parity stripes: One stripe is computed the same way as RAID5 (simple XOR). The second parity stripe is much harder to compute - see [https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf|raid6 (pdf)] for more information.}}

==== 씬 RAID6 논리 볼륨 ====

It is not (yet) possible to create a RAID6 thin pool or thin volumes. It is possible to create a RAID6 thin pool by creating a normal RAID6 logical volume and then converting the logical volume into a thin pool with <tt>lvconvert</tt>. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.

{{Warning|LVM 2.02.98 or above is required for this to work properly. Prior versions are either not capable or will segfault and corrupt the VG. Also, conversion of a RAID6 LV into a thin pool '''destroys''' all existing data in the LV!}}

{{RootCmd|lvcreate --type raid6 -i 2  -l20%VG -n thin_pool vg0
|lvcreate --type raid6 -i 2 -L4MB -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

==== LVM RAID10 ====

{{Note/ko|RAID10은 최소한 4개의 물리 볼륨이 필요합니다. 게다가 LVM 문법에서는 RAID10 형식이 이렇지 않지만, 여러 물리 볼륨이 여러개의 스트라이프와 미러가 되어야 합니다.}}

RAID10은 RAID0과 RAID1의 조합입니다. 논리 볼륨 레벨 대신 스트라이프 레벨에서 미러링을 처리하기 때문에 RAID0+RAID1보다 더 강력하기 때문에 물리 배치를 대칭형으로 둘 필요가 없습니다. RAID10 볼륨은 단일 물리 볼륨의 누락이 일어나도 상관 없으며, 가능한 경우 그 이상의 문제가 발생해도 문제 없습니다.

{{Note/ko|LVM에서는 현재 RAID10을 단일 미러로 제한합니다.}}

{{RootCmd|lvcreate --type raid10 -l 1020 -i 2 -m 1 --nosync -n lvm_raid10 vg0}}

''-i'' 옵션과 ''-m'' 옵션을 지정했습니다: ''-i''는 스트라이프 갯수이며 ''-m''은 미러 갯수입니다. 2개의 스트라이프와 1개의 미러는 4개의 물리 볼륨이 필요합니다.

==== 씬 RAID 10 ====

It is not (yet) possible to create a RAID10 thin pool or thin volumes. It is possible to create a RAID10 thin pool by creating a normal RAID10 logical volume and then converting the logical volume into a thin pool with <code>lvconvert</code>. 2 logical volumes are required: one for the thin pool and one for the thin metadata; the conversion process will merge them into a single logical volume.
 
{{Warning|Conversion of a RAID10 logical volume into a thin pool '''destroys''' all existing data in the logical volume!}}

{{RootCmd|lvcreate -i 2 -m 1 --type raid10 -l 1012 -n thin_pool vg0
|lvcreate -i 2 -m 1 --type raid10 -l 6 -n thin_meta vg0
|lvconvert --thinpool vg0/thin_pool --poolmetadata vg0/thin_meta}}

== LVM으로 실험하기 ==

실제 저장 장치를 활용하지 않고도 LVM으로 실험 활동을 할 수 있습니다. 이를 수행해보려면, 루프백 장치를 만듭니다.

먼저 루프백 모듈을 불러왔는지 확인하십시오. 

{{RootCmd|modprobe -r loop && modprobe loop max_part{{=}}63}}

{{Note/ko|루프백 지원을 커널에 빌드했다면, <code>loop.max_part{{=}}63</code> 부팅 옵션을 활용하십시오.}}

다음 장치를 검색하는데 LVM에서 [[udev]]를 활용하지 않도록 설정하십시오:

{{File|/etc/lvm/lvm.conf|LVM 설정에서 udev 비활성화|<pre>
obtain_device_list_from_udev = 0
</pre>}}

{{Important/ko|시험 목적일 뿐이며, 실제 장치를 다루는데 있어 udev를 사용하는 방식이 빠른지 설정을 되돌려서 확인하십시오!}}

저장 장치가 될 이미지 파일을 만드십시오. 다음 예제에서는 실제 하드 디스크 드라이브 공간에서 전부 ~10GB 가량의 용량에 대해 다섯개의 파일을 사용합니다:

{{RootCmd|mkdir /var/lib/lvm_img
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm0.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm1.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm2.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm3.img bs{{=}}1024 seek{{=}}2097152
|dd if{{=}}/dev/null of{{=}}/var/lib/lvm_img/lvm4.img bs{{=}}1024 seek{{=}}2097152}}

어떤 루프백 장치를 활용할 수 있는지 확인하십시오:

{{RootCmd|losetup -a}}

모든 루프백 장치가 있다면, 장치를 만드십시오:

{{RootCmd|losetup /dev/loop0 /var/lib/lvm_img/lvm0.img
|losetup /dev/loop1 /var/lib/lvm_img/lvm1.img
|losetup /dev/loop2 /var/lib/lvm_img/lvm2.img
|losetup /dev/loop3 /var/lib/lvm_img/lvm3.img
|losetup /dev/loop4 /var/lib/lvm_img/lvm4.img}}

이제 시스템의 다른 하드 디스크 드라이브처럼 {{Path|/dev/loop[0-4]}} 장치를 사용할 수 있습니다(그래서 완벽한 물리 볼륨이 됩니다).

{{Note/ko|다음에 재부팅을 수행할 때 모든 루프백 장치를 활성화해제 할 것이며 {{Path|/var/lib/lvm_img}} 폴더를 삭제할 수 있습니다.}}

== 문제해결 ==

LVM에는 몇가지 레벨의 중복을 지원하는 일부 기능을 지니고 있습니다. 다만, 잃어버린 물리 볼륨 또는 논리 볼륨을 복원할 수 있는 곳에 몇가지 상황이 있긴 합니다.

=== vgcfgrestore 유틸리티 ===

기본적으로 LVM 물리 볼륨, 볼륨 그룹, 논리 볼륨 그 어느 곳에서든 내용이 바뀔 경우, LVM2에서 {{Path|/etc/lvm/archive}}에 메타데이터 백업 파일을 만듭니다. 이 파일은 갑작스럽게 바뀐 상태(잘못된 논리 볼륨 삭제 같은 경우)로부터 복원하는데 활용할 수 있습니다. LVM은 또한 {{Path|/etc/lvm/backup}}에 가장 최근의 메타데이터 백업 사본을 유지합니다. 이런 요소는 교체 디스크에 메타데이터를 복원하는데 활용할 수 있을 뿐만 아니라, 깨진 메타데이터를 복구하는데도 활용할 수 있습니다.

복원하려는 존재 볼륨 그룹의 상태를 보려면(가독성을 개선하기 위해 일부만 출력):

{{RootCmd|vgcfgrestore --list vg00|output=<pre>
  File:		/etc/lvm/archive/vg0_00042-302371184.vg
  VG name:    	vg0
  Description:	Created *before* executing 'lvremove vg0/lvm_raid1'
  Backup Time:	Sat Jul 13 01:41:32 201
</pre>}}

==== 갑작스럽게 삭제된 논리 볼륨 복원 ====

볼륨 그룹 ''vg0''에서 논리 볼륨 ''lvm_raid1''이 갑자기 제거된 상황을 가정하겠습니다. 다음과 같이 복구할 수 있습니다:

{{RootCmd|vgcfgrestore -f /etc/lvm/archive/vg0_00042-302371184.vg vg0}}

{{Important/ko|<tt>vgcfgrestore</tt> 명령은 LVM 메타데이터만 복원하며, 논리 볼륨에 있는 모든 데이터를 복원하는 것이 ''아닙니다''. 또한 <code>pvremove</code>, <code>vgremove</code>, <code>lvremove</code>도 데이터는 온전히 남겨두고 메타데이터만 제거합니다. {{Path|/etc/lvm/lvm.conf}}에 <code>issue_discards</code>를 설정했다면, 해당 명령은 데이터에 ''해가 됩니다''.}}

==== 고장난 물리 볼륨 바꾸기 ====

이 방법을 통해 제대로 ''교체''하고, 이전 물리 볼륨에서와 완전히 똑같은 메타데이터를 새 물리 볼륨에 다시 만들 수 있습니다.

{{RootCmd|vgdisplay --partial --verbose|output=<pre>
  --- Physical volumes ---
  PV Name               /dev/loop0     
  PV UUID               iLdp2U-GX3X-W2PY-aSlX-AVE9-7zVC-Cjr5VU
  PV Status             allocatable
  Total PE / Free PE    511 / 102
  
  PV Name               unknown device     
  PV UUID               T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY
  PV Status             allocatable
  Total PE / Free PE    511 / 102
</pre>}}

여기서 중요한 줄은 UUID ''unknown device'' 입니다. 

{{RootCmd|pvcreate --uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY --restorefile /etc/lvm/backup/vg0 /dev/loop1|output=<pre>
  Couldn't find device with uuid T7bUjc-PYoO-bMqI-53vh-uxOV-xHYv-0VejBY.
  Physical volume "/dev/loop1" successfully created</pre>}}

이 명령으로 물리 볼륨 메타데이터를 다시 만들지만, 물리 볼륨의 빠진 논리 볼륨이나 볼륨 그룹 데이터를 다시 만들진 않습니다.

{{RootCmd|vgcfgrestore -f /etc/lvm/backup/vg0 vg0|output=<pre>
  Restored volume group vg0
</pre>}}

이 명령으로 이제 물리 볼륨, 논리 볼륨, 볼륨 그룹 데이터의 빠진 메타데이터를 다시 만듭니다. 그러나 데이터를 복원하지는 않기 때문에 미러의 동기화는 오래된 상태가 됩니다.

{{RootCmd|vgchange -ay vg0|output=<pre>
  device-mapper: reload ioctl on  failed: Invalid argument
  1 logical volume(s) in volume group "vg0" now active
</pre>}}

{{RootCmd|lvchange --resync vg0/lvm_raid1|output=<pre>
Do you really want to deactivate logical volume lvm_raid1 to resync it? [y/n]: y
</pre>}}

이 명령은 미러를 다시 싱크할 것입니다. RAID 4, 5, 6에서도 동작합니다. 

=== 논리 볼륨 비활성화 ===

다음 명령으로 논리 볼륨을 비활성화 할 수 있습니다:

{{RootCmd|umount /dev/vg0/lvol1
|lvchange -a n /dev/vg0/lvol1}}

다시 활성화하기 전에는 논리 볼륨을 어디에서든 다시 마운트 할 수 없습니다:

{{RootCmd|lvchange -a y /dev/vg0/lvol1}}

== 외부 자료 ==

* [http://sourceware.org/lvm2/ LVM2 sourceware.org]
* [http://tldp.org/HOWTO/LVM-HOWTO/ LVM tldp.org]
* [http://sources.redhat.com/lvm2/wiki/ LVM2 Wiki redhat.com]


[[Category:Core system]]
